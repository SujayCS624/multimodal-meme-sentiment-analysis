{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NNFLProject.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xy924162Jykv",
        "colab_type": "code",
        "outputId": "794c9ef4-96bf-47e4-834b-a672e9eef42b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsqgPy4FJ1w3",
        "colab_type": "code",
        "outputId": "e8fbe377-453e-41a8-e738-ea54954a4a2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras\n",
        "import re\n",
        "import os\n",
        "import nltk\n",
        "import pickle\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, SnowballStemmer\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "#from keras.callbacks.callbacks import EarlyStopping\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential,model_from_json,Model\n",
        "from keras.layers import Dense, Dropout, Activation,Bidirectional,Conv1D,MaxPooling1D,Flatten,GRU,SimpleRNN\n",
        "from keras.layers import Embedding\n",
        "from sklearn.metrics import f1_score, precision_score, accuracy_score, recall_score\n",
        "import sklearn\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import SpatialDropout1D\n",
        "from keras.utils import to_categorical\n",
        "from keras.applications.resnet_v2 import ResNet50V2\n",
        "from keras import optimizers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWAaD9mTKkJf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv(\"/content/drive/My Drive/NNFL Fall'19 Project/data_7000_new.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tC9JBAdaHooW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-yOv4mvK_PD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.columns = [\"MEME Name\", \"URL\", \"Text1\", \"Text2\", \"Sentiment_Humour\", \"Sentiment_General\",\"Sentiment_Offensive\",\"Sentiment_Motivational\",\"Sentiment_Positive\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWFih7QhPO9m",
        "colab_type": "code",
        "outputId": "237ad177-2e2e-456d-c472-b979a2f93b51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "data['Sentiment_Positive'][669] = 'positive'\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "data['Sentiment_Positive'].fillna('positive',inplace=True)\n",
        "pd.set_option('display.width', 2000)\n",
        "print(data[data['Text2'].str.contains('funny').fillna(False) & ~data['Sentiment_Humour'].str.contains('hilarious').fillna(True) & ~data['Sentiment_Humour'].str.contains('funny').fillna(True)])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Empty DataFrame\n",
            "Columns: [MEME Name, URL, Text1, Text2, Sentiment_Humour, Sentiment_General, Sentiment_Offensive, Sentiment_Motivational, Sentiment_Positive]\n",
            "Index: []\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3UaWMkYzOgg",
        "colab_type": "code",
        "outputId": "c549212e-84c7-482c-9a79-960f5f79d168",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        }
      },
      "source": [
        "data[data['Text2'].str.contains('nigger') | data['Text1'].str.contains('nigger') | data['MEME Name'].str.contains('nigger') ]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MEME Name</th>\n",
              "      <th>URL</th>\n",
              "      <th>Text1</th>\n",
              "      <th>Text2</th>\n",
              "      <th>Sentiment_Humour</th>\n",
              "      <th>Sentiment_General</th>\n",
              "      <th>Sentiment_Offensive</th>\n",
              "      <th>Sentiment_Motivational</th>\n",
              "      <th>Sentiment_Positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3252</th>\n",
              "      <td>racis_194+memes_a52fba_6202283.jpg</td>\n",
              "      <td>https://memestatic.fjcdn.com/pictures/+memes_a...</td>\n",
              "      <td>Normie: \"Your meme's are racist and offensive</td>\n",
              "      <td>Normie: \"Your meme's are racist and offensive ...</td>\n",
              "      <td>not_funny</td>\n",
              "      <td>general</td>\n",
              "      <td>not_offensive</td>\n",
              "      <td>not_motivational</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3262</th>\n",
              "      <td>racis_232black-nigger-memes.jpg</td>\n",
              "      <td>https://racistmemes.com/wp-content/uploads/201...</td>\n",
              "      <td>IF I HAD A DOLLAR FOR EVERY RACIST THING I'VE ...</td>\n",
              "      <td>IF I HAD A DOLLAR FOR EVERY RACIST THING I'VE ...</td>\n",
              "      <td>very_funny</td>\n",
              "      <td>twisted_meaning</td>\n",
              "      <td>very_offensive</td>\n",
              "      <td>motivational</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5511</th>\n",
              "      <td>minion_b2b3a14c649a3561275649de293dc20ba41adf8...</td>\n",
              "      <td>https://pm1.narvii.com/6748/b2b3a14c649a356127...</td>\n",
              "      <td>I'm not clumsy It's just The niggers in my bas...</td>\n",
              "      <td>I'm not clumsy It's just The niggers in my bas...</td>\n",
              "      <td>funny</td>\n",
              "      <td>not_sarcastic</td>\n",
              "      <td>slight</td>\n",
              "      <td>not_motivational</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              MEME Name  ... Sentiment_Positive\n",
              "3252                 racis_194+memes_a52fba_6202283.jpg  ...            neutral\n",
              "3262                    racis_232black-nigger-memes.jpg  ...            neutral\n",
              "5511  minion_b2b3a14c649a3561275649de293dc20ba41adf8...  ...           positive\n",
              "\n",
              "[3 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyTha_BXzO0t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_h3IQq6NMNXO",
        "colab_type": "code",
        "outputId": "4bd6d580-e8ae-404a-907b-b82bd7737f17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "data['Sentiment_Offensive'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "not_offensive        2488\n",
              "slight               2353\n",
              "very_offensive       1327\n",
              "hateful_offensive     199\n",
              "Name: Sentiment_Offensive, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7WvEGAAzMuo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9VvJBTCMiuc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzR8rdp1QO9N",
        "colab_type": "code",
        "outputId": "adb6e4eb-477e-4a40-ac0f-23c758d7a625",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(data[data['Sentiment_Offensive'] == 'neutral']),\n",
        "len(data[data['Sentiment_Offensive'] == 'positive']),\n",
        "len(data[data['Sentiment_Offensive'] == 'negative']),\n",
        "len(data[data['Sentiment_Offensive'] == 'very_positive']),\n",
        "len(data[data['Sentiment_Positive'] == 'very_negative']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0 0 0 133\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUVH0tGZQyYa",
        "colab_type": "code",
        "outputId": "6454f535-b2ce-4887-8dfe-c140674ed9b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(data[data['Sentiment_Positive'] == 'neutral']),\n",
        "len(data[data['Sentiment_Positive'] == 'positive']),\n",
        "len(data[data['Sentiment_Positive'] == 'negative']),\n",
        "len(data[data['Sentiment_Positive'] == 'very_positive']),\n",
        "len(data[data['Sentiment_Positive'] == 'very_negative']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2033 2845 430 926 133\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlNVMlNK8eda",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "STOPWORDS = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNy7p2-xMWmx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(0,len(data)):\n",
        "  if i not in data.index:\n",
        "    continue\n",
        "  text = data[\"Text2\"][i]\n",
        "  #print(text)\n",
        "  text = str(text)\n",
        "  bad_chars = [';', ':', '!', '*', '#','@','\"','(',')']\n",
        "  for j in bad_chars: \n",
        "    text = text.replace(j, ' ') \n",
        "  text = text.lower()\n",
        "  text = ' '.join(word for word in text.split() if word not in STOPWORDS)\n",
        "  word_list = []\n",
        "  for word in text.split():\n",
        "    word = lemmatizer.lemmatize(word)\n",
        "    word_list.append(word)\n",
        "  text = ' '.join(word for word in word_list)\n",
        "  data[\"Text2\"][i] = text "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "karxyK_i-sj2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#X = (data[data['Sentiment_Positive']!='neutral'])['Text2']\n",
        "X=data['Text2']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2F6ve4eE75I",
        "colab_type": "code",
        "outputId": "05b9ab61-d04b-4750-85a1-11868ccedc51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "MAX_NB_WORDS = 13000\n",
        "MAX_SEQUENCE_LENGTH = 60\n",
        "EMBEDDING_DIM = 200\n",
        "tokenizer = Tokenizer(lower=True)\n",
        "tokenizer.fit_on_texts(X)\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "X_proc = tokenizer.texts_to_sequences(X)\n",
        "X_proc = pad_sequences(X_proc, maxlen=MAX_SEQUENCE_LENGTH,padding='post')\n",
        "print('Shape of data tensor:', X_proc.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 12104 unique tokens.\n",
            "Shape of data tensor: (6367, 60)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fd3gh-ALFAUY",
        "colab_type": "code",
        "outputId": "08231027-73f2-4a5f-f5b0-de4eea2e1e33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "Y = data.iloc[:,4:]\n",
        "\n",
        "Y_motivational = Y['Sentiment_Motivational']\n",
        "print(Y_motivational[0])\n",
        "#Y_positive = (Y[Y['Sentiment_Positive']!='neutral'])['Sentiment_Positive']\n",
        "Y_positive = (Y['Sentiment_Positive'])\n",
        "Y_offensive = Y['Sentiment_Offensive']\n",
        "Y_general = Y['Sentiment_General']\n",
        "Y_humour = Y['Sentiment_Humour']\n",
        "Y_motivational = pd.get_dummies(Y_motivational)\n",
        "Y_positive = pd.get_dummies(Y_positive)\n",
        "Y_offensive = pd.get_dummies(Y_offensive)\n",
        "Y_general = pd.get_dummies(Y_general)\n",
        "Y_humour = pd.get_dummies(Y_humour)\n",
        "print(Y_positive.columns)\n",
        "#print(Y.head())\n",
        "#print(data.iloc[:,4:].head())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "motivational\n",
            "Index(['negative', 'neutral', 'positive', 'very_negative', 'very_positive'], dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58a87RL2iiGb",
        "colab_type": "code",
        "outputId": "1bf8f0d9-540c-4521-9416-cff8daf100a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "Y['Sentiment_Motivational'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "not_motivational    4132\n",
              "motivational        2235\n",
              "Name: Sentiment_Motivational, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLnUQRFalvyL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "#!wget http://nlp.stanford.edu/data/glove.twitter.27B.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17AhdzS2mksM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!unzip glove.twitter.27B.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhsyImMDW331",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!unzip glove.6B.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LduSdQ2xdg1r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrBTWCZcWqSj",
        "colab_type": "code",
        "outputId": "0a745852-d47e-4be5-cb06-716d36008bf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'''with open('/content/drive/My Drive/embed/glove-twitter-27B-200d.txt', 'w') as f:\n",
        "  with open('/content/glove.twitter.27B.200d.txt', 'r') as f1:\n",
        "    for line in f1:\n",
        "      f.write(line)\n",
        "      #print(line)\n",
        "'''\n",
        "print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TILyjZtWbApz",
        "colab_type": "code",
        "outputId": "076d2f0c-b092-41e7-c832-ad6ecff7ff31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'''with open('/content/drive/My Drive/embed/glove-6B-200d.txt', 'w') as f:\n",
        "  with open('/content/glove.6B.200d.txt', 'r') as f1:\n",
        "    for line in f1:\n",
        "      f.write(line)\n",
        "      #print(line)\n",
        "'''\n",
        "print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CORfsRkBtQP",
        "colab_type": "code",
        "outputId": "300c7b98-eef4-44b7-fe83-95693e5de2b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from gensim.test.utils import datapath, get_tmpfile\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "glove_file = ('/content/drive/My Drive/glove-twitter-27B-200d.txt')\n",
        "tmp_file = get_tmpfile(\"test_word2vec.txt\")\n",
        "\n",
        "_ = glove2word2vec(glove_file, tmp_file)\n",
        "\n",
        "glove_twitter = KeyedVectors.load_word2vec_format(tmp_file)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCM9lRiTB-xS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "glove_twitter.most_similar(positive=['king','woman'],negative=['man'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mt0_fb4lgY95",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TWITTER'''\n",
        "\n",
        "embeddings_index = {}\n",
        "f = open('/content/drive/My Drive/embed/glove-twitter-27B-200d.txt')#### have to check this part (Suhas- needs to be on colab bub,maybe import glove to google drive?,quick hack is to use wget each time)\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oo0wuSpWeUIT",
        "colab_type": "code",
        "outputId": "b4521f24-0feb-4f8e-e8e8-ce018972c240",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#NORMAL GLOVE\n",
        "embeddings_index_2 = {}\n",
        "f = open('/content/drive/My Drive/glove-6B-200d.txt')#### have to check this part (Suhas- needs to be on colab bub,maybe import glove to google drive?,quick hack is to use wget each time)\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index_2[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index_2))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yvgJaMYHL9S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrQBz_ZeyzYK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDAV4tBDgaH-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TWITTER\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "    try:\n",
        "      embedding_vector = glove_twitter.wv[word]\n",
        "      if embedding_vector is not None:\n",
        "          # words not found in embedding index will be all-zeros\n",
        "          embedding_matrix[i] = embedding_vector\n",
        "    except:\n",
        "       f=0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQtMEmRop7lS",
        "colab_type": "code",
        "outputId": "74065f33-6070-45cc-a66c-bcdd4b267fab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(embedding_matrix.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(12105, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iL5nyMaQ7kAy",
        "colab_type": "code",
        "outputId": "06aebdeb-a492-4ac7-de1b-899c4b7aae9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "print(X_proc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  35  111 4951 ...    0    0    0]\n",
            " [3263 4955 4956 ...    0    0    0]\n",
            " [ 111   27  305 ...    0    0    0]\n",
            " ...\n",
            " [4941  887  351 ...    0    0    0]\n",
            " [ 335   96  518 ...    0    0    0]\n",
            " [  42 2625  387 ...    0    0    0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKqh4UiXqGej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.savetxt(\"twitter_matrix.csv\", embedding_matrix, delimiter=\",\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hr3AfGoEefYq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#NORMAL GLOVE\n",
        "# embedding_matrix_2 = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "   embedding_vector = embeddings_index_2.get(word)\n",
        "   if embedding_vector is not None:\n",
        "       # words not found in embedding index will be all-zeros.\n",
        "       embedding_matrix_2[i] = embedding_vector\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfIzr6ongkl-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TWITTER\n",
        "from keras.layers import Embedding\n",
        "\n",
        "embedding_layer = Embedding(len(word_index) + 1,\n",
        "                            EMBEDDING_DIM,\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=MAX_SEQUENCE_LENGTH,\n",
        "                            trainable=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRz3KZ_7ekda",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#NORMAL GLOVE\n",
        "\n",
        "embedding_layer_2 = Embedding(len(word_index) + 1,\n",
        "                            EMBEDDING_DIM,\n",
        "                            weights=[embedding_matrix_2],\n",
        "                            input_length=MAX_SEQUENCE_LENGTH,\n",
        "                            trainable=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ONS_JMXCVQk",
        "colab_type": "code",
        "outputId": "06d42235-eb78-417f-ddcc-bd0c0a3e3bcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X_proc,Y_offensive, test_size = 0.10, random_state = 42,shuffle = True)\n",
        "print(X_train.shape,Y_positive.shape)\n",
        "print(X_test.shape,Y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5730, 60) (6367, 5)\n",
            "(637, 60) (637, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhE4Au7OZ2aD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_proc_s = np.ones((6367,60)).reshape((-1,60,1))\n",
        "# Y_proc_s = np.random.randn(6367,4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7w1lCvU09gRZ",
        "colab_type": "code",
        "outputId": "3da11dd0-4b4f-4b46-e731-92f1c55893c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "source": [
        "from keras import optimizers\n",
        "\n",
        "########Normal glove\n",
        "modelg = Sequential()\n",
        "modelg.add(embedding_layer)#### model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X_proc.shape[1])) ##### making changes here maybe\n",
        "#model.add(SpatialDropout1D(0.2))\n",
        "#model.add((SimpleRNN(32,activation='relu',input_shape=(1,60))))\n",
        "#model.add(Flatten())\n",
        "#model.add(Dense(60,input_shape=(60,)))\n",
        "#modelg.add((LSTM(200, activation='relu'))\n",
        "modelg.add((LSTM(200,return_sequences=True,kernel_initializer='zeros',activation='relu')))\n",
        "\n",
        "#model.add((LSTM(200,return_sequences=True,kernel_initializer='zeros',activation='relu')))\n",
        "#model.add(LSTM(200,kernel_initializer='zeros',activation='relu'))\n",
        "#model.add(Conv1D(512, 3, activation='relu'))\n",
        "#model.add(MaxPooling1D(5))\n",
        "#model.add(Conv1D(512, 3, activation='relu'))\n",
        "#model.add(MaxPooling1D(2))\n",
        "#model.add(Dense(128,activation='relu'))\n",
        "#model.add(Dense(64,activation='relu'))\n",
        "modelg.add(Flatten())\n",
        "#modelg.add(Dense(64,activation='relu',kernel_initializer=keras.initializers.RandomUniform(minval=-0.05, maxval=0.05, seed=None),bias_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)))\n",
        "modelg.add(Dense(128, activation='relu'))\n",
        "modelg.add(Dense(64, activation='relu'))\n",
        "modelg.add(Dense(2, activation='softmax'))\n",
        "\n",
        "print(modelg.summary())\n",
        "modelg.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(lr=0.01), metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 60, 200)           2421000   \n",
            "_________________________________________________________________\n",
            "lstm_14 (LSTM)               (None, 60, 200)           320800    \n",
            "_________________________________________________________________\n",
            "flatten_13 (Flatten)         (None, 12000)             0         \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (None, 128)               1536128   \n",
            "_________________________________________________________________\n",
            "dense_42 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_43 (Dense)             (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 4,286,314\n",
            "Trainable params: 1,865,314\n",
            "Non-trainable params: 2,421,000\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1woUUtUyeOd6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelg.save('model_motivational.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKVYjoPA9gZ_",
        "colab_type": "code",
        "outputId": "3316646e-2a70-46f4-df71-d602046571b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        }
      },
      "source": [
        "from keras.utils import plot_model\n",
        "historyg = modelg.fit(X_proc, Y_motivational, epochs=20, batch_size=32,validation_split=0.1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 5730 samples, validate on 637 samples\n",
            "Epoch 1/20\n",
            "5730/5730 [==============================] - 53s 9ms/step - loss: 0.6511 - acc: 0.6473 - val_loss: 0.6403 - val_acc: 0.6641\n",
            "Epoch 2/20\n",
            "5730/5730 [==============================] - 47s 8ms/step - loss: 0.6503 - acc: 0.6473 - val_loss: 0.6410 - val_acc: 0.6641\n",
            "Epoch 3/20\n",
            "5730/5730 [==============================] - 47s 8ms/step - loss: 0.6498 - acc: 0.6473 - val_loss: 0.6385 - val_acc: 0.6641\n",
            "Epoch 4/20\n",
            "5730/5730 [==============================] - 46s 8ms/step - loss: 0.6498 - acc: 0.6473 - val_loss: 0.6418 - val_acc: 0.6641\n",
            "Epoch 5/20\n",
            "5730/5730 [==============================] - 47s 8ms/step - loss: 0.6499 - acc: 0.6473 - val_loss: 0.6388 - val_acc: 0.6641\n",
            "Epoch 6/20\n",
            "5730/5730 [==============================] - 46s 8ms/step - loss: 0.6502 - acc: 0.6473 - val_loss: 0.6388 - val_acc: 0.6641\n",
            "Epoch 7/20\n",
            "5730/5730 [==============================] - 46s 8ms/step - loss: 0.6497 - acc: 0.6473 - val_loss: 0.6426 - val_acc: 0.6641\n",
            "Epoch 8/20\n",
            "5730/5730 [==============================] - 46s 8ms/step - loss: 0.6508 - acc: 0.6473 - val_loss: 0.6433 - val_acc: 0.6641\n",
            "Epoch 9/20\n",
            "5730/5730 [==============================] - 46s 8ms/step - loss: 0.6500 - acc: 0.6473 - val_loss: 0.6388 - val_acc: 0.6641\n",
            "Epoch 10/20\n",
            "5730/5730 [==============================] - 47s 8ms/step - loss: 0.6498 - acc: 0.6473 - val_loss: 0.6439 - val_acc: 0.6641\n",
            "Epoch 11/20\n",
            "5730/5730 [==============================] - 46s 8ms/step - loss: 0.6501 - acc: 0.6473 - val_loss: 0.6393 - val_acc: 0.6641\n",
            "Epoch 12/20\n",
            "5730/5730 [==============================] - 45s 8ms/step - loss: 0.6505 - acc: 0.6473 - val_loss: 0.6408 - val_acc: 0.6641\n",
            "Epoch 13/20\n",
            "5730/5730 [==============================] - 45s 8ms/step - loss: 0.6494 - acc: 0.6473 - val_loss: 0.6383 - val_acc: 0.6641\n",
            "Epoch 14/20\n",
            "5730/5730 [==============================] - 45s 8ms/step - loss: 0.6519 - acc: 0.6473 - val_loss: 0.6387 - val_acc: 0.6641\n",
            "Epoch 15/20\n",
            "5730/5730 [==============================] - 45s 8ms/step - loss: 0.6493 - acc: 0.6473 - val_loss: 0.6396 - val_acc: 0.6641\n",
            "Epoch 16/20\n",
            "5730/5730 [==============================] - 45s 8ms/step - loss: 0.6499 - acc: 0.6473 - val_loss: 0.6395 - val_acc: 0.6641\n",
            "Epoch 17/20\n",
            "5730/5730 [==============================] - 45s 8ms/step - loss: 0.6502 - acc: 0.6473 - val_loss: 0.6386 - val_acc: 0.6641\n",
            "Epoch 18/20\n",
            "5730/5730 [==============================] - 45s 8ms/step - loss: 0.6500 - acc: 0.6473 - val_loss: 0.6395 - val_acc: 0.6641\n",
            "Epoch 19/20\n",
            "5730/5730 [==============================] - 45s 8ms/step - loss: 0.6505 - acc: 0.6473 - val_loss: 0.6391 - val_acc: 0.6641\n",
            "Epoch 20/20\n",
            "5730/5730 [==============================] - 45s 8ms/step - loss: 0.6499 - acc: 0.6473 - val_loss: 0.6417 - val_acc: 0.6641\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nARV8lEJ9gdB",
        "colab_type": "code",
        "outputId": "f899bc0b-669d-4aec-e33d-85be0de0f57d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.plot(historyg.history['acc'])\n",
        "plt.plot(historyg.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(historyg.history['loss'])\n",
        "plt.plot(historyg.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEWCAYAAACufwpNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLv8DI0pQ1QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMdIPPJy9ggK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAD7Z5fs9gop",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKR1w_Vh9gw6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o23SdCVOChL5",
        "colab_type": "code",
        "outputId": "ad3f5710-44b3-4c46-c77a-e7fc07183676",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        }
      },
      "source": [
        "from keras import optimizers\n",
        "\n",
        "#TWITTER\n",
        "model = Sequential()\n",
        "model.add(embedding_layer)#### model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X_proc.shape[1])) ##### making changes here maybe\n",
        "#model.add(SpatialDropout1D(0.2))\n",
        "#model.add((SimpleRNN(32,activation='relu',input_shape=(1,60))))\n",
        "#model.add(Flatten())\n",
        "#model.add(Dense(60,input_shape=(60,)))\n",
        "model.add((LSTM(200,return_sequences=True,kernel_initializer='zeros',activation='relu')))\n",
        "# model.add((LSTM(200,return_sequences=True,kernel_initializer='zeros',activation='relu')))\n",
        "\n",
        "#model.add((LSTM(200,return_sequences=True,kernel_initializer='zeros',activation='relu')))\n",
        "#model.add(LSTM(200,kernel_initializer='zeros',activation='relu'))\n",
        "#model.add(Conv1D(512, 3, activation='relu'))\n",
        "#model.add(MaxPooling1D(5))\n",
        "#model.add(Conv1D(512, 3, activation='relu'))\n",
        "#model.add(MaxPooling1D(2))\n",
        "#model.add(Dense(128,activation='relu'))\n",
        "#model.add(Dense(64,activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(104,activation='relu',kernel_initializer=keras.initializers.RandomUniform(minval=-0.05, maxval=0.05, seed=None)\n",
        ",bias_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)))\n",
        "model.add(Dense(128, activation='softmax'))\n",
        "model.add(Dense(64, activation='softmax'))\n",
        "\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "print(model.summary())\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(lr=0.01), metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4409: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n",
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 60, 200)           2421000   \n",
            "_________________________________________________________________\n",
            "lstm_13 (LSTM)               (None, 60, 200)           320800    \n",
            "_________________________________________________________________\n",
            "flatten_12 (Flatten)         (None, 12000)             0         \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 104)               1248104   \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 128)               13440     \n",
            "_________________________________________________________________\n",
            "dense_39 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 4,011,730\n",
            "Trainable params: 1,590,730\n",
            "Non-trainable params: 2,421,000\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maD2EI18FMka",
        "colab_type": "code",
        "outputId": "82744020-88d3-4882-839b-31ab55eee4ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "from keras.utils import plot_model\n",
        "history = model.fit(X_proc, Y_positive, epochs=10, batch_size=32,validation_split=0.1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 5730 samples, validate on 637 samples\n",
            "Epoch 1/10\n",
            "5730/5730 [==============================] - 18s 3ms/step - loss: 1.3160 - acc: 0.4442 - val_loss: 1.2475 - val_acc: 0.4505\n",
            "Epoch 2/10\n",
            "5730/5730 [==============================] - 17s 3ms/step - loss: 1.2715 - acc: 0.4464 - val_loss: 1.2475 - val_acc: 0.4505\n",
            "Epoch 3/10\n",
            "5730/5730 [==============================] - 17s 3ms/step - loss: 1.2720 - acc: 0.4464 - val_loss: 1.2459 - val_acc: 0.4505\n",
            "Epoch 4/10\n",
            "5730/5730 [==============================] - 17s 3ms/step - loss: 1.2716 - acc: 0.4464 - val_loss: 1.2503 - val_acc: 0.4505\n",
            "Epoch 5/10\n",
            "5730/5730 [==============================] - 17s 3ms/step - loss: 1.2732 - acc: 0.4464 - val_loss: 1.2460 - val_acc: 0.4505\n",
            "Epoch 6/10\n",
            "5730/5730 [==============================] - 17s 3ms/step - loss: 1.2722 - acc: 0.4464 - val_loss: 1.2438 - val_acc: 0.4505\n",
            "Epoch 7/10\n",
            "5730/5730 [==============================] - 17s 3ms/step - loss: 1.2722 - acc: 0.4464 - val_loss: 1.2469 - val_acc: 0.4505\n",
            "Epoch 8/10\n",
            "5730/5730 [==============================] - 17s 3ms/step - loss: 1.2718 - acc: 0.4464 - val_loss: 1.2446 - val_acc: 0.4505\n",
            "Epoch 9/10\n",
            "5730/5730 [==============================] - 17s 3ms/step - loss: 1.2712 - acc: 0.4464 - val_loss: 1.2467 - val_acc: 0.4505\n",
            "Epoch 10/10\n",
            "5730/5730 [==============================] - 17s 3ms/step - loss: 1.2719 - acc: 0.4464 - val_loss: 1.2445 - val_acc: 0.4505\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7mgeyEqk_ei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "twitter_model = model.save('text_positive.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtX_EMKg2m6h",
        "colab_type": "code",
        "outputId": "afb3f7ff-e86a-496e-ee17-69676555e76d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "# Plot training & validation accuracy values\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEWCAYAAACufwpNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de5hdVX3/8feHmYREuQSSAJo7MKkk\npYR4ikK0IiAGVMJjEZNKFQRSrQiWgoY+Vmy8/KDVeiPVBokF5SICxrEFAwoUxAKZ4HDJRGAcLpkY\nmmTMhVgwmeT7+2OvgZ1hkpwke8/JZD6v5znP7L3W2uusPcp8stY+Z29FBGZmZkXYq9YDMDOzPYdD\nxczMCuNQMTOzwjhUzMysMA4VMzMrjEPFzMwK41Ax2wmSxkoKSfVVtD1b0i97Y1xmteZQsT2epGcl\nbZA0rFv5r1MwjK3NyMz2PA4V6y+eAWZ07Ug6Enhd7Yaze6hmpmW2Ixwq1l98H/hwbv8jwHX5BpL2\nl3SdpJWSnpP0WUl7pbo6SV+RtEpSG/CeHo69RtJyScskfVFSXTUDk/QjSS9IWivpPkkTc3WDJX01\njWetpF9KGpzq3ibpV5LWSFoq6exUfq+k83J9bLH8lmZnn5D0NPB0KvtG6mOdpEWS3p5rXyfpHyT9\nVtKLqX6UpDmSvtrtXBol/V015217JoeK9RcPAvtJOiL9sZ8O/KBbm28B+wOHAu8gC6FzUt35wHuB\no4EKcEa3Y/8D6AQOT21OBs6jOncADcBBwCPA9bm6rwBvBo4DDgQ+DWyWNCYd9y1gODAJaK7y/QBO\nB94CTEj7C1MfBwI3AD+SNCjVXUw2yzsV2A/4KPB/wLXAjFzwDgNOSsdbfxURfvm1R7+AZ8n+2H0W\n+H/AVOAuoB4IYCxQB2wAJuSO+xvg3rR9N/CxXN3J6dh64GDgj8DgXP0M4J60fTbwyyrHOiT1uz/Z\nP/peAo7qod1lwI+30se9wHm5/S3eP/V/wnbGsbrrfYEngWlbabcEeFfavgC4vdb/e/tV25fXU60/\n+T5wHzCObktfwDBgAPBcruw5YETafiOwtFtdlzHp2OWSusr26ta+R2nW9CXgA2Qzjs258ewNDAJ+\n28Oho7ZSXq0txibpEuBcsvMMshlJ1wcbtvVe1wJnkYX0WcA3dmFMtgfw8pf1GxHxHNkF+1OB27pV\nrwI2kgVEl9HAsrS9nOyPa76uy1KymcqwiBiSXvtFxES276+AaWQzqf3JZk0ASmN6GTish+OWbqUc\n4A9s+SGEQ3po88rtydP1k08DZwIHRMQQYG0aw/be6wfANElHAUcA87fSzvoJh4r1N+eSLf38IV8Y\nEZuAm4EvSdo3XbO4mFevu9wMXChppKQDgFm5Y5cDdwJflbSfpL0kHSbpHVWMZ1+yQOogC4Iv5/rd\nDMwD/lXSG9MF82Ml7U123eUkSWdKqpc0VNKkdGgz8H5Jr5N0eDrn7Y2hE1gJ1Ev6HNlMpct3gS9I\nalDmzyQNTWNsJ7se833g1oh4qYpztj2YQ8X6lYj4bUQ0baX6k2T/ym8Dfkl2wXleqrsaWAA8SnYx\nvftM58PAQKCF7HrELcAbqhjSdWRLacvSsQ92q78EeJzsD/fvgSuBvSLiebIZ19+n8mbgqHTM18iu\nD/0v2fLU9WzbAuBnwFNpLC+z5fLYv5KF6p3AOuAaYHCu/lrgSLJgsX5OEX5Il5ntPEl/QTajGxP+\ng9LveaZiZjtN0gDgIuC7DhQDh4qZ7SRJRwBryJb5vl7j4dhuwstfZmZWGM9UzMysMP36y4/Dhg2L\nsWPH1noYZmZ9yqJFi1ZFxPCe6vp1qIwdO5ampq19utTMzHoi6bmt1Xn5y8zMCuNQMTOzwjhUzMys\nMP36mkpPNm7cSHt7Oy+//HKth9JrBg0axMiRIxkwYECth2JmfZxDpZv29nb23Xdfxo4dS+425nus\niKCjo4P29nbGjRtX6+GYWR/n5a9uXn75ZYYOHdovAgVAEkOHDu1XMzMzK49DpQf9JVC69LfzNbPy\nePlrZ6xth4172GMj1q+A711S61GYWW855Eg45YrCu3Wo7GY6fr+aE9//EQBeWLGKurq9GD70QAAe\nvvMWBg4cuN0+zvnkLGZdNJM/OfzQUsdqZtadQ2Vn7D+ytK6HDoPmJ5YA8PnPf5599tmHSy7ZcgYR\nEUQEe+3V8+rl9268dcffeGUnnPNfO36cmVmOr6n0Ea2trUyYMIEPfehDTJw4keXLlzNz5kwqlQoT\nJ05k9uzZr7R929veRnNzM52dnQwZMoRZs2Zx1FFHceyxx7JixYoanoWZ7ek8U9mGf/rpYlp+t67Q\nPie8cT8uf9/EnTr2N7/5Dddddx2VSgWAK664ggMPPJDOzk7e+c53csYZZzBhwoQtjlm7di3veMc7\nuOKKK7j44ouZN28es2bN6ql7M7Nd5plKH3LYYYe9EigAN954I5MnT2by5MksWbKElpaW1xwzePBg\nTjnlFADe/OY38+yzz/bWcM2sH/JMZRt2dkZRlte//vWvbD/99NN84xvf4OGHH2bIkCGcddZZPX7X\nJH9hv66ujs7Ozl4Zq5n1T56p9FHr1q1j3333Zb/99mP58uUsWLCg1kMyM/NMpa+aPHkyEyZM4E1v\nehNjxoxhypQptR6SmVn/fkZ9pVKJ7g/pWrJkCUcccUSNRlQ7/fW8zWzHSVoUEZWe6rz8ZWZmhXGo\nmJlZYRwqZmZWGIeKmZkVxqFiZmaFcaiYmVlhSg0VSVMlPSmpVVKPN5ySdKakFkmLJd2QKx8t6U5J\nS1L92FR+ferzCUnzJA1I5cdLWiupOb0+V+a5laWjo4NJkyYxadIkDjnkEEaMGPHK/oYNG6ruZ968\nebzwwgsljtTM7LVK+/KjpDpgDvAuoB1YKKkxIlpybRqAy4ApEbFa0kG5Lq4DvhQRd0naB9icyq8H\nzkrbNwDnAd9O+/dHxHvLOqfeMHToUJqbm4Gt3/q+GvPmzWPy5MkccsghRQ/RzGyryvxG/TFAa0S0\nAUi6CZgG5O96eD4wJyJWA0TEitR2AlAfEXel8vVdB0TE7V3bkh4Gynu4yW7m2muvZc6cOWzYsIHj\njjuOq666is2bN3POOefQ3NxMRDBz5kwOPvhgmpub+eAHP8jgwYN5+OGHq3q4l5nZriozVEYAS3P7\n7cBburUZDyDpAaAO+HxE/CyVr5F0GzAO+DkwKyI2dR2Ylr3+Grgo19+xkh4FfgdcEhGLd+kM7pgF\nLzy+S128xk4+wvOJJ57gxz/+Mb/61a+or69n5syZ3HTTTRx22GGsWrWKxx/PxrlmzRqGDBnCt771\nLa666iomTZpU7PjNzLah1vf+qgcagOPJZhz3SToylb8dOBp4HvghcDZwTe7YfwPui4j70/4jwJiI\nWC/pVGB+6nsLkmYCMwFGjx5d/BmV5Oc//zkLFy585db3L730EqNGjeLd7343Tz75JBdeeCHvec97\nOPnkk2s8UjPrz8oMlWXAqNz+yFSW1w48FBEbgWckPUUWBO1Ac27pbD7wVlKoSLocGA78TVdHEbEu\nt327pH+TNCwiVuXfMCLmAnMhu/fXNs9gJ2YUZYkIPvrRj/KFL3zhNXWPPfYYd9xxB3PmzOHWW29l\n7ty5NRihmVm5n/5aCDRIGidpIDAdaOzWZj7ZLAVJw8iWvdrSsUMkDU/tTiBdi5F0HvBuYEZEdF28\nR9IhkpS2jyE7t45yTq33nXTSSdx8882sWpVlZEdHB88//zwrV64kIvjABz7A7NmzeeSRRwDYd999\nefHFF2s5ZDPrh0qbqUREp6QLgAVk10vmRcRiSbOBpohoTHUnS2oBNgGXRkQHgKRLgF+koFgEXJ26\n/g7wHPA/KUNui4jZwBnAxyV1Ai8B02MPugXzkUceyeWXX85JJ53E5s2bGTBgAN/5zneoq6vj3HPP\nJSKQxJVXXgnAOeecw3nnnecL9WbWq3zre9/6Hui/521mO863vjczs17hUDEzs8I4VHrQ35YE+9v5\nmll5HCrdDBo0iI6Ojn7zhzYi6OjoYNCgQbUeipntAWr95cfdzsiRI2lvb2flypW1HkqvGTRoECNH\n9pu73ZhZiRwq3QwYMIBx48bVehhmZn2Sl7/MzKwwDhUzMyuMQ8XMzArjUDEzs8I4VMzMrDAOFTMz\nK4xDxczMCuNQMTOzwjhUzMysMA4VMzMrjEPFzMwK41AxM7PCOFTMzKwwDhUzMyuMQ8XMzApTaqhI\nmirpSUmtkmZtpc2ZklokLZZ0Q658tKQ7JS1J9WNT+ThJD6U+fyhpYCrfO+23pvqxZZ6bmZm9Vmmh\nIqkOmAOcAkwAZkia0K1NA3AZMCUiJgKfylVfB/xLRBwBHAOsSOVXAl+LiMOB1cC5qfxcYHUq/1pq\nZ2ZmvajMmcoxQGtEtEXEBuAmYFq3NucDcyJiNUBErABI4VMfEXel8vUR8X+SBJwA3JKOvxY4PW1P\nS/uk+hNTezMz6yVlhsoIYGluvz2V5Y0Hxkt6QNKDkqbmytdIuk3SryX9S5r5DAXWRERnD32+8n6p\nfm1qvwVJMyU1SWrqT8+hNzPrDbW+UF8PNADHAzOAqyUNSeVvBy4B/hw4FDi7iDeMiLkRUYmIyvDh\nw4vo0szMkjJDZRkwKrc/MpXltQONEbExIp4BniILmXagOS2ddQLzgclABzBEUn0Pfb7yfql+/9Te\nzMx6SZmhshBoSJ/WGghMBxq7tZlPNktB0jCyZa+2dOwQSV1TiROAlogI4B7gjFT+EeAnabsx7ZPq\n707tzcysl5QWKmmGcQGwAFgC3BwRiyXNlnRaarYA6JDUQhYWl0ZER0RsIlv6+oWkxwEBV6djPgNc\nLKmV7JrJNan8GmBoKr8Y6PEjzGZmVh7153/MVyqVaGpqqvUwzMz6FEmLIqLSU12tL9SbmdkexKFi\nZmaFcaiYmVlhHCpmZlYYh4qZmRXGoWJmZoVxqJiZWWEcKmZmVhiHipmZFcahYmZmhXGomJlZYRwq\nZmZWGIeKmZkVxqFiZmaFcaiYmVlhHCpmZlYYh4qZmRXGoWJmZoVxqJiZWWEcKmZmVphSQ0XSVElP\nSmqVNGsrbc6U1CJpsaQbcuWbJDWnV2Ou/P5c+e8kzU/lx0tam6v7XJnnZmZmr1VfVseS6oA5wLuA\ndmChpMaIaMm1aQAuA6ZExGpJB+W6eCkiJnXvNyLenjv+VuAnuer7I+K9BZ+KmZlVqcyZyjFAa0S0\nRcQG4CZgWrc25wNzImI1QESsqLZzSfsBJwDzCxqvmZntojJDZQSwNLffnsryxgPjJT0g6UFJU3N1\ngyQ1pfLTe+j/dOAXEbEuV3aspEcl3SFpYiFnYWZmVStt+WsH3r8BOB4YCdwn6ciIWAOMiYhlkg4F\n7pb0eET8NnfsDOC7uf1H0jHrJZ1KNoNp6P6GkmYCMwFGjx5dxjmZmfVb252pSPqkpAN2ou9lwKjc\n/shUltcONEbExoh4BniKFAQRsSz9bAPuBY7OjWkY2fLaf3WVRcS6iFiftm8HBqR2W4iIuRFRiYjK\n8OHDd+K0zMxsa6pZ/jqY7CL7zenTXKqy74VAg6RxkgYC04HGbm3mk81SuoJiPNAm6QBJe+fKpwAt\nuePOAP4zIl7uKpB0SNfYJB2Tzq2jyrGamVkBthsqEfFZstnDNcDZwNOSvizpsO0c1wlcACwAlgA3\nR8RiSbMlnZaaLQA6JLUA9wCXRkQHcATQJOnRVH5F/lNjZAF1Y7e3PAN4Ih3zTWB6RMT2zs/MzIqj\nav/uSjoKOAeYSvaH/q3AXRHx6fKGV65KpRJNTU21HoaZWZ8iaVFEVHqq2+6FekkXAR8GVpFdGL80\nIjZK2gt4GuizoWJmZsWq5tNfBwLvj4jn8oURsVmSv2hoZmavqOZC/R3A77t2JO0n6S0AEbGkrIGZ\nmVnfU02ofBtYn9tfn8rMzMy2UE2oKP8pqojYTO2/NGlmZruhakKlTdKFkgak10VAW9kDMzOzvqea\nUPkYcBzZt+HbgbeQbnNiZmaWt91lrHTn4Om9MBYzM+vjqvmeyiDgXGAiMKirPCI+WuK4zMysD6pm\n+ev7wCHAu4H/Jrsx5ItlDsrMzPqmakLl8Ij4R+APEXEt8B6y6ypmZmZbqCZUNqafayT9KbA/cNA2\n2puZWT9VzfdN5qbnqXyW7Nb1+wD/WOqozMysT9pmqKSbRq5Lz5C/Dzi0V0ZlZmZ90jaXv9K3530X\nYjMzq0o111R+LukSSaMkHdj1Kn1kZmbW51RzTeWD6ecncmWBl8LMzKybar5RP643BmJmZn1fNd+o\n/3BP5RFxXfHDMTOzvqya5a8/z20PAk4EHgEcKmZmtoVqlr8+md+XNAS4qbQRmZlZn1XNp7+6+wNQ\n1XUWSVMlPSmpVdKsrbQ5U1KLpMWSbsiVb5LUnF6NufL/kPRMrm5SKpekb6b3ekzS5J04NzMz2wXV\nXFP5KdmnvSALoQnAzVUcVwfMAd5F9hyWhZIaI6Il16YBuAyYEhGrJeVv//JSREzaSveXRsQt3cpO\nARrS6y1kjzz2PcrMzHpRNddUvpLb7gSei4j2Ko47BmiNiDYASTcB04CWXJvzgTnpG/tdz27ZWdOA\n69Kjjx+UNETSGyJi+S70aWZmO6Ca5a/ngYci4r8j4gGgQ9LYKo4bASzN7bensrzxwHhJD0h6UNLU\nXN0gSU2p/PRux30pLXF9TdLeO/B+SJqZ+m1auXJlFadhZmbVqiZUfgRszu1vSmVFqCdbrjoemAFc\nnT4IADAmIirAXwFfl3RYKr8MeBPZp9IOBD6zI28YEXMjohIRleHDhxdwCmZm1qWaUKmPiA1dO2l7\nYBXHLQNG5fZHprK8dqAxIjZGxDPAU2QhQ0QsSz/bgHuBo9P+8sj8Efge2TJbte9nZmYlqiZUVko6\nrWtH0jRgVRXHLQQaJI2TNJDsOfeN3drMJ5ulIGkY2XJYm6QDupa1UvkU0rUYSW9IPwWcDjyR+moE\nPpw+BfZWYK2vp5iZ9a5qLtR/DLhe0lVpvx3o8Vv2eRHRKekCYAFQB8yLiMWSZgNNEdGY6k6W1EK2\nrHZpRHRIOg74d0mbyYLvitynxq6XNBwQ0JzGB3A7cCrQCvwfcE4V52ZmZgVS9mGpKhpK+wBExPpS\nR9SLKpVKNDU11XoYZmZ9iqRF6Zr3a2x3+UvSlyUNiYj1EbE+LU19sfhhmplZX1fNNZVTImJN1076\nTsmp5Q3JzMz6qmpCpS73XRAkDQb23kZ7MzPrp6q5UH898AtJ3yO7OH42cG2ZgzIzs76pmrsUXynp\nUeAksnuALQDGlD0wMzPre6q9S/H/kgXKB4ATgCWljcjMzPqsrc5UJI0nu3XKDLIvO/6Q7CPI7+yl\nsZmZWR+zreWv3wD3A++NiFYASX/XK6MyM7M+aVvLX+8HlgP3SLpa0olkF+rNzMx6tNVQiYj5ETGd\n7I7A9wCfAg6S9G1JJ/fWAM3MrO/Y7oX6iPhDRNwQEe8ju/Pvr9nB282bmVn/sEPPqI+I1el5JCeW\nNSAzM+u7dihUzMzMtsWhYmZmhXGomJlZYRwqZmZWGIeKmZkVxqFiZmaFcaiYmVlhHCpmZlaYUkNF\n0lRJT0pqlTRrK23OlNQiabGkG3LlmyQ1p1djrvz61OcTkuZJGpDKj5e0NnfM58o8NzMze61qnvy4\nUyTVAXOAdwHtwEJJjRHRkmvTAFwGTImI1ZIOynXxUkRM6qHr64Gz0vYNwHnAt9P+/RHx3oJPxczM\nqlTmTOUYoDUi2iJiA3ATMK1bm/OBORGxGiAiVmyv04i4PRLgYbL7kZmZ2W6gzFAZASzN7bensrzx\nwHhJD0h6UNLUXN0gSU2p/PTunadlr78GfpYrPlbSo5LukDSxoPMwM7Mqlbb8tQPv3wAcTzbjuE/S\nkRGxBhgTEcskHQrcLenxiPht7th/A+6LiPvT/iPpmPWSTgXmp763IGkmMBNg9OjRZZ2XmVm/VOZM\nZRkwKrc/MpXltQONEbExIp4BniIFQUQsSz/bgHuBo7sOknQ5MBy4uKssItZFxPq0fTswQNKw7oNK\nd1muRERl+PDhu3ySZmb2qjJDZSHQIGmcpIHAdKCxW5v5ZLMUUgCMB9okHSBp71z5FKAl7Z8HvBuY\nERGbuzqSdIgkpe1j0rl1lHd6ZmbWXWnLXxHRKekCYAFQB8yLiMWSZgNNEdGY6k6W1AJsAi6NiA5J\nxwH/LmkzWThckfvU2HeA54D/SRlyW0TMBs4APi6pE3gJmJ4u5puZWS9Rf/67W6lUoqmpqdbDMDPr\nUyQtiohKT3X+Rr2ZmRXGoWJmZoVxqJiZWWEcKmZmVhiHipmZFcahYmZmhXGomJlZYRwqZmZWGIeK\nmZkVxqFiZmaFcaiYmVlhHCpmZlYYh4qZmRXGoWJmZoVxqJiZWWEcKmZmVhiHipmZFcahYmZmhXGo\nmJlZYRwqZmZWGIeKmZkVptRQkTRV0pOSWiXN2kqbMyW1SFos6YZc+SZJzenVmCsfJ+mh1OcPJQ1M\n5Xun/dZUP7bMczMzs9cqLVQk1QFzgFOACcAMSRO6tWkALgOmRMRE4FO56pciYlJ6nZYrvxL4WkQc\nDqwGzk3l5wKrU/nXUjszM+tFZc5UjgFaI6ItIjYANwHTurU5H5gTEasBImLFtjqUJOAE4JZUdC1w\netqelvZJ9Sem9mZm1kvKDJURwNLcfnsqyxsPjJf0gKQHJU3N1Q2S1JTKu4JjKLAmIjp76POV90v1\na1P7LUiamfptWrly5a6cn5mZdVO/G7x/A3A8MBK4T9KREbEGGBMRyyQdCtwt6XGyoNglETEXmAtQ\nqVRiV/szM7NXlTlTWQaMyu2PTGV57UBjRGyMiGeAp8hChohYln62AfcCRwMdwBBJ9T30+cr7pfr9\nU3szM+slZYbKQqAhfVprIDAdaOzWZj7ZLAVJw8iWw9okHSBp71z5FKAlIgK4BzgjHf8R4CdpuzHt\nk+rvTu3NzKyXlBYq6brGBcACYAlwc0QsljRbUtenuRYAHZJayMLi0ojoAI4AmiQ9msqviIiWdMxn\ngIsltZJdM7kmlV8DDE3lFwM9foTZzMzKo/78j/lKpRJNTU21HoaZWZ8iaVFEVHqq8zfqzcysMA4V\nMzMrjEPFzMwK41AxM7PCOFTMzKwwDhUzMyuMQ8XMzArjUDEzs8I4VMzMrDAOFTMzK4xDxczMCuNQ\nMTOzwjhUzMysMA4VMzMrjEPFzMwK41AxM7PCOFTMzKwwDhUzMyuMQ8XMzArjUDEzs8KUGiqSpkp6\nUlKrpFlbaXOmpBZJiyXd0K1uP0ntkq5K+/tKas69Vkn6eqo7W9LKXN15ZZ6bmZm9Vn1ZHUuqA+YA\n7wLagYWSGiOiJdemAbgMmBIRqyUd1K2bLwD3de1ExIvApNzxi4Dbcu1/GBEXFH4yZmZWlTJnKscA\nrRHRFhEbgJuAad3anA/MiYjVABGxoqtC0puBg4E7e+pc0njgIOD+EsZuZmY7ocxQGQEsze23p7K8\n8cB4SQ9IelDSVABJewFfBS7ZRv/TyWYmkSv7S0mPSbpF0qieDpI0U1KTpKaVK1fu6DmZmdk21PpC\nfT3QABwPzACuljQE+Fvg9oho38ax04Ebc/s/BcZGxJ8BdwHX9nRQRMyNiEpEVIYPH17AKZiZWZfS\nrqkAy4D8bGFkKstrBx6KiI3AM5KeIguZY4G3S/pbYB9goKT1ETELQNJRQH1ELOrqKCI6cv1+F/jn\nok+oyz/9dDEtv1tXVvdmZqWb8Mb9uPx9Ewvvt8yZykKgQdI4SQPJZhaN3drMJ5ulIGkY2XJYW0R8\nKCJGR8RYsiWw67oCJZnBlrMUJL0ht3sasKTAczEzsyqUNlOJiE5JFwALgDpgXkQsljQbaIqIxlR3\nsqQWYBNwabcZx9acCZzarexCSacBncDvgbMLOpXXKCPdzcz2BNryOnf/UqlUoqmpqdbDMDPrUyQt\niohKT3W1vlBvZmZ7EIeKmZkVxqFiZmaFcaiYmVlhHCpmZlYYh4qZmRXGoWJmZoXp199TkbQSeG4n\nDx8GrCpwOH2dfx9b8u/jVf5dbGlP+H2MiYgeb57Yr0NlV0hq2tqXf/oj/z625N/Hq/y72NKe/vvw\n8peZmRXGoWJmZoVxqOy8ubUewG7Gv48t+ffxKv8utrRH/z58TcXMzArjmYqZmRXGoWJmZoVxqOwE\nSVMlPSmpVdKs7R+x55I0StI9klokLZZ0Ua3HVGuS6iT9WtJ/1nostSZpiKRbJP1G0hJJx9Z6TLUi\n6e/SfyNPSLpR0qBaj6kMDpUdJKkOmAOcAkwAZkiaUNtR1VQn8PcRMQF4K/CJfv77ALgIP866yzeA\nn0XEm4Cj6Ke/F0kjgAuBSkT8KdnTcKfXdlTlcKjsuGOA1ohoi4gNwE3AtBqPqWYiYnlEPJK2XyT7\nozGitqOqHUkjgfcA3631WGpN0v7AXwDXAETEhohYU9tR1VQ9MFhSPfA64Hc1Hk8pHCo7bgSwNLff\nTj/+I5onaSxwNPBQbUdSU18HPg1srvVAdgPjgJXA99Jy4Hclvb7Wg6qFiFgGfAV4HlgOrI2IO2s7\nqnI4VKwQkvYBbgU+FRHraj2eWpD0XmBFRCyq9Vh2E/XAZODbEXE08AegX16DlHQA2YrGOOCNwOsl\nnVXbUZXDobLjlgGjcvsjU1m/JWkAWaBcHxG31Xo8NTQFOE3Ss2TLoidI+kFth1RT7UB7RHTNXG8h\nC5n+6CTgmYhYGREbgduA42o8plI4VHbcQqBB0jhJA8kutjXWeEw1I0lka+ZLIuJfaz2eWoqIyyJi\nZESMJfv/xd0RsUf+a7QaEfECsFTSn6SiE4GWGg6plp4H3irpdem/mRPZQz+0UF/rAfQ1EdEp6QJg\nAdknOOZFxOIaD6uWpgB/DTwuqTmV/UNE3F7DMdnu45PA9ekfYG3AOTUeT01ExEOSbgEeIfvE5K/Z\nQ2/X4tu0mJlZYbz8ZWZmhXGomJlZYRwqZmZWGIeKmZkVxqFiZmaFcaiYlUjSJknNuVdh3yiXNFbS\nE0X1Z1YEf0/FrFwvRcSkWg/CrLd4pmJWA5KelfTPkh6X9LCkw1P5WEl3S3pM0i8kjU7lB0v6saRH\n06vrFh91kq5Oz+m4U9LgmjUKRLYAAAEtSURBVJ2UGQ4Vs7IN7rb89cFc3dqIOBK4iuzuxgDfAq6N\niD8Drge+mcq/Cfx3RBxFdv+srrs4NABzImIisAb4y5LPx2yb/I16sxJJWh8R+/RQ/ixwQkS0pRty\nvhARQyWtAt4QERtT+fKIGCZpJTAyIv6Y62MscFdENKT9zwADIuKL5Z+ZWc88UzGrndjK9o74Y257\nE75OajXmUDGrnQ/mfv5P2v4Vrz5m9kPA/Wn7F8DHIXukdXqqotlux/+qMSvX4NzdmyF7XnvXx4oP\nkPQY2WxjRir7JNmTEi8le2pi1119LwLmSjqXbEbycbInCJrtVnxNxawG0jWVSkSsqvVYzIrk5S8z\nMyuMZypmZlYYz1TMzKwwDhUzMyuMQ8XMzArjUDEzs8I4VMzMrDD/H6doJfFyQKV8AAAAAElFTkSu\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nazYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scdJmXM6k-aG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNEIpApN6dMf",
        "colab_type": "code",
        "outputId": "66f93136-1825-495f-88df-24b2c6fe7cab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "# embed_dim = 50 #Change to observe effects\n",
        "# lstm_out = 128 #Change to observe effects\n",
        "# batch_size = 32\n",
        "# num_classes = 4\n",
        "\n",
        "# inputs = Input((max_length_of_text, ))\n",
        "# x = Embedding(num_words, embed_dim)(inputs)  \n",
        "# x = LSTM(lstm_out)(x) \n",
        "# x = Dense(num_classes, activation='sigmoid')(x)\n",
        "# model = Model(inputs, x)\n",
        "# print(model.summary())\n",
        "\n",
        "##### Normal LSTM without embeddings\n",
        "\n",
        "modelNormal = Sequential()\n",
        "# # model.add(embedding_layer)####\n",
        "# inputs = Input((MAX_SEQUENCE_LENGTH, ))\n",
        "modelNormal.add(Embedding(len(word_index) + 1, EMBEDDING_DIM, input_length=X_proc.shape[1])) ##### making changes here maybe\n",
        "#model.add(SpatialDropout1D(0.2))\n",
        "#model.add((SimpleRNN(32,activation='relu',input_shape=(1,60))))\n",
        "#model.add(Flatten())\n",
        "#model.add(Dense(60,input_shape=(60,)))\n",
        "modeNormal.add((LSTM(200,kernel_initializer='zeros',activation='relu')))\n",
        "#model.add((LSTM(200,return_sequences=True,kernel_initializer='zeros',activation='relu')))\n",
        "#model.add(LSTM(200,kernel_initializer='zeros',activation='relu'))\n",
        "#model.add(Conv1D(512, 3, activation='relu'))\n",
        "#model.add(MaxPooling1D(5))\n",
        "#model.add(Conv1D(512, 3, activation='relu'))\n",
        "#model.add(MaxPooling1D(2))\n",
        "#model.add(Dense(128,activation='relu'))\n",
        "#model.add(Dense(64,activation='relu'))\n",
        "\n",
        "modelNormal.add(Flatten())\n",
        "modelNormal.add(Dense(64,activation='relu',kernel_initializer=keras.initializers.RandomUniform(minval=-0.05, maxval=0.05, seed=None)\n",
        ",bias_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)))\n",
        "modelNormal.add(Dense(4, activation='softmax'))\n",
        "print(modelNormal.summary())\n",
        "modelNormal.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(lr=0.01), metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-e208fa55fc27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#model.add(Flatten())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#model.add(Dense(60,input_shape=(60,)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodeNormal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'zeros'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m#model.add((LSTM(200,return_sequences=True,kernel_initializer='zeros',activation='relu')))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#model.add(LSTM(200,kernel_initializer='zeros',activation='relu'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'modeNormal' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnHMdK1D9HMz",
        "colab_type": "code",
        "outputId": "e9662248-ff09-476e-9df4-a14e2821a4a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        }
      },
      "source": [
        "historyNormal = modelNormal.fit(X_proc, Y_motivational, epochs=20, batch_size=32,validation_split=0.1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 5730 samples, validate on 637 samples\n",
            "Epoch 1/20\n",
            "5730/5730 [==============================] - 7s 1ms/step - loss: 0.7077 - acc: 0.6279 - val_loss: 0.6429 - val_acc: 0.6641\n",
            "Epoch 2/20\n",
            "5730/5730 [==============================] - 2s 316us/step - loss: 0.3861 - acc: 0.8293 - val_loss: 0.8993 - val_acc: 0.5306\n",
            "Epoch 3/20\n",
            "5730/5730 [==============================] - 2s 323us/step - loss: 0.1246 - acc: 0.9555 - val_loss: 1.3798 - val_acc: 0.5589\n",
            "Epoch 4/20\n",
            "5730/5730 [==============================] - 2s 306us/step - loss: 0.0512 - acc: 0.9817 - val_loss: 1.4502 - val_acc: 0.5667\n",
            "Epoch 5/20\n",
            "5730/5730 [==============================] - 2s 315us/step - loss: 0.0315 - acc: 0.9899 - val_loss: 1.9310 - val_acc: 0.5463\n",
            "Epoch 6/20\n",
            "5730/5730 [==============================] - 2s 313us/step - loss: 0.0177 - acc: 0.9928 - val_loss: 2.1030 - val_acc: 0.5526\n",
            "Epoch 7/20\n",
            "5730/5730 [==============================] - 2s 313us/step - loss: 0.0192 - acc: 0.9918 - val_loss: 2.5297 - val_acc: 0.5400\n",
            "Epoch 8/20\n",
            "5730/5730 [==============================] - 2s 315us/step - loss: 0.0190 - acc: 0.9916 - val_loss: 2.4204 - val_acc: 0.5212\n",
            "Epoch 9/20\n",
            "5730/5730 [==============================] - 2s 314us/step - loss: 0.0221 - acc: 0.9923 - val_loss: 2.7007 - val_acc: 0.5416\n",
            "Epoch 10/20\n",
            "5730/5730 [==============================] - 2s 310us/step - loss: 0.0331 - acc: 0.9899 - val_loss: 2.9527 - val_acc: 0.5887\n",
            "Epoch 11/20\n",
            "5730/5730 [==============================] - 2s 314us/step - loss: 0.0587 - acc: 0.9812 - val_loss: 2.1283 - val_acc: 0.5730\n",
            "Epoch 12/20\n",
            "5730/5730 [==============================] - 2s 307us/step - loss: 0.0538 - acc: 0.9832 - val_loss: 2.6676 - val_acc: 0.5620\n",
            "Epoch 13/20\n",
            "5730/5730 [==============================] - 2s 311us/step - loss: 0.0625 - acc: 0.9843 - val_loss: 4.7232 - val_acc: 0.4710\n",
            "Epoch 14/20\n",
            "5730/5730 [==============================] - 2s 316us/step - loss: 0.0572 - acc: 0.9867 - val_loss: 2.4804 - val_acc: 0.5981\n",
            "Epoch 15/20\n",
            "5730/5730 [==============================] - 2s 313us/step - loss: 0.0686 - acc: 0.9846 - val_loss: 4.1726 - val_acc: 0.6044\n",
            "Epoch 16/20\n",
            "5730/5730 [==============================] - 2s 313us/step - loss: 0.1250 - acc: 0.9602 - val_loss: 2.5067 - val_acc: 0.5259\n",
            "Epoch 17/20\n",
            "5730/5730 [==============================] - 2s 304us/step - loss: 0.0557 - acc: 0.9862 - val_loss: 2.4377 - val_acc: 0.5573\n",
            "Epoch 18/20\n",
            "5730/5730 [==============================] - 2s 305us/step - loss: 0.0391 - acc: 0.9899 - val_loss: 3.0590 - val_acc: 0.5746\n",
            "Epoch 19/20\n",
            "5730/5730 [==============================] - 2s 309us/step - loss: 0.0310 - acc: 0.9906 - val_loss: 3.4494 - val_acc: 0.5432\n",
            "Epoch 20/20\n",
            "5730/5730 [==============================] - 2s 309us/step - loss: 0.0222 - acc: 0.9925 - val_loss: 3.6174 - val_acc: 0.5463\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaupcrJQ9HVs",
        "colab_type": "code",
        "outputId": "7d13fbbc-8e8a-4e09-a371-e3cffd5f3e9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.plot(historyNormal.history['acc'])\n",
        "plt.plot(historyNormal.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(historyNormal.history['loss'])\n",
        "plt.plot(historyNormal.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFLLJkN2YRgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEWCAYAAABsY4yMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJnillEpSmuCVUipJaYJXSqkk9f8Bgzg5NPP7t1EAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_58Lp2mQhmR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x1 = model.layers[2].get_weights()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbDyagQ3Mkz5",
        "colab_type": "code",
        "outputId": "b0a92af2-594f-4dbc-d50d-72eac16e74df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 924
        }
      },
      "source": [
        "x2 = model.layers[2].get_weights()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-0.02818851,  0.04366925,  0.00087268, ...,  0.01177585,\n",
              "         -0.02906323, -0.04296286],\n",
              "        [-0.03472773,  0.00306273, -0.02614651, ...,  0.04116422,\n",
              "         -0.00804956, -0.00205766],\n",
              "        [-0.02779009, -0.01088719,  0.00277435, ..., -0.03548681,\n",
              "          0.01593403, -0.01989742],\n",
              "        ...,\n",
              "        [ 0.00334866, -0.0237309 , -0.00272692, ...,  0.00291566,\n",
              "         -0.01399468, -0.0362225 ],\n",
              "        [ 0.02953343,  0.04819537, -0.00152519, ..., -0.04667242,\n",
              "         -0.04539862, -0.02649623],\n",
              "        [ 0.0065194 , -0.00587861, -0.01335849, ..., -0.04994297,\n",
              "         -0.0333499 , -0.01672566]], dtype=float32),\n",
              " array([-0.04956612, -0.0402556 , -0.05505383, -0.00545066, -0.0463523 ,\n",
              "        -0.02841845,  0.01805037, -0.07546956, -0.03774472,  0.04110087,\n",
              "         0.04255107, -0.02478768,  0.01599017, -0.04456089,  0.06721716,\n",
              "        -0.03220953,  0.00611401, -0.01598294, -0.03382299,  0.01565853,\n",
              "        -0.01582068, -0.01310624,  0.01470552, -0.02864268, -0.06125559,\n",
              "        -0.01081976,  0.03157264,  0.02913095,  0.08285475,  0.02129709,\n",
              "         0.04194685, -0.01925955,  0.077682  ,  0.06395016,  0.05959034,\n",
              "         0.02263702,  0.00109144,  0.05808025, -0.00481156,  0.00700956,\n",
              "        -0.08762762, -0.02586557,  0.02067765,  0.02772327,  0.05826428,\n",
              "         0.01056045, -0.0100116 , -0.05700082,  0.0245717 ,  0.03273551,\n",
              "         0.07611533, -0.00372039, -0.1079906 ,  0.06774288, -0.0047628 ,\n",
              "        -0.08484612, -0.0102667 , -0.028674  ,  0.11504464, -0.01998243,\n",
              "         0.02713398, -0.12821071,  0.01070799,  0.06036782,  0.02082178,\n",
              "        -0.01189714,  0.00884466, -0.04580642,  0.0432912 ,  0.00343297,\n",
              "        -0.0758163 ,  0.13065322, -0.0413221 ,  0.00401318, -0.0139066 ,\n",
              "         0.00128672,  0.02022922, -0.08142634,  0.00987467,  0.07539951,\n",
              "         0.03182271, -0.00369978, -0.0210331 , -0.05093307, -0.0189785 ,\n",
              "         0.05813606, -0.00992818,  0.03674283,  0.03160223, -0.07674259,\n",
              "        -0.06334029, -0.01692847, -0.02027879, -0.07736728,  0.07686443,\n",
              "         0.02125955,  0.03550117, -0.00095876,  0.02416366, -0.05186531,\n",
              "        -0.03768386, -0.00483389,  0.00111024, -0.02113515,  0.02330207,\n",
              "        -0.01386666,  0.00327906, -0.06995343, -0.02891136,  0.00413013,\n",
              "        -0.06356315, -0.0487164 ,  0.14719018,  0.00850624, -0.04453911,\n",
              "        -0.00462075,  0.01744447, -0.01353112,  0.0561464 , -0.02204335,\n",
              "         0.03521477, -0.02599419, -0.05956752, -0.0016558 , -0.00214155,\n",
              "        -0.05223183,  0.04900231,  0.05766333,  0.06675652, -0.05936545,\n",
              "         0.02918772,  0.01093269,  0.07878704,  0.06475033,  0.02481355,\n",
              "        -0.02236977, -0.01652069,  0.02443614,  0.12684615,  0.00376507,\n",
              "        -0.06045924, -0.07904527,  0.0083085 ,  0.0441254 , -0.01500721,\n",
              "        -0.00867234,  0.03352712, -0.05601105, -0.04187812,  0.02786619,\n",
              "        -0.01070184, -0.0611965 , -0.1088532 ,  0.01102639, -0.02772677,\n",
              "        -0.0263074 , -0.00130205,  0.0711083 , -0.06021082,  0.01320638,\n",
              "        -0.02236899,  0.01677961,  0.07331258,  0.06220472, -0.00284121,\n",
              "        -0.02626321,  0.03024024, -0.01369155,  0.00408088,  0.01794024,\n",
              "         0.01986603,  0.08538572, -0.03759415,  0.0472195 ,  0.05847256,\n",
              "         0.14383312,  0.05906532,  0.04891326, -0.04885627, -0.04654073,\n",
              "        -0.02034046, -0.010532  ,  0.01539643,  0.11286273, -0.05828349,\n",
              "         0.06816757, -0.1303513 , -0.08740938,  0.02993548,  0.04345511,\n",
              "        -0.05294468, -0.00288254, -0.00201405, -0.02727906,  0.06927081,\n",
              "         0.03305411,  0.04690878,  0.05611586,  0.00629274,  0.00817955],\n",
              "       dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgWrABBQP-8b",
        "colab_type": "code",
        "outputId": "7f482876-526a-4590-c778-9efe5951f8f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "import keras.backend as K\n",
        "fn = K.function([X_proc], K.gradients(Y_offensive, [X_proc]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-3fb7fa218d2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_proc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_offensive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mX_proc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(inputs, outputs, updates, **kwargs)\u001b[0m\n\u001b[1;32m   3008\u001b[0m                 raise ValueError('Invalid argument \"%s\" passed to K.function '\n\u001b[1;32m   3009\u001b[0m                                  'with TensorFlow backend' % key)\n\u001b[0;32m-> 3010\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, updates, name, **session_kwargs)\u001b[0m\n\u001b[1;32m   2806\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2807\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2808\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2809\u001b[0m             \u001b[0mupdates_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2810\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mupdate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mupdates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mcontrol_dependencies\u001b[0;34m(control_inputs)\u001b[0m\n\u001b[1;32m   5252\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mNullContextmanager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5253\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5254\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontrol_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mcontrol_dependencies\u001b[0;34m(self, control_inputs)\u001b[0m\n\u001b[1;32m   4686\u001b[0m           (hasattr(c, \"_handle\") and hasattr(c, \"op\"))):\n\u001b[1;32m   4687\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4688\u001b[0;31m       \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_graph_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4689\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4690\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3606\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3607\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3609\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3694\u001b[0m       \u001b[0;31m# We give up!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3695\u001b[0m       raise TypeError(\"Can not convert a %s into a %s.\" %\n\u001b[0;32m-> 3696\u001b[0;31m                       (type(obj).__name__, types_str))\n\u001b[0m\u001b[1;32m   3697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3698\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_operations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Can not convert a NoneType into a Tensor or Operation."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rpsx3T2NPzJ",
        "colab_type": "code",
        "outputId": "36e235a8-750a-4559-cb6c-ca80f98fd5b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "print(YTU[0:100])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjpTg0W0Gbc_",
        "colab_type": "code",
        "outputId": "12cd9a45-0e1e-4a6b-e015-987250d5981b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        }
      },
      "source": [
        "model2 = Sequential()\n",
        "model2.add(embedding_layer_2)#### model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X_proc.shape[1])) ##### making changes here maybe\n",
        "#model.add(SpatialDropout1D(0.2))\n",
        "#model.add((LSTM(200)))\n",
        "model2.add(Conv1D(256, 5, activation='relu'))\n",
        "#model.add(MaxPooling1D(5))\n",
        "model2.add(Conv1D(256, 5, activation='relu'))\n",
        "model2.add(MaxPooling1D(2))\n",
        "#model.add(Dense(128,activation='relu'))\n",
        "#model.add(Dense(64,activation='relu'))\n",
        "model2.add(Flatten())\n",
        "#model.add(Dense(32,activation='relu'))\n",
        "model2.add(Dense(5, activation='sigmoid'))\n",
        "print(model.summary())\n",
        "model2.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(lr=0.01), metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-7294f66d8021>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_layer_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#### model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X_proc.shape[1])) ##### making changes here maybe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#model.add(SpatialDropout1D(0.2))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#model.add((LSTM(200)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'embedding_layer_2' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xb_0i2veqeu",
        "colab_type": "code",
        "outputId": "8e34a467-e4ef-4c2b-ee54-63dffeff8c62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model2.fit(X_proc, Y_positive, epochs=40, batch_size=512,validation_split=0.1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 5730 samples, validate on 637 samples\n",
            "Epoch 1/40\n",
            "5730/5730 [==============================] - 0s 40us/step - loss: 1.2703 - acc: 0.4464 - val_loss: 1.2447 - val_acc: 0.4505\n",
            "Epoch 2/40\n",
            "5730/5730 [==============================] - 0s 36us/step - loss: 1.2703 - acc: 0.4464 - val_loss: 1.2447 - val_acc: 0.4505\n",
            "Epoch 3/40\n",
            "5730/5730 [==============================] - 0s 38us/step - loss: 1.2703 - acc: 0.4464 - val_loss: 1.2447 - val_acc: 0.4505\n",
            "Epoch 4/40\n",
            "5730/5730 [==============================] - 0s 37us/step - loss: 1.2704 - acc: 0.4464 - val_loss: 1.2449 - val_acc: 0.4505\n",
            "Epoch 5/40\n",
            "5730/5730 [==============================] - 0s 37us/step - loss: 1.2703 - acc: 0.4464 - val_loss: 1.2451 - val_acc: 0.4505\n",
            "Epoch 6/40\n",
            "5730/5730 [==============================] - 0s 38us/step - loss: 1.2703 - acc: 0.4464 - val_loss: 1.2451 - val_acc: 0.4505\n",
            "Epoch 7/40\n",
            "5730/5730 [==============================] - 0s 37us/step - loss: 1.2704 - acc: 0.4464 - val_loss: 1.2449 - val_acc: 0.4505\n",
            "Epoch 8/40\n",
            "5730/5730 [==============================] - 0s 37us/step - loss: 1.2703 - acc: 0.4464 - val_loss: 1.2448 - val_acc: 0.4505\n",
            "Epoch 9/40\n",
            "5730/5730 [==============================] - 0s 38us/step - loss: 1.2703 - acc: 0.4464 - val_loss: 1.2449 - val_acc: 0.4505\n",
            "Epoch 10/40\n",
            "5730/5730 [==============================] - 0s 36us/step - loss: 1.2704 - acc: 0.4464 - val_loss: 1.2448 - val_acc: 0.4505\n",
            "Epoch 11/40\n",
            "5730/5730 [==============================] - 0s 36us/step - loss: 1.2704 - acc: 0.4464 - val_loss: 1.2449 - val_acc: 0.4505\n",
            "Epoch 12/40\n",
            "5730/5730 [==============================] - 0s 36us/step - loss: 1.2704 - acc: 0.4464 - val_loss: 1.2447 - val_acc: 0.4505\n",
            "Epoch 13/40\n",
            "5730/5730 [==============================] - 0s 38us/step - loss: 1.2704 - acc: 0.4464 - val_loss: 1.2446 - val_acc: 0.4505\n",
            "Epoch 14/40\n",
            "5730/5730 [==============================] - 0s 37us/step - loss: 1.2704 - acc: 0.4464 - val_loss: 1.2448 - val_acc: 0.4505\n",
            "Epoch 15/40\n",
            "5730/5730 [==============================] - 0s 38us/step - loss: 1.2703 - acc: 0.4464 - val_loss: 1.2447 - val_acc: 0.4505\n",
            "Epoch 16/40\n",
            "5730/5730 [==============================] - 0s 36us/step - loss: 1.2704 - acc: 0.4464 - val_loss: 1.2445 - val_acc: 0.4505\n",
            "Epoch 17/40\n",
            "5730/5730 [==============================] - 0s 38us/step - loss: 1.2704 - acc: 0.4464 - val_loss: 1.2444 - val_acc: 0.4505\n",
            "Epoch 18/40\n",
            "5730/5730 [==============================] - 0s 37us/step - loss: 1.2703 - acc: 0.4464 - val_loss: 1.2447 - val_acc: 0.4505\n",
            "Epoch 19/40\n",
            "5730/5730 [==============================] - 0s 38us/step - loss: 1.2703 - acc: 0.4464 - val_loss: 1.2448 - val_acc: 0.4505\n",
            "Epoch 20/40\n",
            "5730/5730 [==============================] - 0s 37us/step - loss: 1.2703 - acc: 0.4464 - val_loss: 1.2450 - val_acc: 0.4505\n",
            "Epoch 21/40\n",
            "5730/5730 [==============================] - 0s 37us/step - loss: 1.2704 - acc: 0.4464 - val_loss: 1.2448 - val_acc: 0.4505\n",
            "Epoch 22/40\n",
            "5730/5730 [==============================] - 0s 37us/step - loss: 1.2703 - acc: 0.4464 - val_loss: 1.2446 - val_acc: 0.4505\n",
            "Epoch 23/40\n",
            "5730/5730 [==============================] - 0s 37us/step - loss: 1.2704 - acc: 0.4464 - val_loss: 1.2446 - val_acc: 0.4505\n",
            "Epoch 24/40\n",
            "5730/5730 [==============================] - 0s 37us/step - loss: 1.2703 - acc: 0.4464 - val_loss: 1.2443 - val_acc: 0.4505\n",
            "Epoch 25/40\n",
            "5730/5730 [==============================] - 0s 37us/step - loss: 1.2704 - acc: 0.4464 - val_loss: 1.2443 - val_acc: 0.4505\n",
            "Epoch 26/40\n",
            "5730/5730 [==============================] - 0s 36us/step - loss: 1.2703 - acc: 0.4464 - val_loss: 1.2443 - val_acc: 0.4505\n",
            "Epoch 27/40\n",
            "5730/5730 [==============================] - 0s 36us/step - loss: 1.2703 - acc: 0.4464 - val_loss: 1.2444 - val_acc: 0.4505\n",
            "Epoch 28/40\n",
            "5730/5730 [==============================] - 0s 37us/step - loss: 1.2703 - acc: 0.4464 - val_loss: 1.2445 - val_acc: 0.4505\n",
            "Epoch 29/40\n",
            "5730/5730 [==============================] - 0s 37us/step - loss: 1.2703 - acc: 0.4464 - val_loss: 1.2445 - val_acc: 0.4505\n",
            "Epoch 30/40\n",
            "5730/5730 [==============================] - 0s 36us/step - loss: 1.2703 - acc: 0.4464 - val_loss: 1.2446 - val_acc: 0.4505\n",
            "Epoch 31/40\n",
            "5730/5730 [==============================] - 0s 36us/step - loss: 1.2704 - acc: 0.4464 - val_loss: 1.2447 - val_acc: 0.4505\n",
            "Epoch 32/40\n",
            "5730/5730 [==============================] - 0s 37us/step - loss: 1.2703 - acc: 0.4464 - val_loss: 1.2444 - val_acc: 0.4505\n",
            "Epoch 33/40\n",
            "5730/5730 [==============================] - 0s 37us/step - loss: 1.2703 - acc: 0.4464 - val_loss: 1.2445 - val_acc: 0.4505\n",
            "Epoch 34/40\n",
            "5730/5730 [==============================] - 0s 38us/step - loss: 1.2703 - acc: 0.4464 - val_loss: 1.2448 - val_acc: 0.4505\n",
            "Epoch 35/40\n",
            "5730/5730 [==============================] - 0s 37us/step - loss: 1.2704 - acc: 0.4464 - val_loss: 1.2450 - val_acc: 0.4505\n",
            "Epoch 36/40\n",
            "5730/5730 [==============================] - 0s 37us/step - loss: 1.2703 - acc: 0.4464 - val_loss: 1.2449 - val_acc: 0.4505\n",
            "Epoch 37/40\n",
            "5730/5730 [==============================] - 0s 38us/step - loss: 1.2703 - acc: 0.4464 - val_loss: 1.2448 - val_acc: 0.4505\n",
            "Epoch 38/40\n",
            "5730/5730 [==============================] - 0s 36us/step - loss: 1.2704 - acc: 0.4464 - val_loss: 1.2448 - val_acc: 0.4505\n",
            "Epoch 39/40\n",
            "5730/5730 [==============================] - 0s 37us/step - loss: 1.2703 - acc: 0.4464 - val_loss: 1.2449 - val_acc: 0.4505\n",
            "Epoch 40/40\n",
            "5730/5730 [==============================] - 0s 36us/step - loss: 1.2704 - acc: 0.4464 - val_loss: 1.2446 - val_acc: 0.4505\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb5b06652b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 427
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtvxWjyyj1vF",
        "colab_type": "code",
        "outputId": "454e1c04-7720-488d-bbb4-f5499ca73283",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "img_dir = \"/content/drive/My Drive/NNFL Fall'19 Project/data_7000\"\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "        dataframe=data,\n",
        "        directory=img_dir,\n",
        "        x_col=\"MEME Name\",\n",
        "        y_col=\"Sentiment_Offensive\",\n",
        "        target_size=(224, 224),\n",
        "        batch_size=512,\n",
        "        class_mode='categorical')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6366 validated image filenames belonging to 4 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/dataframe_iterator.py:273: UserWarning: Found 1 invalid image filename(s) in x_col=\"MEME Name\". These filename(s) will be ignored.\n",
            "  .format(n_invalid, x_col)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrRKNqLymFJQ",
        "colab_type": "code",
        "outputId": "3c2072b6-38ae-4ac5-d7f0-10340182a85f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "resnet = ResNet50V2(weights='imagenet')\n",
        "#resnet.trainable = False\n",
        "#resnet.layers.pop()\n",
        "#resnet.compile(optimizer='Adam',loss='categorical_crossentropy')\n",
        "#cnn_model = resnet.layers[-1].output\n",
        "#cnn_model.summary()\n",
        "for layer in resnet.layers[:-1]:\n",
        "  layer.trainable=False\n",
        "\n",
        "#cnn_model.add(ResNet50V2(weights='imagenet'))\n",
        "#cnn_model = cnn_model.layers[-1]\n",
        "temp1 = Dense(128,activation='relu')(resnet.layers[-2].output)\n",
        "temp2 = Dense(64,activation='relu')(temp1)\n",
        "predictions = Dense(4, activation= 'softmax')(temp2)\n",
        "img_model = Model(inputs = resnet.input, outputs = predictions)\n",
        "img_model.summary()\n",
        "#print(cnn_model.summary())\n",
        "#img_model = Dense(2,activation='sigmoid')(cnn_model)\n",
        "#cnn_model = Dense(4, activation='sigmoid')(resnet)\n",
        "#img_model.summary(img_model.summary()\n",
        "#resnet.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels.h5\n",
            "102875136/102869336 [==============================] - 8s 0us/step\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_preact_bn (BatchNo (None, 56, 56, 64)   256         pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_preact_relu (Activ (None, 56, 56, 64)   0           conv2_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4096        conv2_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_pad (ZeroPadding (None, 58, 58, 64)   0           conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36864       conv2_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Add)          (None, 56, 56, 256)  0           conv2_block1_0_conv[0][0]        \n",
            "                                                                 conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_preact_bn (BatchNo (None, 56, 56, 256)  1024        conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_preact_relu (Activ (None, 56, 56, 256)  0           conv2_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16384       conv2_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_pad (ZeroPadding (None, 58, 58, 64)   0           conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36864       conv2_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_preact_bn (BatchNo (None, 56, 56, 256)  1024        conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_preact_relu (Activ (None, 56, 56, 256)  0           conv2_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16384       conv2_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_pad (ZeroPadding (None, 58, 58, 64)   0           conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 28, 28, 64)   36864       conv2_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 28, 28, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 28, 28, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 28, 28, 256)  0           conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 28, 28, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Add)          (None, 28, 28, 256)  0           max_pooling2d_1[0][0]            \n",
            "                                                                 conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_preact_bn (BatchNo (None, 28, 28, 256)  1024        conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_preact_relu (Activ (None, 28, 28, 256)  0           conv3_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32768       conv3_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147456      conv3_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv3_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Add)          (None, 28, 28, 512)  0           conv3_block1_0_conv[0][0]        \n",
            "                                                                 conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_preact_bn (BatchNo (None, 28, 28, 512)  2048        conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_preact_relu (Activ (None, 28, 28, 512)  0           conv3_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65536       conv3_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147456      conv3_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_preact_bn (BatchNo (None, 28, 28, 512)  2048        conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_preact_relu (Activ (None, 28, 28, 512)  0           conv3_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65536       conv3_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147456      conv3_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_preact_bn (BatchNo (None, 28, 28, 512)  2048        conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_preact_relu (Activ (None, 28, 28, 512)  0           conv3_block4_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65536       conv3_block4_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 14, 14, 128)  147456      conv3_block4_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 14, 14, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 14, 14, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 512)  0           conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 14, 14, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Add)          (None, 14, 14, 512)  0           max_pooling2d_2[0][0]            \n",
            "                                                                 conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_preact_bn (BatchNo (None, 14, 14, 512)  2048        conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_preact_relu (Activ (None, 14, 14, 512)  0           conv4_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131072      conv4_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv4_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_conv[0][0]        \n",
            "                                                                 conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block4_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block4_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block4_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block5_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block5_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block5_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block6_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block6_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 7, 7, 256)    589824      conv4_block6_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 7, 7, 256)    0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 7, 7, 1024)   0           conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Add)          (None, 7, 7, 1024)   0           max_pooling2d_3[0][0]            \n",
            "                                                                 conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_preact_bn (BatchNo (None, 7, 7, 1024)   4096        conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_preact_relu (Activ (None, 7, 7, 1024)   0           conv5_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524288      conv5_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv5_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_conv[0][0]        \n",
            "                                                                 conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_preact_bn (BatchNo (None, 7, 7, 2048)   8192        conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_preact_relu (Activ (None, 7, 7, 2048)   0           conv5_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1048576     conv5_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_preact_bn (BatchNo (None, 7, 7, 2048)   8192        conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_preact_relu (Activ (None, 7, 7, 2048)   0           conv5_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1048576     conv5_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "post_bn (BatchNormalization)    (None, 7, 7, 2048)   8192        conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "post_relu (Activation)          (None, 7, 7, 2048)   0           post_bn[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (GlobalAveragePooling2 (None, 2048)         0           post_relu[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 128)          262272      avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 64)           8256        dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 4)            260         dense_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 23,835,588\n",
            "Trainable params: 270,788\n",
            "Non-trainable params: 23,564,800\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAyg-cswlUmf",
        "colab_type": "code",
        "outputId": "925c80a9-4a6c-4abc-9139-4537eb9b7121",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kj36wprN1p7c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(), metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VjW6bFkk98A",
        "colab_type": "code",
        "outputId": "69dfde0f-fd1f-4a52-e8a4-e6823dfa7a11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 749
        }
      },
      "source": [
        "img_model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=10,\n",
        "        epochs=2\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py:610: UserWarning: The input 5 could not be retrieved. It could be because a worker has died.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 1/10 [==>...........................] - ETA: 30:26 - loss: 1.4367 - acc: 0.2676"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py:610: UserWarning: The input 9 could not be retrieved. It could be because a worker has died.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 2/10 [=====>........................] - ETA: 24:18 - loss: 1.3848 - acc: 0.3457"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py:610: UserWarning: The input 12 could not be retrieved. It could be because a worker has died.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 3/10 [========>.....................] - ETA: 17:09 - loss: 1.3550 - acc: 0.3581"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py:610: UserWarning: The input 7 could not be retrieved. It could be because a worker has died.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:914: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  'to RGBA images')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 4/10 [===========>..................] - ETA: 15:51 - loss: 1.3814 - acc: 0.3423"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py:610: UserWarning: The input 3 could not be retrieved. It could be because a worker has died.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 5/10 [==============>...............] - ETA: 14:01 - loss: 1.3817 - acc: 0.3481"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:742: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py:610: UserWarning: The input 4 could not be retrieved. It could be because a worker has died.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    602\u001b[0m                     \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m                     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_success\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTimeoutError\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-124-31f2c0d8f08b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m         \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1656\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1658\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    609\u001b[0m                         \u001b[0;34m' It could be because a worker has died.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m                         UserWarning)\n\u001b[0;32m--> 611\u001b[0;31m                     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     63\u001b[0m         index_array = self.index_array[self.batch_size * idx:\n\u001b[1;32m     64\u001b[0m                                        self.batch_size * (idx + 1)]\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[0;34m(self, index_array)\u001b[0m\n\u001b[1;32m    228\u001b[0m                            \u001b[0mcolor_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolor_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                            \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                            interpolation=self.interpolation)\n\u001b[0m\u001b[1;32m    231\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;31m# Pillow images should be closed after `load_img`,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    108\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    109\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'L'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2529\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2530\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2531\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Us7dYN3mDcH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Sgd8nOZsgQs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVG2df3Ewdx0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import os\n",
        "import skimage\n",
        "from keras.models import load_model\n",
        "from keras.models import model_from_json \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwmKX_4TXrmS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data1 = pd.read_csv(\"/content/drive/My Drive/data_7000_new.csv\")\n",
        "# data1['Sentiment_Positive'][669] = 'positive'\n",
        "data1.dropna(inplace=True)\n",
        "# data2 = pd.read_csv(\"/home/nahush/Desktop/nnfl-assignment-i/test_data_file_id.csv\")\n",
        "# t = cv2.imread('./data/final_train/682.jpg')\n",
        "data1.columns = [\"MEME Name\", \"URL\", \"Text1\", \"Text2\", \"Sentiment_Humour\", \"Sentiment_General\",\"Sentiment_Offensive\",\"Sentiment_Motivational\",\"Sentiment_Positive\"]\n",
        "data1['Sentiment_Positive'][669] = 'positive'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlfWoMyqXw92",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load data\n",
        "\n",
        "nums = re.compile(r'(\\d+)')\n",
        "def key(value):\n",
        "    parts = nums.split(value)\n",
        "    parts[1::2] = map(int, parts[1::2])\n",
        "    return parts\n",
        "\n",
        "\n",
        "names = data1['MEME Name']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rf8F32zsX68H",
        "colab_type": "code",
        "outputId": "dcc27bc3-a7c5-49aa-ab2d-918d47b74b8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(names)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6367"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHq-db6NpLTI",
        "colab_type": "code",
        "outputId": "dc35c3a3-a45a-4a65-931a-cf00bd9c6573",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "\n",
        "# for i in trainingImages:\n",
        "#     j = skimage.transform.rescale(i, 0.25, anti_aliasing = True)\n",
        "#     trainingImages1.append(j.astype('float32') / 255.)\n",
        "\n",
        "#test_path = './data/final_test'\n",
        "trainingImages1 = []\n",
        "y_train = []\n",
        "c=0\n",
        "for i in sorted(os.listdir(\"/content/drive/My Drive/NNFL Fall'19 Project/data_7000/\"), key=key):\n",
        "#     print(i)\n",
        "    if i in names.values:\n",
        "        imgFile=\"/content/drive/My Drive/NNFL Fall'19 Project/data_7000/\"+i\n",
        "        img = cv2.imread(imgFile)\n",
        "        if img is not None:\n",
        "            print(c)\n",
        "            c+=1\n",
        "    #         print(imgFile)\n",
        "    #         img = cv2.imread(imgFile)\n",
        "    #         print(img.shape)\n",
        "            img = cv2.resize(img,(224,224))\n",
        "    #         print(img.shape)\n",
        "        #     print(type(img))\n",
        "            img = img.astype('float32')\n",
        "    #         print(type(img))\n",
        "            trainingImages1.append(img/255.)\n",
        "            y_train2 = data1.loc[data1['MEME Name'] == i]\n",
        "            y_train2 = y_train2['Sentiment_Positive'].values[0]\n",
        "            y_train.append(y_train2)\n",
        "# x_train = np.asarray(trainingImages1)\n",
        "        \n",
        "# y_train = df.loc[df['MEME_Name'].isin(x_train)]\n",
        "# y_train = y_train['Sentiment_Offensive']\n",
        "# y_train = y_train.to_numpy() \n",
        "\n",
        "# print(y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "234\n",
            "235\n",
            "236\n",
            "237\n",
            "238\n",
            "239\n",
            "240\n",
            "241\n",
            "242\n",
            "243\n",
            "244\n",
            "245\n",
            "246\n",
            "247\n",
            "248\n",
            "249\n",
            "250\n",
            "251\n",
            "252\n",
            "253\n",
            "254\n",
            "255\n",
            "256\n",
            "257\n",
            "258\n",
            "259\n",
            "260\n",
            "261\n",
            "262\n",
            "263\n",
            "264\n",
            "265\n",
            "266\n",
            "267\n",
            "268\n",
            "269\n",
            "270\n",
            "271\n",
            "272\n",
            "273\n",
            "274\n",
            "275\n",
            "276\n",
            "277\n",
            "278\n",
            "279\n",
            "280\n",
            "281\n",
            "282\n",
            "283\n",
            "284\n",
            "285\n",
            "286\n",
            "287\n",
            "288\n",
            "289\n",
            "290\n",
            "291\n",
            "292\n",
            "293\n",
            "294\n",
            "295\n",
            "296\n",
            "297\n",
            "298\n",
            "299\n",
            "300\n",
            "301\n",
            "302\n",
            "303\n",
            "304\n",
            "305\n",
            "306\n",
            "307\n",
            "308\n",
            "309\n",
            "310\n",
            "311\n",
            "312\n",
            "313\n",
            "314\n",
            "315\n",
            "316\n",
            "317\n",
            "318\n",
            "319\n",
            "320\n",
            "321\n",
            "322\n",
            "323\n",
            "324\n",
            "325\n",
            "326\n",
            "327\n",
            "328\n",
            "329\n",
            "330\n",
            "331\n",
            "332\n",
            "333\n",
            "334\n",
            "335\n",
            "336\n",
            "337\n",
            "338\n",
            "339\n",
            "340\n",
            "341\n",
            "342\n",
            "343\n",
            "344\n",
            "345\n",
            "346\n",
            "347\n",
            "348\n",
            "349\n",
            "350\n",
            "351\n",
            "352\n",
            "353\n",
            "354\n",
            "355\n",
            "356\n",
            "357\n",
            "358\n",
            "359\n",
            "360\n",
            "361\n",
            "362\n",
            "363\n",
            "364\n",
            "365\n",
            "366\n",
            "367\n",
            "368\n",
            "369\n",
            "370\n",
            "371\n",
            "372\n",
            "373\n",
            "374\n",
            "375\n",
            "376\n",
            "377\n",
            "378\n",
            "379\n",
            "380\n",
            "381\n",
            "382\n",
            "383\n",
            "384\n",
            "385\n",
            "386\n",
            "387\n",
            "388\n",
            "389\n",
            "390\n",
            "391\n",
            "392\n",
            "393\n",
            "394\n",
            "395\n",
            "396\n",
            "397\n",
            "398\n",
            "399\n",
            "400\n",
            "401\n",
            "402\n",
            "403\n",
            "404\n",
            "405\n",
            "406\n",
            "407\n",
            "408\n",
            "409\n",
            "410\n",
            "411\n",
            "412\n",
            "413\n",
            "414\n",
            "415\n",
            "416\n",
            "417\n",
            "418\n",
            "419\n",
            "420\n",
            "421\n",
            "422\n",
            "423\n",
            "424\n",
            "425\n",
            "426\n",
            "427\n",
            "428\n",
            "429\n",
            "430\n",
            "431\n",
            "432\n",
            "433\n",
            "434\n",
            "435\n",
            "436\n",
            "437\n",
            "438\n",
            "439\n",
            "440\n",
            "441\n",
            "442\n",
            "443\n",
            "444\n",
            "445\n",
            "446\n",
            "447\n",
            "448\n",
            "449\n",
            "450\n",
            "451\n",
            "452\n",
            "453\n",
            "454\n",
            "455\n",
            "456\n",
            "457\n",
            "458\n",
            "459\n",
            "460\n",
            "461\n",
            "462\n",
            "463\n",
            "464\n",
            "465\n",
            "466\n",
            "467\n",
            "468\n",
            "469\n",
            "470\n",
            "471\n",
            "472\n",
            "473\n",
            "474\n",
            "475\n",
            "476\n",
            "477\n",
            "478\n",
            "479\n",
            "480\n",
            "481\n",
            "482\n",
            "483\n",
            "484\n",
            "485\n",
            "486\n",
            "487\n",
            "488\n",
            "489\n",
            "490\n",
            "491\n",
            "492\n",
            "493\n",
            "494\n",
            "495\n",
            "496\n",
            "497\n",
            "498\n",
            "499\n",
            "500\n",
            "501\n",
            "502\n",
            "503\n",
            "504\n",
            "505\n",
            "506\n",
            "507\n",
            "508\n",
            "509\n",
            "510\n",
            "511\n",
            "512\n",
            "513\n",
            "514\n",
            "515\n",
            "516\n",
            "517\n",
            "518\n",
            "519\n",
            "520\n",
            "521\n",
            "522\n",
            "523\n",
            "524\n",
            "525\n",
            "526\n",
            "527\n",
            "528\n",
            "529\n",
            "530\n",
            "531\n",
            "532\n",
            "533\n",
            "534\n",
            "535\n",
            "536\n",
            "537\n",
            "538\n",
            "539\n",
            "540\n",
            "541\n",
            "542\n",
            "543\n",
            "544\n",
            "545\n",
            "546\n",
            "547\n",
            "548\n",
            "549\n",
            "550\n",
            "551\n",
            "552\n",
            "553\n",
            "554\n",
            "555\n",
            "556\n",
            "557\n",
            "558\n",
            "559\n",
            "560\n",
            "561\n",
            "562\n",
            "563\n",
            "564\n",
            "565\n",
            "566\n",
            "567\n",
            "568\n",
            "569\n",
            "570\n",
            "571\n",
            "572\n",
            "573\n",
            "574\n",
            "575\n",
            "576\n",
            "577\n",
            "578\n",
            "579\n",
            "580\n",
            "581\n",
            "582\n",
            "583\n",
            "584\n",
            "585\n",
            "586\n",
            "587\n",
            "588\n",
            "589\n",
            "590\n",
            "591\n",
            "592\n",
            "593\n",
            "594\n",
            "595\n",
            "596\n",
            "597\n",
            "598\n",
            "599\n",
            "600\n",
            "601\n",
            "602\n",
            "603\n",
            "604\n",
            "605\n",
            "606\n",
            "607\n",
            "608\n",
            "609\n",
            "610\n",
            "611\n",
            "612\n",
            "613\n",
            "614\n",
            "615\n",
            "616\n",
            "617\n",
            "618\n",
            "619\n",
            "620\n",
            "621\n",
            "622\n",
            "623\n",
            "624\n",
            "625\n",
            "626\n",
            "627\n",
            "628\n",
            "629\n",
            "630\n",
            "631\n",
            "632\n",
            "633\n",
            "634\n",
            "635\n",
            "636\n",
            "637\n",
            "638\n",
            "639\n",
            "640\n",
            "641\n",
            "642\n",
            "643\n",
            "644\n",
            "645\n",
            "646\n",
            "647\n",
            "648\n",
            "649\n",
            "650\n",
            "651\n",
            "652\n",
            "653\n",
            "654\n",
            "655\n",
            "656\n",
            "657\n",
            "658\n",
            "659\n",
            "660\n",
            "661\n",
            "662\n",
            "663\n",
            "664\n",
            "665\n",
            "666\n",
            "667\n",
            "668\n",
            "669\n",
            "670\n",
            "671\n",
            "672\n",
            "673\n",
            "674\n",
            "675\n",
            "676\n",
            "677\n",
            "678\n",
            "679\n",
            "680\n",
            "681\n",
            "682\n",
            "683\n",
            "684\n",
            "685\n",
            "686\n",
            "687\n",
            "688\n",
            "689\n",
            "690\n",
            "691\n",
            "692\n",
            "693\n",
            "694\n",
            "695\n",
            "696\n",
            "697\n",
            "698\n",
            "699\n",
            "700\n",
            "701\n",
            "702\n",
            "703\n",
            "704\n",
            "705\n",
            "706\n",
            "707\n",
            "708\n",
            "709\n",
            "710\n",
            "711\n",
            "712\n",
            "713\n",
            "714\n",
            "715\n",
            "716\n",
            "717\n",
            "718\n",
            "719\n",
            "720\n",
            "721\n",
            "722\n",
            "723\n",
            "724\n",
            "725\n",
            "726\n",
            "727\n",
            "728\n",
            "729\n",
            "730\n",
            "731\n",
            "732\n",
            "733\n",
            "734\n",
            "735\n",
            "736\n",
            "737\n",
            "738\n",
            "739\n",
            "740\n",
            "741\n",
            "742\n",
            "743\n",
            "744\n",
            "745\n",
            "746\n",
            "747\n",
            "748\n",
            "749\n",
            "750\n",
            "751\n",
            "752\n",
            "753\n",
            "754\n",
            "755\n",
            "756\n",
            "757\n",
            "758\n",
            "759\n",
            "760\n",
            "761\n",
            "762\n",
            "763\n",
            "764\n",
            "765\n",
            "766\n",
            "767\n",
            "768\n",
            "769\n",
            "770\n",
            "771\n",
            "772\n",
            "773\n",
            "774\n",
            "775\n",
            "776\n",
            "777\n",
            "778\n",
            "779\n",
            "780\n",
            "781\n",
            "782\n",
            "783\n",
            "784\n",
            "785\n",
            "786\n",
            "787\n",
            "788\n",
            "789\n",
            "790\n",
            "791\n",
            "792\n",
            "793\n",
            "794\n",
            "795\n",
            "796\n",
            "797\n",
            "798\n",
            "799\n",
            "800\n",
            "801\n",
            "802\n",
            "803\n",
            "804\n",
            "805\n",
            "806\n",
            "807\n",
            "808\n",
            "809\n",
            "810\n",
            "811\n",
            "812\n",
            "813\n",
            "814\n",
            "815\n",
            "816\n",
            "817\n",
            "818\n",
            "819\n",
            "820\n",
            "821\n",
            "822\n",
            "823\n",
            "824\n",
            "825\n",
            "826\n",
            "827\n",
            "828\n",
            "829\n",
            "830\n",
            "831\n",
            "832\n",
            "833\n",
            "834\n",
            "835\n",
            "836\n",
            "837\n",
            "838\n",
            "839\n",
            "840\n",
            "841\n",
            "842\n",
            "843\n",
            "844\n",
            "845\n",
            "846\n",
            "847\n",
            "848\n",
            "849\n",
            "850\n",
            "851\n",
            "852\n",
            "853\n",
            "854\n",
            "855\n",
            "856\n",
            "857\n",
            "858\n",
            "859\n",
            "860\n",
            "861\n",
            "862\n",
            "863\n",
            "864\n",
            "865\n",
            "866\n",
            "867\n",
            "868\n",
            "869\n",
            "870\n",
            "871\n",
            "872\n",
            "873\n",
            "874\n",
            "875\n",
            "876\n",
            "877\n",
            "878\n",
            "879\n",
            "880\n",
            "881\n",
            "882\n",
            "883\n",
            "884\n",
            "885\n",
            "886\n",
            "887\n",
            "888\n",
            "889\n",
            "890\n",
            "891\n",
            "892\n",
            "893\n",
            "894\n",
            "895\n",
            "896\n",
            "897\n",
            "898\n",
            "899\n",
            "900\n",
            "901\n",
            "902\n",
            "903\n",
            "904\n",
            "905\n",
            "906\n",
            "907\n",
            "908\n",
            "909\n",
            "910\n",
            "911\n",
            "912\n",
            "913\n",
            "914\n",
            "915\n",
            "916\n",
            "917\n",
            "918\n",
            "919\n",
            "920\n",
            "921\n",
            "922\n",
            "923\n",
            "924\n",
            "925\n",
            "926\n",
            "927\n",
            "928\n",
            "929\n",
            "930\n",
            "931\n",
            "932\n",
            "933\n",
            "934\n",
            "935\n",
            "936\n",
            "937\n",
            "938\n",
            "939\n",
            "940\n",
            "941\n",
            "942\n",
            "943\n",
            "944\n",
            "945\n",
            "946\n",
            "947\n",
            "948\n",
            "949\n",
            "950\n",
            "951\n",
            "952\n",
            "953\n",
            "954\n",
            "955\n",
            "956\n",
            "957\n",
            "958\n",
            "959\n",
            "960\n",
            "961\n",
            "962\n",
            "963\n",
            "964\n",
            "965\n",
            "966\n",
            "967\n",
            "968\n",
            "969\n",
            "970\n",
            "971\n",
            "972\n",
            "973\n",
            "974\n",
            "975\n",
            "976\n",
            "977\n",
            "978\n",
            "979\n",
            "980\n",
            "981\n",
            "982\n",
            "983\n",
            "984\n",
            "985\n",
            "986\n",
            "987\n",
            "988\n",
            "989\n",
            "990\n",
            "991\n",
            "992\n",
            "993\n",
            "994\n",
            "995\n",
            "996\n",
            "997\n",
            "998\n",
            "999\n",
            "1000\n",
            "1001\n",
            "1002\n",
            "1003\n",
            "1004\n",
            "1005\n",
            "1006\n",
            "1007\n",
            "1008\n",
            "1009\n",
            "1010\n",
            "1011\n",
            "1012\n",
            "1013\n",
            "1014\n",
            "1015\n",
            "1016\n",
            "1017\n",
            "1018\n",
            "1019\n",
            "1020\n",
            "1021\n",
            "1022\n",
            "1023\n",
            "1024\n",
            "1025\n",
            "1026\n",
            "1027\n",
            "1028\n",
            "1029\n",
            "1030\n",
            "1031\n",
            "1032\n",
            "1033\n",
            "1034\n",
            "1035\n",
            "1036\n",
            "1037\n",
            "1038\n",
            "1039\n",
            "1040\n",
            "1041\n",
            "1042\n",
            "1043\n",
            "1044\n",
            "1045\n",
            "1046\n",
            "1047\n",
            "1048\n",
            "1049\n",
            "1050\n",
            "1051\n",
            "1052\n",
            "1053\n",
            "1054\n",
            "1055\n",
            "1056\n",
            "1057\n",
            "1058\n",
            "1059\n",
            "1060\n",
            "1061\n",
            "1062\n",
            "1063\n",
            "1064\n",
            "1065\n",
            "1066\n",
            "1067\n",
            "1068\n",
            "1069\n",
            "1070\n",
            "1071\n",
            "1072\n",
            "1073\n",
            "1074\n",
            "1075\n",
            "1076\n",
            "1077\n",
            "1078\n",
            "1079\n",
            "1080\n",
            "1081\n",
            "1082\n",
            "1083\n",
            "1084\n",
            "1085\n",
            "1086\n",
            "1087\n",
            "1088\n",
            "1089\n",
            "1090\n",
            "1091\n",
            "1092\n",
            "1093\n",
            "1094\n",
            "1095\n",
            "1096\n",
            "1097\n",
            "1098\n",
            "1099\n",
            "1100\n",
            "1101\n",
            "1102\n",
            "1103\n",
            "1104\n",
            "1105\n",
            "1106\n",
            "1107\n",
            "1108\n",
            "1109\n",
            "1110\n",
            "1111\n",
            "1112\n",
            "1113\n",
            "1114\n",
            "1115\n",
            "1116\n",
            "1117\n",
            "1118\n",
            "1119\n",
            "1120\n",
            "1121\n",
            "1122\n",
            "1123\n",
            "1124\n",
            "1125\n",
            "1126\n",
            "1127\n",
            "1128\n",
            "1129\n",
            "1130\n",
            "1131\n",
            "1132\n",
            "1133\n",
            "1134\n",
            "1135\n",
            "1136\n",
            "1137\n",
            "1138\n",
            "1139\n",
            "1140\n",
            "1141\n",
            "1142\n",
            "1143\n",
            "1144\n",
            "1145\n",
            "1146\n",
            "1147\n",
            "1148\n",
            "1149\n",
            "1150\n",
            "1151\n",
            "1152\n",
            "1153\n",
            "1154\n",
            "1155\n",
            "1156\n",
            "1157\n",
            "1158\n",
            "1159\n",
            "1160\n",
            "1161\n",
            "1162\n",
            "1163\n",
            "1164\n",
            "1165\n",
            "1166\n",
            "1167\n",
            "1168\n",
            "1169\n",
            "1170\n",
            "1171\n",
            "1172\n",
            "1173\n",
            "1174\n",
            "1175\n",
            "1176\n",
            "1177\n",
            "1178\n",
            "1179\n",
            "1180\n",
            "1181\n",
            "1182\n",
            "1183\n",
            "1184\n",
            "1185\n",
            "1186\n",
            "1187\n",
            "1188\n",
            "1189\n",
            "1190\n",
            "1191\n",
            "1192\n",
            "1193\n",
            "1194\n",
            "1195\n",
            "1196\n",
            "1197\n",
            "1198\n",
            "1199\n",
            "1200\n",
            "1201\n",
            "1202\n",
            "1203\n",
            "1204\n",
            "1205\n",
            "1206\n",
            "1207\n",
            "1208\n",
            "1209\n",
            "1210\n",
            "1211\n",
            "1212\n",
            "1213\n",
            "1214\n",
            "1215\n",
            "1216\n",
            "1217\n",
            "1218\n",
            "1219\n",
            "1220\n",
            "1221\n",
            "1222\n",
            "1223\n",
            "1224\n",
            "1225\n",
            "1226\n",
            "1227\n",
            "1228\n",
            "1229\n",
            "1230\n",
            "1231\n",
            "1232\n",
            "1233\n",
            "1234\n",
            "1235\n",
            "1236\n",
            "1237\n",
            "1238\n",
            "1239\n",
            "1240\n",
            "1241\n",
            "1242\n",
            "1243\n",
            "1244\n",
            "1245\n",
            "1246\n",
            "1247\n",
            "1248\n",
            "1249\n",
            "1250\n",
            "1251\n",
            "1252\n",
            "1253\n",
            "1254\n",
            "1255\n",
            "1256\n",
            "1257\n",
            "1258\n",
            "1259\n",
            "1260\n",
            "1261\n",
            "1262\n",
            "1263\n",
            "1264\n",
            "1265\n",
            "1266\n",
            "1267\n",
            "1268\n",
            "1269\n",
            "1270\n",
            "1271\n",
            "1272\n",
            "1273\n",
            "1274\n",
            "1275\n",
            "1276\n",
            "1277\n",
            "1278\n",
            "1279\n",
            "1280\n",
            "1281\n",
            "1282\n",
            "1283\n",
            "1284\n",
            "1285\n",
            "1286\n",
            "1287\n",
            "1288\n",
            "1289\n",
            "1290\n",
            "1291\n",
            "1292\n",
            "1293\n",
            "1294\n",
            "1295\n",
            "1296\n",
            "1297\n",
            "1298\n",
            "1299\n",
            "1300\n",
            "1301\n",
            "1302\n",
            "1303\n",
            "1304\n",
            "1305\n",
            "1306\n",
            "1307\n",
            "1308\n",
            "1309\n",
            "1310\n",
            "1311\n",
            "1312\n",
            "1313\n",
            "1314\n",
            "1315\n",
            "1316\n",
            "1317\n",
            "1318\n",
            "1319\n",
            "1320\n",
            "1321\n",
            "1322\n",
            "1323\n",
            "1324\n",
            "1325\n",
            "1326\n",
            "1327\n",
            "1328\n",
            "1329\n",
            "1330\n",
            "1331\n",
            "1332\n",
            "1333\n",
            "1334\n",
            "1335\n",
            "1336\n",
            "1337\n",
            "1338\n",
            "1339\n",
            "1340\n",
            "1341\n",
            "1342\n",
            "1343\n",
            "1344\n",
            "1345\n",
            "1346\n",
            "1347\n",
            "1348\n",
            "1349\n",
            "1350\n",
            "1351\n",
            "1352\n",
            "1353\n",
            "1354\n",
            "1355\n",
            "1356\n",
            "1357\n",
            "1358\n",
            "1359\n",
            "1360\n",
            "1361\n",
            "1362\n",
            "1363\n",
            "1364\n",
            "1365\n",
            "1366\n",
            "1367\n",
            "1368\n",
            "1369\n",
            "1370\n",
            "1371\n",
            "1372\n",
            "1373\n",
            "1374\n",
            "1375\n",
            "1376\n",
            "1377\n",
            "1378\n",
            "1379\n",
            "1380\n",
            "1381\n",
            "1382\n",
            "1383\n",
            "1384\n",
            "1385\n",
            "1386\n",
            "1387\n",
            "1388\n",
            "1389\n",
            "1390\n",
            "1391\n",
            "1392\n",
            "1393\n",
            "1394\n",
            "1395\n",
            "1396\n",
            "1397\n",
            "1398\n",
            "1399\n",
            "1400\n",
            "1401\n",
            "1402\n",
            "1403\n",
            "1404\n",
            "1405\n",
            "1406\n",
            "1407\n",
            "1408\n",
            "1409\n",
            "1410\n",
            "1411\n",
            "1412\n",
            "1413\n",
            "1414\n",
            "1415\n",
            "1416\n",
            "1417\n",
            "1418\n",
            "1419\n",
            "1420\n",
            "1421\n",
            "1422\n",
            "1423\n",
            "1424\n",
            "1425\n",
            "1426\n",
            "1427\n",
            "1428\n",
            "1429\n",
            "1430\n",
            "1431\n",
            "1432\n",
            "1433\n",
            "1434\n",
            "1435\n",
            "1436\n",
            "1437\n",
            "1438\n",
            "1439\n",
            "1440\n",
            "1441\n",
            "1442\n",
            "1443\n",
            "1444\n",
            "1445\n",
            "1446\n",
            "1447\n",
            "1448\n",
            "1449\n",
            "1450\n",
            "1451\n",
            "1452\n",
            "1453\n",
            "1454\n",
            "1455\n",
            "1456\n",
            "1457\n",
            "1458\n",
            "1459\n",
            "1460\n",
            "1461\n",
            "1462\n",
            "1463\n",
            "1464\n",
            "1465\n",
            "1466\n",
            "1467\n",
            "1468\n",
            "1469\n",
            "1470\n",
            "1471\n",
            "1472\n",
            "1473\n",
            "1474\n",
            "1475\n",
            "1476\n",
            "1477\n",
            "1478\n",
            "1479\n",
            "1480\n",
            "1481\n",
            "1482\n",
            "1483\n",
            "1484\n",
            "1485\n",
            "1486\n",
            "1487\n",
            "1488\n",
            "1489\n",
            "1490\n",
            "1491\n",
            "1492\n",
            "1493\n",
            "1494\n",
            "1495\n",
            "1496\n",
            "1497\n",
            "1498\n",
            "1499\n",
            "1500\n",
            "1501\n",
            "1502\n",
            "1503\n",
            "1504\n",
            "1505\n",
            "1506\n",
            "1507\n",
            "1508\n",
            "1509\n",
            "1510\n",
            "1511\n",
            "1512\n",
            "1513\n",
            "1514\n",
            "1515\n",
            "1516\n",
            "1517\n",
            "1518\n",
            "1519\n",
            "1520\n",
            "1521\n",
            "1522\n",
            "1523\n",
            "1524\n",
            "1525\n",
            "1526\n",
            "1527\n",
            "1528\n",
            "1529\n",
            "1530\n",
            "1531\n",
            "1532\n",
            "1533\n",
            "1534\n",
            "1535\n",
            "1536\n",
            "1537\n",
            "1538\n",
            "1539\n",
            "1540\n",
            "1541\n",
            "1542\n",
            "1543\n",
            "1544\n",
            "1545\n",
            "1546\n",
            "1547\n",
            "1548\n",
            "1549\n",
            "1550\n",
            "1551\n",
            "1552\n",
            "1553\n",
            "1554\n",
            "1555\n",
            "1556\n",
            "1557\n",
            "1558\n",
            "1559\n",
            "1560\n",
            "1561\n",
            "1562\n",
            "1563\n",
            "1564\n",
            "1565\n",
            "1566\n",
            "1567\n",
            "1568\n",
            "1569\n",
            "1570\n",
            "1571\n",
            "1572\n",
            "1573\n",
            "1574\n",
            "1575\n",
            "1576\n",
            "1577\n",
            "1578\n",
            "1579\n",
            "1580\n",
            "1581\n",
            "1582\n",
            "1583\n",
            "1584\n",
            "1585\n",
            "1586\n",
            "1587\n",
            "1588\n",
            "1589\n",
            "1590\n",
            "1591\n",
            "1592\n",
            "1593\n",
            "1594\n",
            "1595\n",
            "1596\n",
            "1597\n",
            "1598\n",
            "1599\n",
            "1600\n",
            "1601\n",
            "1602\n",
            "1603\n",
            "1604\n",
            "1605\n",
            "1606\n",
            "1607\n",
            "1608\n",
            "1609\n",
            "1610\n",
            "1611\n",
            "1612\n",
            "1613\n",
            "1614\n",
            "1615\n",
            "1616\n",
            "1617\n",
            "1618\n",
            "1619\n",
            "1620\n",
            "1621\n",
            "1622\n",
            "1623\n",
            "1624\n",
            "1625\n",
            "1626\n",
            "1627\n",
            "1628\n",
            "1629\n",
            "1630\n",
            "1631\n",
            "1632\n",
            "1633\n",
            "1634\n",
            "1635\n",
            "1636\n",
            "1637\n",
            "1638\n",
            "1639\n",
            "1640\n",
            "1641\n",
            "1642\n",
            "1643\n",
            "1644\n",
            "1645\n",
            "1646\n",
            "1647\n",
            "1648\n",
            "1649\n",
            "1650\n",
            "1651\n",
            "1652\n",
            "1653\n",
            "1654\n",
            "1655\n",
            "1656\n",
            "1657\n",
            "1658\n",
            "1659\n",
            "1660\n",
            "1661\n",
            "1662\n",
            "1663\n",
            "1664\n",
            "1665\n",
            "1666\n",
            "1667\n",
            "1668\n",
            "1669\n",
            "1670\n",
            "1671\n",
            "1672\n",
            "1673\n",
            "1674\n",
            "1675\n",
            "1676\n",
            "1677\n",
            "1678\n",
            "1679\n",
            "1680\n",
            "1681\n",
            "1682\n",
            "1683\n",
            "1684\n",
            "1685\n",
            "1686\n",
            "1687\n",
            "1688\n",
            "1689\n",
            "1690\n",
            "1691\n",
            "1692\n",
            "1693\n",
            "1694\n",
            "1695\n",
            "1696\n",
            "1697\n",
            "1698\n",
            "1699\n",
            "1700\n",
            "1701\n",
            "1702\n",
            "1703\n",
            "1704\n",
            "1705\n",
            "1706\n",
            "1707\n",
            "1708\n",
            "1709\n",
            "1710\n",
            "1711\n",
            "1712\n",
            "1713\n",
            "1714\n",
            "1715\n",
            "1716\n",
            "1717\n",
            "1718\n",
            "1719\n",
            "1720\n",
            "1721\n",
            "1722\n",
            "1723\n",
            "1724\n",
            "1725\n",
            "1726\n",
            "1727\n",
            "1728\n",
            "1729\n",
            "1730\n",
            "1731\n",
            "1732\n",
            "1733\n",
            "1734\n",
            "1735\n",
            "1736\n",
            "1737\n",
            "1738\n",
            "1739\n",
            "1740\n",
            "1741\n",
            "1742\n",
            "1743\n",
            "1744\n",
            "1745\n",
            "1746\n",
            "1747\n",
            "1748\n",
            "1749\n",
            "1750\n",
            "1751\n",
            "1752\n",
            "1753\n",
            "1754\n",
            "1755\n",
            "1756\n",
            "1757\n",
            "1758\n",
            "1759\n",
            "1760\n",
            "1761\n",
            "1762\n",
            "1763\n",
            "1764\n",
            "1765\n",
            "1766\n",
            "1767\n",
            "1768\n",
            "1769\n",
            "1770\n",
            "1771\n",
            "1772\n",
            "1773\n",
            "1774\n",
            "1775\n",
            "1776\n",
            "1777\n",
            "1778\n",
            "1779\n",
            "1780\n",
            "1781\n",
            "1782\n",
            "1783\n",
            "1784\n",
            "1785\n",
            "1786\n",
            "1787\n",
            "1788\n",
            "1789\n",
            "1790\n",
            "1791\n",
            "1792\n",
            "1793\n",
            "1794\n",
            "1795\n",
            "1796\n",
            "1797\n",
            "1798\n",
            "1799\n",
            "1800\n",
            "1801\n",
            "1802\n",
            "1803\n",
            "1804\n",
            "1805\n",
            "1806\n",
            "1807\n",
            "1808\n",
            "1809\n",
            "1810\n",
            "1811\n",
            "1812\n",
            "1813\n",
            "1814\n",
            "1815\n",
            "1816\n",
            "1817\n",
            "1818\n",
            "1819\n",
            "1820\n",
            "1821\n",
            "1822\n",
            "1823\n",
            "1824\n",
            "1825\n",
            "1826\n",
            "1827\n",
            "1828\n",
            "1829\n",
            "1830\n",
            "1831\n",
            "1832\n",
            "1833\n",
            "1834\n",
            "1835\n",
            "1836\n",
            "1837\n",
            "1838\n",
            "1839\n",
            "1840\n",
            "1841\n",
            "1842\n",
            "1843\n",
            "1844\n",
            "1845\n",
            "1846\n",
            "1847\n",
            "1848\n",
            "1849\n",
            "1850\n",
            "1851\n",
            "1852\n",
            "1853\n",
            "1854\n",
            "1855\n",
            "1856\n",
            "1857\n",
            "1858\n",
            "1859\n",
            "1860\n",
            "1861\n",
            "1862\n",
            "1863\n",
            "1864\n",
            "1865\n",
            "1866\n",
            "1867\n",
            "1868\n",
            "1869\n",
            "1870\n",
            "1871\n",
            "1872\n",
            "1873\n",
            "1874\n",
            "1875\n",
            "1876\n",
            "1877\n",
            "1878\n",
            "1879\n",
            "1880\n",
            "1881\n",
            "1882\n",
            "1883\n",
            "1884\n",
            "1885\n",
            "1886\n",
            "1887\n",
            "1888\n",
            "1889\n",
            "1890\n",
            "1891\n",
            "1892\n",
            "1893\n",
            "1894\n",
            "1895\n",
            "1896\n",
            "1897\n",
            "1898\n",
            "1899\n",
            "1900\n",
            "1901\n",
            "1902\n",
            "1903\n",
            "1904\n",
            "1905\n",
            "1906\n",
            "1907\n",
            "1908\n",
            "1909\n",
            "1910\n",
            "1911\n",
            "1912\n",
            "1913\n",
            "1914\n",
            "1915\n",
            "1916\n",
            "1917\n",
            "1918\n",
            "1919\n",
            "1920\n",
            "1921\n",
            "1922\n",
            "1923\n",
            "1924\n",
            "1925\n",
            "1926\n",
            "1927\n",
            "1928\n",
            "1929\n",
            "1930\n",
            "1931\n",
            "1932\n",
            "1933\n",
            "1934\n",
            "1935\n",
            "1936\n",
            "1937\n",
            "1938\n",
            "1939\n",
            "1940\n",
            "1941\n",
            "1942\n",
            "1943\n",
            "1944\n",
            "1945\n",
            "1946\n",
            "1947\n",
            "1948\n",
            "1949\n",
            "1950\n",
            "1951\n",
            "1952\n",
            "1953\n",
            "1954\n",
            "1955\n",
            "1956\n",
            "1957\n",
            "1958\n",
            "1959\n",
            "1960\n",
            "1961\n",
            "1962\n",
            "1963\n",
            "1964\n",
            "1965\n",
            "1966\n",
            "1967\n",
            "1968\n",
            "1969\n",
            "1970\n",
            "1971\n",
            "1972\n",
            "1973\n",
            "1974\n",
            "1975\n",
            "1976\n",
            "1977\n",
            "1978\n",
            "1979\n",
            "1980\n",
            "1981\n",
            "1982\n",
            "1983\n",
            "1984\n",
            "1985\n",
            "1986\n",
            "1987\n",
            "1988\n",
            "1989\n",
            "1990\n",
            "1991\n",
            "1992\n",
            "1993\n",
            "1994\n",
            "1995\n",
            "1996\n",
            "1997\n",
            "1998\n",
            "1999\n",
            "2000\n",
            "2001\n",
            "2002\n",
            "2003\n",
            "2004\n",
            "2005\n",
            "2006\n",
            "2007\n",
            "2008\n",
            "2009\n",
            "2010\n",
            "2011\n",
            "2012\n",
            "2013\n",
            "2014\n",
            "2015\n",
            "2016\n",
            "2017\n",
            "2018\n",
            "2019\n",
            "2020\n",
            "2021\n",
            "2022\n",
            "2023\n",
            "2024\n",
            "2025\n",
            "2026\n",
            "2027\n",
            "2028\n",
            "2029\n",
            "2030\n",
            "2031\n",
            "2032\n",
            "2033\n",
            "2034\n",
            "2035\n",
            "2036\n",
            "2037\n",
            "2038\n",
            "2039\n",
            "2040\n",
            "2041\n",
            "2042\n",
            "2043\n",
            "2044\n",
            "2045\n",
            "2046\n",
            "2047\n",
            "2048\n",
            "2049\n",
            "2050\n",
            "2051\n",
            "2052\n",
            "2053\n",
            "2054\n",
            "2055\n",
            "2056\n",
            "2057\n",
            "2058\n",
            "2059\n",
            "2060\n",
            "2061\n",
            "2062\n",
            "2063\n",
            "2064\n",
            "2065\n",
            "2066\n",
            "2067\n",
            "2068\n",
            "2069\n",
            "2070\n",
            "2071\n",
            "2072\n",
            "2073\n",
            "2074\n",
            "2075\n",
            "2076\n",
            "2077\n",
            "2078\n",
            "2079\n",
            "2080\n",
            "2081\n",
            "2082\n",
            "2083\n",
            "2084\n",
            "2085\n",
            "2086\n",
            "2087\n",
            "2088\n",
            "2089\n",
            "2090\n",
            "2091\n",
            "2092\n",
            "2093\n",
            "2094\n",
            "2095\n",
            "2096\n",
            "2097\n",
            "2098\n",
            "2099\n",
            "2100\n",
            "2101\n",
            "2102\n",
            "2103\n",
            "2104\n",
            "2105\n",
            "2106\n",
            "2107\n",
            "2108\n",
            "2109\n",
            "2110\n",
            "2111\n",
            "2112\n",
            "2113\n",
            "2114\n",
            "2115\n",
            "2116\n",
            "2117\n",
            "2118\n",
            "2119\n",
            "2120\n",
            "2121\n",
            "2122\n",
            "2123\n",
            "2124\n",
            "2125\n",
            "2126\n",
            "2127\n",
            "2128\n",
            "2129\n",
            "2130\n",
            "2131\n",
            "2132\n",
            "2133\n",
            "2134\n",
            "2135\n",
            "2136\n",
            "2137\n",
            "2138\n",
            "2139\n",
            "2140\n",
            "2141\n",
            "2142\n",
            "2143\n",
            "2144\n",
            "2145\n",
            "2146\n",
            "2147\n",
            "2148\n",
            "2149\n",
            "2150\n",
            "2151\n",
            "2152\n",
            "2153\n",
            "2154\n",
            "2155\n",
            "2156\n",
            "2157\n",
            "2158\n",
            "2159\n",
            "2160\n",
            "2161\n",
            "2162\n",
            "2163\n",
            "2164\n",
            "2165\n",
            "2166\n",
            "2167\n",
            "2168\n",
            "2169\n",
            "2170\n",
            "2171\n",
            "2172\n",
            "2173\n",
            "2174\n",
            "2175\n",
            "2176\n",
            "2177\n",
            "2178\n",
            "2179\n",
            "2180\n",
            "2181\n",
            "2182\n",
            "2183\n",
            "2184\n",
            "2185\n",
            "2186\n",
            "2187\n",
            "2188\n",
            "2189\n",
            "2190\n",
            "2191\n",
            "2192\n",
            "2193\n",
            "2194\n",
            "2195\n",
            "2196\n",
            "2197\n",
            "2198\n",
            "2199\n",
            "2200\n",
            "2201\n",
            "2202\n",
            "2203\n",
            "2204\n",
            "2205\n",
            "2206\n",
            "2207\n",
            "2208\n",
            "2209\n",
            "2210\n",
            "2211\n",
            "2212\n",
            "2213\n",
            "2214\n",
            "2215\n",
            "2216\n",
            "2217\n",
            "2218\n",
            "2219\n",
            "2220\n",
            "2221\n",
            "2222\n",
            "2223\n",
            "2224\n",
            "2225\n",
            "2226\n",
            "2227\n",
            "2228\n",
            "2229\n",
            "2230\n",
            "2231\n",
            "2232\n",
            "2233\n",
            "2234\n",
            "2235\n",
            "2236\n",
            "2237\n",
            "2238\n",
            "2239\n",
            "2240\n",
            "2241\n",
            "2242\n",
            "2243\n",
            "2244\n",
            "2245\n",
            "2246\n",
            "2247\n",
            "2248\n",
            "2249\n",
            "2250\n",
            "2251\n",
            "2252\n",
            "2253\n",
            "2254\n",
            "2255\n",
            "2256\n",
            "2257\n",
            "2258\n",
            "2259\n",
            "2260\n",
            "2261\n",
            "2262\n",
            "2263\n",
            "2264\n",
            "2265\n",
            "2266\n",
            "2267\n",
            "2268\n",
            "2269\n",
            "2270\n",
            "2271\n",
            "2272\n",
            "2273\n",
            "2274\n",
            "2275\n",
            "2276\n",
            "2277\n",
            "2278\n",
            "2279\n",
            "2280\n",
            "2281\n",
            "2282\n",
            "2283\n",
            "2284\n",
            "2285\n",
            "2286\n",
            "2287\n",
            "2288\n",
            "2289\n",
            "2290\n",
            "2291\n",
            "2292\n",
            "2293\n",
            "2294\n",
            "2295\n",
            "2296\n",
            "2297\n",
            "2298\n",
            "2299\n",
            "2300\n",
            "2301\n",
            "2302\n",
            "2303\n",
            "2304\n",
            "2305\n",
            "2306\n",
            "2307\n",
            "2308\n",
            "2309\n",
            "2310\n",
            "2311\n",
            "2312\n",
            "2313\n",
            "2314\n",
            "2315\n",
            "2316\n",
            "2317\n",
            "2318\n",
            "2319\n",
            "2320\n",
            "2321\n",
            "2322\n",
            "2323\n",
            "2324\n",
            "2325\n",
            "2326\n",
            "2327\n",
            "2328\n",
            "2329\n",
            "2330\n",
            "2331\n",
            "2332\n",
            "2333\n",
            "2334\n",
            "2335\n",
            "2336\n",
            "2337\n",
            "2338\n",
            "2339\n",
            "2340\n",
            "2341\n",
            "2342\n",
            "2343\n",
            "2344\n",
            "2345\n",
            "2346\n",
            "2347\n",
            "2348\n",
            "2349\n",
            "2350\n",
            "2351\n",
            "2352\n",
            "2353\n",
            "2354\n",
            "2355\n",
            "2356\n",
            "2357\n",
            "2358\n",
            "2359\n",
            "2360\n",
            "2361\n",
            "2362\n",
            "2363\n",
            "2364\n",
            "2365\n",
            "2366\n",
            "2367\n",
            "2368\n",
            "2369\n",
            "2370\n",
            "2371\n",
            "2372\n",
            "2373\n",
            "2374\n",
            "2375\n",
            "2376\n",
            "2377\n",
            "2378\n",
            "2379\n",
            "2380\n",
            "2381\n",
            "2382\n",
            "2383\n",
            "2384\n",
            "2385\n",
            "2386\n",
            "2387\n",
            "2388\n",
            "2389\n",
            "2390\n",
            "2391\n",
            "2392\n",
            "2393\n",
            "2394\n",
            "2395\n",
            "2396\n",
            "2397\n",
            "2398\n",
            "2399\n",
            "2400\n",
            "2401\n",
            "2402\n",
            "2403\n",
            "2404\n",
            "2405\n",
            "2406\n",
            "2407\n",
            "2408\n",
            "2409\n",
            "2410\n",
            "2411\n",
            "2412\n",
            "2413\n",
            "2414\n",
            "2415\n",
            "2416\n",
            "2417\n",
            "2418\n",
            "2419\n",
            "2420\n",
            "2421\n",
            "2422\n",
            "2423\n",
            "2424\n",
            "2425\n",
            "2426\n",
            "2427\n",
            "2428\n",
            "2429\n",
            "2430\n",
            "2431\n",
            "2432\n",
            "2433\n",
            "2434\n",
            "2435\n",
            "2436\n",
            "2437\n",
            "2438\n",
            "2439\n",
            "2440\n",
            "2441\n",
            "2442\n",
            "2443\n",
            "2444\n",
            "2445\n",
            "2446\n",
            "2447\n",
            "2448\n",
            "2449\n",
            "2450\n",
            "2451\n",
            "2452\n",
            "2453\n",
            "2454\n",
            "2455\n",
            "2456\n",
            "2457\n",
            "2458\n",
            "2459\n",
            "2460\n",
            "2461\n",
            "2462\n",
            "2463\n",
            "2464\n",
            "2465\n",
            "2466\n",
            "2467\n",
            "2468\n",
            "2469\n",
            "2470\n",
            "2471\n",
            "2472\n",
            "2473\n",
            "2474\n",
            "2475\n",
            "2476\n",
            "2477\n",
            "2478\n",
            "2479\n",
            "2480\n",
            "2481\n",
            "2482\n",
            "2483\n",
            "2484\n",
            "2485\n",
            "2486\n",
            "2487\n",
            "2488\n",
            "2489\n",
            "2490\n",
            "2491\n",
            "2492\n",
            "2493\n",
            "2494\n",
            "2495\n",
            "2496\n",
            "2497\n",
            "2498\n",
            "2499\n",
            "2500\n",
            "2501\n",
            "2502\n",
            "2503\n",
            "2504\n",
            "2505\n",
            "2506\n",
            "2507\n",
            "2508\n",
            "2509\n",
            "2510\n",
            "2511\n",
            "2512\n",
            "2513\n",
            "2514\n",
            "2515\n",
            "2516\n",
            "2517\n",
            "2518\n",
            "2519\n",
            "2520\n",
            "2521\n",
            "2522\n",
            "2523\n",
            "2524\n",
            "2525\n",
            "2526\n",
            "2527\n",
            "2528\n",
            "2529\n",
            "2530\n",
            "2531\n",
            "2532\n",
            "2533\n",
            "2534\n",
            "2535\n",
            "2536\n",
            "2537\n",
            "2538\n",
            "2539\n",
            "2540\n",
            "2541\n",
            "2542\n",
            "2543\n",
            "2544\n",
            "2545\n",
            "2546\n",
            "2547\n",
            "2548\n",
            "2549\n",
            "2550\n",
            "2551\n",
            "2552\n",
            "2553\n",
            "2554\n",
            "2555\n",
            "2556\n",
            "2557\n",
            "2558\n",
            "2559\n",
            "2560\n",
            "2561\n",
            "2562\n",
            "2563\n",
            "2564\n",
            "2565\n",
            "2566\n",
            "2567\n",
            "2568\n",
            "2569\n",
            "2570\n",
            "2571\n",
            "2572\n",
            "2573\n",
            "2574\n",
            "2575\n",
            "2576\n",
            "2577\n",
            "2578\n",
            "2579\n",
            "2580\n",
            "2581\n",
            "2582\n",
            "2583\n",
            "2584\n",
            "2585\n",
            "2586\n",
            "2587\n",
            "2588\n",
            "2589\n",
            "2590\n",
            "2591\n",
            "2592\n",
            "2593\n",
            "2594\n",
            "2595\n",
            "2596\n",
            "2597\n",
            "2598\n",
            "2599\n",
            "2600\n",
            "2601\n",
            "2602\n",
            "2603\n",
            "2604\n",
            "2605\n",
            "2606\n",
            "2607\n",
            "2608\n",
            "2609\n",
            "2610\n",
            "2611\n",
            "2612\n",
            "2613\n",
            "2614\n",
            "2615\n",
            "2616\n",
            "2617\n",
            "2618\n",
            "2619\n",
            "2620\n",
            "2621\n",
            "2622\n",
            "2623\n",
            "2624\n",
            "2625\n",
            "2626\n",
            "2627\n",
            "2628\n",
            "2629\n",
            "2630\n",
            "2631\n",
            "2632\n",
            "2633\n",
            "2634\n",
            "2635\n",
            "2636\n",
            "2637\n",
            "2638\n",
            "2639\n",
            "2640\n",
            "2641\n",
            "2642\n",
            "2643\n",
            "2644\n",
            "2645\n",
            "2646\n",
            "2647\n",
            "2648\n",
            "2649\n",
            "2650\n",
            "2651\n",
            "2652\n",
            "2653\n",
            "2654\n",
            "2655\n",
            "2656\n",
            "2657\n",
            "2658\n",
            "2659\n",
            "2660\n",
            "2661\n",
            "2662\n",
            "2663\n",
            "2664\n",
            "2665\n",
            "2666\n",
            "2667\n",
            "2668\n",
            "2669\n",
            "2670\n",
            "2671\n",
            "2672\n",
            "2673\n",
            "2674\n",
            "2675\n",
            "2676\n",
            "2677\n",
            "2678\n",
            "2679\n",
            "2680\n",
            "2681\n",
            "2682\n",
            "2683\n",
            "2684\n",
            "2685\n",
            "2686\n",
            "2687\n",
            "2688\n",
            "2689\n",
            "2690\n",
            "2691\n",
            "2692\n",
            "2693\n",
            "2694\n",
            "2695\n",
            "2696\n",
            "2697\n",
            "2698\n",
            "2699\n",
            "2700\n",
            "2701\n",
            "2702\n",
            "2703\n",
            "2704\n",
            "2705\n",
            "2706\n",
            "2707\n",
            "2708\n",
            "2709\n",
            "2710\n",
            "2711\n",
            "2712\n",
            "2713\n",
            "2714\n",
            "2715\n",
            "2716\n",
            "2717\n",
            "2718\n",
            "2719\n",
            "2720\n",
            "2721\n",
            "2722\n",
            "2723\n",
            "2724\n",
            "2725\n",
            "2726\n",
            "2727\n",
            "2728\n",
            "2729\n",
            "2730\n",
            "2731\n",
            "2732\n",
            "2733\n",
            "2734\n",
            "2735\n",
            "2736\n",
            "2737\n",
            "2738\n",
            "2739\n",
            "2740\n",
            "2741\n",
            "2742\n",
            "2743\n",
            "2744\n",
            "2745\n",
            "2746\n",
            "2747\n",
            "2748\n",
            "2749\n",
            "2750\n",
            "2751\n",
            "2752\n",
            "2753\n",
            "2754\n",
            "2755\n",
            "2756\n",
            "2757\n",
            "2758\n",
            "2759\n",
            "2760\n",
            "2761\n",
            "2762\n",
            "2763\n",
            "2764\n",
            "2765\n",
            "2766\n",
            "2767\n",
            "2768\n",
            "2769\n",
            "2770\n",
            "2771\n",
            "2772\n",
            "2773\n",
            "2774\n",
            "2775\n",
            "2776\n",
            "2777\n",
            "2778\n",
            "2779\n",
            "2780\n",
            "2781\n",
            "2782\n",
            "2783\n",
            "2784\n",
            "2785\n",
            "2786\n",
            "2787\n",
            "2788\n",
            "2789\n",
            "2790\n",
            "2791\n",
            "2792\n",
            "2793\n",
            "2794\n",
            "2795\n",
            "2796\n",
            "2797\n",
            "2798\n",
            "2799\n",
            "2800\n",
            "2801\n",
            "2802\n",
            "2803\n",
            "2804\n",
            "2805\n",
            "2806\n",
            "2807\n",
            "2808\n",
            "2809\n",
            "2810\n",
            "2811\n",
            "2812\n",
            "2813\n",
            "2814\n",
            "2815\n",
            "2816\n",
            "2817\n",
            "2818\n",
            "2819\n",
            "2820\n",
            "2821\n",
            "2822\n",
            "2823\n",
            "2824\n",
            "2825\n",
            "2826\n",
            "2827\n",
            "2828\n",
            "2829\n",
            "2830\n",
            "2831\n",
            "2832\n",
            "2833\n",
            "2834\n",
            "2835\n",
            "2836\n",
            "2837\n",
            "2838\n",
            "2839\n",
            "2840\n",
            "2841\n",
            "2842\n",
            "2843\n",
            "2844\n",
            "2845\n",
            "2846\n",
            "2847\n",
            "2848\n",
            "2849\n",
            "2850\n",
            "2851\n",
            "2852\n",
            "2853\n",
            "2854\n",
            "2855\n",
            "2856\n",
            "2857\n",
            "2858\n",
            "2859\n",
            "2860\n",
            "2861\n",
            "2862\n",
            "2863\n",
            "2864\n",
            "2865\n",
            "2866\n",
            "2867\n",
            "2868\n",
            "2869\n",
            "2870\n",
            "2871\n",
            "2872\n",
            "2873\n",
            "2874\n",
            "2875\n",
            "2876\n",
            "2877\n",
            "2878\n",
            "2879\n",
            "2880\n",
            "2881\n",
            "2882\n",
            "2883\n",
            "2884\n",
            "2885\n",
            "2886\n",
            "2887\n",
            "2888\n",
            "2889\n",
            "2890\n",
            "2891\n",
            "2892\n",
            "2893\n",
            "2894\n",
            "2895\n",
            "2896\n",
            "2897\n",
            "2898\n",
            "2899\n",
            "2900\n",
            "2901\n",
            "2902\n",
            "2903\n",
            "2904\n",
            "2905\n",
            "2906\n",
            "2907\n",
            "2908\n",
            "2909\n",
            "2910\n",
            "2911\n",
            "2912\n",
            "2913\n",
            "2914\n",
            "2915\n",
            "2916\n",
            "2917\n",
            "2918\n",
            "2919\n",
            "2920\n",
            "2921\n",
            "2922\n",
            "2923\n",
            "2924\n",
            "2925\n",
            "2926\n",
            "2927\n",
            "2928\n",
            "2929\n",
            "2930\n",
            "2931\n",
            "2932\n",
            "2933\n",
            "2934\n",
            "2935\n",
            "2936\n",
            "2937\n",
            "2938\n",
            "2939\n",
            "2940\n",
            "2941\n",
            "2942\n",
            "2943\n",
            "2944\n",
            "2945\n",
            "2946\n",
            "2947\n",
            "2948\n",
            "2949\n",
            "2950\n",
            "2951\n",
            "2952\n",
            "2953\n",
            "2954\n",
            "2955\n",
            "2956\n",
            "2957\n",
            "2958\n",
            "2959\n",
            "2960\n",
            "2961\n",
            "2962\n",
            "2963\n",
            "2964\n",
            "2965\n",
            "2966\n",
            "2967\n",
            "2968\n",
            "2969\n",
            "2970\n",
            "2971\n",
            "2972\n",
            "2973\n",
            "2974\n",
            "2975\n",
            "2976\n",
            "2977\n",
            "2978\n",
            "2979\n",
            "2980\n",
            "2981\n",
            "2982\n",
            "2983\n",
            "2984\n",
            "2985\n",
            "2986\n",
            "2987\n",
            "2988\n",
            "2989\n",
            "2990\n",
            "2991\n",
            "2992\n",
            "2993\n",
            "2994\n",
            "2995\n",
            "2996\n",
            "2997\n",
            "2998\n",
            "2999\n",
            "3000\n",
            "3001\n",
            "3002\n",
            "3003\n",
            "3004\n",
            "3005\n",
            "3006\n",
            "3007\n",
            "3008\n",
            "3009\n",
            "3010\n",
            "3011\n",
            "3012\n",
            "3013\n",
            "3014\n",
            "3015\n",
            "3016\n",
            "3017\n",
            "3018\n",
            "3019\n",
            "3020\n",
            "3021\n",
            "3022\n",
            "3023\n",
            "3024\n",
            "3025\n",
            "3026\n",
            "3027\n",
            "3028\n",
            "3029\n",
            "3030\n",
            "3031\n",
            "3032\n",
            "3033\n",
            "3034\n",
            "3035\n",
            "3036\n",
            "3037\n",
            "3038\n",
            "3039\n",
            "3040\n",
            "3041\n",
            "3042\n",
            "3043\n",
            "3044\n",
            "3045\n",
            "3046\n",
            "3047\n",
            "3048\n",
            "3049\n",
            "3050\n",
            "3051\n",
            "3052\n",
            "3053\n",
            "3054\n",
            "3055\n",
            "3056\n",
            "3057\n",
            "3058\n",
            "3059\n",
            "3060\n",
            "3061\n",
            "3062\n",
            "3063\n",
            "3064\n",
            "3065\n",
            "3066\n",
            "3067\n",
            "3068\n",
            "3069\n",
            "3070\n",
            "3071\n",
            "3072\n",
            "3073\n",
            "3074\n",
            "3075\n",
            "3076\n",
            "3077\n",
            "3078\n",
            "3079\n",
            "3080\n",
            "3081\n",
            "3082\n",
            "3083\n",
            "3084\n",
            "3085\n",
            "3086\n",
            "3087\n",
            "3088\n",
            "3089\n",
            "3090\n",
            "3091\n",
            "3092\n",
            "3093\n",
            "3094\n",
            "3095\n",
            "3096\n",
            "3097\n",
            "3098\n",
            "3099\n",
            "3100\n",
            "3101\n",
            "3102\n",
            "3103\n",
            "3104\n",
            "3105\n",
            "3106\n",
            "3107\n",
            "3108\n",
            "3109\n",
            "3110\n",
            "3111\n",
            "3112\n",
            "3113\n",
            "3114\n",
            "3115\n",
            "3116\n",
            "3117\n",
            "3118\n",
            "3119\n",
            "3120\n",
            "3121\n",
            "3122\n",
            "3123\n",
            "3124\n",
            "3125\n",
            "3126\n",
            "3127\n",
            "3128\n",
            "3129\n",
            "3130\n",
            "3131\n",
            "3132\n",
            "3133\n",
            "3134\n",
            "3135\n",
            "3136\n",
            "3137\n",
            "3138\n",
            "3139\n",
            "3140\n",
            "3141\n",
            "3142\n",
            "3143\n",
            "3144\n",
            "3145\n",
            "3146\n",
            "3147\n",
            "3148\n",
            "3149\n",
            "3150\n",
            "3151\n",
            "3152\n",
            "3153\n",
            "3154\n",
            "3155\n",
            "3156\n",
            "3157\n",
            "3158\n",
            "3159\n",
            "3160\n",
            "3161\n",
            "3162\n",
            "3163\n",
            "3164\n",
            "3165\n",
            "3166\n",
            "3167\n",
            "3168\n",
            "3169\n",
            "3170\n",
            "3171\n",
            "3172\n",
            "3173\n",
            "3174\n",
            "3175\n",
            "3176\n",
            "3177\n",
            "3178\n",
            "3179\n",
            "3180\n",
            "3181\n",
            "3182\n",
            "3183\n",
            "3184\n",
            "3185\n",
            "3186\n",
            "3187\n",
            "3188\n",
            "3189\n",
            "3190\n",
            "3191\n",
            "3192\n",
            "3193\n",
            "3194\n",
            "3195\n",
            "3196\n",
            "3197\n",
            "3198\n",
            "3199\n",
            "3200\n",
            "3201\n",
            "3202\n",
            "3203\n",
            "3204\n",
            "3205\n",
            "3206\n",
            "3207\n",
            "3208\n",
            "3209\n",
            "3210\n",
            "3211\n",
            "3212\n",
            "3213\n",
            "3214\n",
            "3215\n",
            "3216\n",
            "3217\n",
            "3218\n",
            "3219\n",
            "3220\n",
            "3221\n",
            "3222\n",
            "3223\n",
            "3224\n",
            "3225\n",
            "3226\n",
            "3227\n",
            "3228\n",
            "3229\n",
            "3230\n",
            "3231\n",
            "3232\n",
            "3233\n",
            "3234\n",
            "3235\n",
            "3236\n",
            "3237\n",
            "3238\n",
            "3239\n",
            "3240\n",
            "3241\n",
            "3242\n",
            "3243\n",
            "3244\n",
            "3245\n",
            "3246\n",
            "3247\n",
            "3248\n",
            "3249\n",
            "3250\n",
            "3251\n",
            "3252\n",
            "3253\n",
            "3254\n",
            "3255\n",
            "3256\n",
            "3257\n",
            "3258\n",
            "3259\n",
            "3260\n",
            "3261\n",
            "3262\n",
            "3263\n",
            "3264\n",
            "3265\n",
            "3266\n",
            "3267\n",
            "3268\n",
            "3269\n",
            "3270\n",
            "3271\n",
            "3272\n",
            "3273\n",
            "3274\n",
            "3275\n",
            "3276\n",
            "3277\n",
            "3278\n",
            "3279\n",
            "3280\n",
            "3281\n",
            "3282\n",
            "3283\n",
            "3284\n",
            "3285\n",
            "3286\n",
            "3287\n",
            "3288\n",
            "3289\n",
            "3290\n",
            "3291\n",
            "3292\n",
            "3293\n",
            "3294\n",
            "3295\n",
            "3296\n",
            "3297\n",
            "3298\n",
            "3299\n",
            "3300\n",
            "3301\n",
            "3302\n",
            "3303\n",
            "3304\n",
            "3305\n",
            "3306\n",
            "3307\n",
            "3308\n",
            "3309\n",
            "3310\n",
            "3311\n",
            "3312\n",
            "3313\n",
            "3314\n",
            "3315\n",
            "3316\n",
            "3317\n",
            "3318\n",
            "3319\n",
            "3320\n",
            "3321\n",
            "3322\n",
            "3323\n",
            "3324\n",
            "3325\n",
            "3326\n",
            "3327\n",
            "3328\n",
            "3329\n",
            "3330\n",
            "3331\n",
            "3332\n",
            "3333\n",
            "3334\n",
            "3335\n",
            "3336\n",
            "3337\n",
            "3338\n",
            "3339\n",
            "3340\n",
            "3341\n",
            "3342\n",
            "3343\n",
            "3344\n",
            "3345\n",
            "3346\n",
            "3347\n",
            "3348\n",
            "3349\n",
            "3350\n",
            "3351\n",
            "3352\n",
            "3353\n",
            "3354\n",
            "3355\n",
            "3356\n",
            "3357\n",
            "3358\n",
            "3359\n",
            "3360\n",
            "3361\n",
            "3362\n",
            "3363\n",
            "3364\n",
            "3365\n",
            "3366\n",
            "3367\n",
            "3368\n",
            "3369\n",
            "3370\n",
            "3371\n",
            "3372\n",
            "3373\n",
            "3374\n",
            "3375\n",
            "3376\n",
            "3377\n",
            "3378\n",
            "3379\n",
            "3380\n",
            "3381\n",
            "3382\n",
            "3383\n",
            "3384\n",
            "3385\n",
            "3386\n",
            "3387\n",
            "3388\n",
            "3389\n",
            "3390\n",
            "3391\n",
            "3392\n",
            "3393\n",
            "3394\n",
            "3395\n",
            "3396\n",
            "3397\n",
            "3398\n",
            "3399\n",
            "3400\n",
            "3401\n",
            "3402\n",
            "3403\n",
            "3404\n",
            "3405\n",
            "3406\n",
            "3407\n",
            "3408\n",
            "3409\n",
            "3410\n",
            "3411\n",
            "3412\n",
            "3413\n",
            "3414\n",
            "3415\n",
            "3416\n",
            "3417\n",
            "3418\n",
            "3419\n",
            "3420\n",
            "3421\n",
            "3422\n",
            "3423\n",
            "3424\n",
            "3425\n",
            "3426\n",
            "3427\n",
            "3428\n",
            "3429\n",
            "3430\n",
            "3431\n",
            "3432\n",
            "3433\n",
            "3434\n",
            "3435\n",
            "3436\n",
            "3437\n",
            "3438\n",
            "3439\n",
            "3440\n",
            "3441\n",
            "3442\n",
            "3443\n",
            "3444\n",
            "3445\n",
            "3446\n",
            "3447\n",
            "3448\n",
            "3449\n",
            "3450\n",
            "3451\n",
            "3452\n",
            "3453\n",
            "3454\n",
            "3455\n",
            "3456\n",
            "3457\n",
            "3458\n",
            "3459\n",
            "3460\n",
            "3461\n",
            "3462\n",
            "3463\n",
            "3464\n",
            "3465\n",
            "3466\n",
            "3467\n",
            "3468\n",
            "3469\n",
            "3470\n",
            "3471\n",
            "3472\n",
            "3473\n",
            "3474\n",
            "3475\n",
            "3476\n",
            "3477\n",
            "3478\n",
            "3479\n",
            "3480\n",
            "3481\n",
            "3482\n",
            "3483\n",
            "3484\n",
            "3485\n",
            "3486\n",
            "3487\n",
            "3488\n",
            "3489\n",
            "3490\n",
            "3491\n",
            "3492\n",
            "3493\n",
            "3494\n",
            "3495\n",
            "3496\n",
            "3497\n",
            "3498\n",
            "3499\n",
            "3500\n",
            "3501\n",
            "3502\n",
            "3503\n",
            "3504\n",
            "3505\n",
            "3506\n",
            "3507\n",
            "3508\n",
            "3509\n",
            "3510\n",
            "3511\n",
            "3512\n",
            "3513\n",
            "3514\n",
            "3515\n",
            "3516\n",
            "3517\n",
            "3518\n",
            "3519\n",
            "3520\n",
            "3521\n",
            "3522\n",
            "3523\n",
            "3524\n",
            "3525\n",
            "3526\n",
            "3527\n",
            "3528\n",
            "3529\n",
            "3530\n",
            "3531\n",
            "3532\n",
            "3533\n",
            "3534\n",
            "3535\n",
            "3536\n",
            "3537\n",
            "3538\n",
            "3539\n",
            "3540\n",
            "3541\n",
            "3542\n",
            "3543\n",
            "3544\n",
            "3545\n",
            "3546\n",
            "3547\n",
            "3548\n",
            "3549\n",
            "3550\n",
            "3551\n",
            "3552\n",
            "3553\n",
            "3554\n",
            "3555\n",
            "3556\n",
            "3557\n",
            "3558\n",
            "3559\n",
            "3560\n",
            "3561\n",
            "3562\n",
            "3563\n",
            "3564\n",
            "3565\n",
            "3566\n",
            "3567\n",
            "3568\n",
            "3569\n",
            "3570\n",
            "3571\n",
            "3572\n",
            "3573\n",
            "3574\n",
            "3575\n",
            "3576\n",
            "3577\n",
            "3578\n",
            "3579\n",
            "3580\n",
            "3581\n",
            "3582\n",
            "3583\n",
            "3584\n",
            "3585\n",
            "3586\n",
            "3587\n",
            "3588\n",
            "3589\n",
            "3590\n",
            "3591\n",
            "3592\n",
            "3593\n",
            "3594\n",
            "3595\n",
            "3596\n",
            "3597\n",
            "3598\n",
            "3599\n",
            "3600\n",
            "3601\n",
            "3602\n",
            "3603\n",
            "3604\n",
            "3605\n",
            "3606\n",
            "3607\n",
            "3608\n",
            "3609\n",
            "3610\n",
            "3611\n",
            "3612\n",
            "3613\n",
            "3614\n",
            "3615\n",
            "3616\n",
            "3617\n",
            "3618\n",
            "3619\n",
            "3620\n",
            "3621\n",
            "3622\n",
            "3623\n",
            "3624\n",
            "3625\n",
            "3626\n",
            "3627\n",
            "3628\n",
            "3629\n",
            "3630\n",
            "3631\n",
            "3632\n",
            "3633\n",
            "3634\n",
            "3635\n",
            "3636\n",
            "3637\n",
            "3638\n",
            "3639\n",
            "3640\n",
            "3641\n",
            "3642\n",
            "3643\n",
            "3644\n",
            "3645\n",
            "3646\n",
            "3647\n",
            "3648\n",
            "3649\n",
            "3650\n",
            "3651\n",
            "3652\n",
            "3653\n",
            "3654\n",
            "3655\n",
            "3656\n",
            "3657\n",
            "3658\n",
            "3659\n",
            "3660\n",
            "3661\n",
            "3662\n",
            "3663\n",
            "3664\n",
            "3665\n",
            "3666\n",
            "3667\n",
            "3668\n",
            "3669\n",
            "3670\n",
            "3671\n",
            "3672\n",
            "3673\n",
            "3674\n",
            "3675\n",
            "3676\n",
            "3677\n",
            "3678\n",
            "3679\n",
            "3680\n",
            "3681\n",
            "3682\n",
            "3683\n",
            "3684\n",
            "3685\n",
            "3686\n",
            "3687\n",
            "3688\n",
            "3689\n",
            "3690\n",
            "3691\n",
            "3692\n",
            "3693\n",
            "3694\n",
            "3695\n",
            "3696\n",
            "3697\n",
            "3698\n",
            "3699\n",
            "3700\n",
            "3701\n",
            "3702\n",
            "3703\n",
            "3704\n",
            "3705\n",
            "3706\n",
            "3707\n",
            "3708\n",
            "3709\n",
            "3710\n",
            "3711\n",
            "3712\n",
            "3713\n",
            "3714\n",
            "3715\n",
            "3716\n",
            "3717\n",
            "3718\n",
            "3719\n",
            "3720\n",
            "3721\n",
            "3722\n",
            "3723\n",
            "3724\n",
            "3725\n",
            "3726\n",
            "3727\n",
            "3728\n",
            "3729\n",
            "3730\n",
            "3731\n",
            "3732\n",
            "3733\n",
            "3734\n",
            "3735\n",
            "3736\n",
            "3737\n",
            "3738\n",
            "3739\n",
            "3740\n",
            "3741\n",
            "3742\n",
            "3743\n",
            "3744\n",
            "3745\n",
            "3746\n",
            "3747\n",
            "3748\n",
            "3749\n",
            "3750\n",
            "3751\n",
            "3752\n",
            "3753\n",
            "3754\n",
            "3755\n",
            "3756\n",
            "3757\n",
            "3758\n",
            "3759\n",
            "3760\n",
            "3761\n",
            "3762\n",
            "3763\n",
            "3764\n",
            "3765\n",
            "3766\n",
            "3767\n",
            "3768\n",
            "3769\n",
            "3770\n",
            "3771\n",
            "3772\n",
            "3773\n",
            "3774\n",
            "3775\n",
            "3776\n",
            "3777\n",
            "3778\n",
            "3779\n",
            "3780\n",
            "3781\n",
            "3782\n",
            "3783\n",
            "3784\n",
            "3785\n",
            "3786\n",
            "3787\n",
            "3788\n",
            "3789\n",
            "3790\n",
            "3791\n",
            "3792\n",
            "3793\n",
            "3794\n",
            "3795\n",
            "3796\n",
            "3797\n",
            "3798\n",
            "3799\n",
            "3800\n",
            "3801\n",
            "3802\n",
            "3803\n",
            "3804\n",
            "3805\n",
            "3806\n",
            "3807\n",
            "3808\n",
            "3809\n",
            "3810\n",
            "3811\n",
            "3812\n",
            "3813\n",
            "3814\n",
            "3815\n",
            "3816\n",
            "3817\n",
            "3818\n",
            "3819\n",
            "3820\n",
            "3821\n",
            "3822\n",
            "3823\n",
            "3824\n",
            "3825\n",
            "3826\n",
            "3827\n",
            "3828\n",
            "3829\n",
            "3830\n",
            "3831\n",
            "3832\n",
            "3833\n",
            "3834\n",
            "3835\n",
            "3836\n",
            "3837\n",
            "3838\n",
            "3839\n",
            "3840\n",
            "3841\n",
            "3842\n",
            "3843\n",
            "3844\n",
            "3845\n",
            "3846\n",
            "3847\n",
            "3848\n",
            "3849\n",
            "3850\n",
            "3851\n",
            "3852\n",
            "3853\n",
            "3854\n",
            "3855\n",
            "3856\n",
            "3857\n",
            "3858\n",
            "3859\n",
            "3860\n",
            "3861\n",
            "3862\n",
            "3863\n",
            "3864\n",
            "3865\n",
            "3866\n",
            "3867\n",
            "3868\n",
            "3869\n",
            "3870\n",
            "3871\n",
            "3872\n",
            "3873\n",
            "3874\n",
            "3875\n",
            "3876\n",
            "3877\n",
            "3878\n",
            "3879\n",
            "3880\n",
            "3881\n",
            "3882\n",
            "3883\n",
            "3884\n",
            "3885\n",
            "3886\n",
            "3887\n",
            "3888\n",
            "3889\n",
            "3890\n",
            "3891\n",
            "3892\n",
            "3893\n",
            "3894\n",
            "3895\n",
            "3896\n",
            "3897\n",
            "3898\n",
            "3899\n",
            "3900\n",
            "3901\n",
            "3902\n",
            "3903\n",
            "3904\n",
            "3905\n",
            "3906\n",
            "3907\n",
            "3908\n",
            "3909\n",
            "3910\n",
            "3911\n",
            "3912\n",
            "3913\n",
            "3914\n",
            "3915\n",
            "3916\n",
            "3917\n",
            "3918\n",
            "3919\n",
            "3920\n",
            "3921\n",
            "3922\n",
            "3923\n",
            "3924\n",
            "3925\n",
            "3926\n",
            "3927\n",
            "3928\n",
            "3929\n",
            "3930\n",
            "3931\n",
            "3932\n",
            "3933\n",
            "3934\n",
            "3935\n",
            "3936\n",
            "3937\n",
            "3938\n",
            "3939\n",
            "3940\n",
            "3941\n",
            "3942\n",
            "3943\n",
            "3944\n",
            "3945\n",
            "3946\n",
            "3947\n",
            "3948\n",
            "3949\n",
            "3950\n",
            "3951\n",
            "3952\n",
            "3953\n",
            "3954\n",
            "3955\n",
            "3956\n",
            "3957\n",
            "3958\n",
            "3959\n",
            "3960\n",
            "3961\n",
            "3962\n",
            "3963\n",
            "3964\n",
            "3965\n",
            "3966\n",
            "3967\n",
            "3968\n",
            "3969\n",
            "3970\n",
            "3971\n",
            "3972\n",
            "3973\n",
            "3974\n",
            "3975\n",
            "3976\n",
            "3977\n",
            "3978\n",
            "3979\n",
            "3980\n",
            "3981\n",
            "3982\n",
            "3983\n",
            "3984\n",
            "3985\n",
            "3986\n",
            "3987\n",
            "3988\n",
            "3989\n",
            "3990\n",
            "3991\n",
            "3992\n",
            "3993\n",
            "3994\n",
            "3995\n",
            "3996\n",
            "3997\n",
            "3998\n",
            "3999\n",
            "4000\n",
            "4001\n",
            "4002\n",
            "4003\n",
            "4004\n",
            "4005\n",
            "4006\n",
            "4007\n",
            "4008\n",
            "4009\n",
            "4010\n",
            "4011\n",
            "4012\n",
            "4013\n",
            "4014\n",
            "4015\n",
            "4016\n",
            "4017\n",
            "4018\n",
            "4019\n",
            "4020\n",
            "4021\n",
            "4022\n",
            "4023\n",
            "4024\n",
            "4025\n",
            "4026\n",
            "4027\n",
            "4028\n",
            "4029\n",
            "4030\n",
            "4031\n",
            "4032\n",
            "4033\n",
            "4034\n",
            "4035\n",
            "4036\n",
            "4037\n",
            "4038\n",
            "4039\n",
            "4040\n",
            "4041\n",
            "4042\n",
            "4043\n",
            "4044\n",
            "4045\n",
            "4046\n",
            "4047\n",
            "4048\n",
            "4049\n",
            "4050\n",
            "4051\n",
            "4052\n",
            "4053\n",
            "4054\n",
            "4055\n",
            "4056\n",
            "4057\n",
            "4058\n",
            "4059\n",
            "4060\n",
            "4061\n",
            "4062\n",
            "4063\n",
            "4064\n",
            "4065\n",
            "4066\n",
            "4067\n",
            "4068\n",
            "4069\n",
            "4070\n",
            "4071\n",
            "4072\n",
            "4073\n",
            "4074\n",
            "4075\n",
            "4076\n",
            "4077\n",
            "4078\n",
            "4079\n",
            "4080\n",
            "4081\n",
            "4082\n",
            "4083\n",
            "4084\n",
            "4085\n",
            "4086\n",
            "4087\n",
            "4088\n",
            "4089\n",
            "4090\n",
            "4091\n",
            "4092\n",
            "4093\n",
            "4094\n",
            "4095\n",
            "4096\n",
            "4097\n",
            "4098\n",
            "4099\n",
            "4100\n",
            "4101\n",
            "4102\n",
            "4103\n",
            "4104\n",
            "4105\n",
            "4106\n",
            "4107\n",
            "4108\n",
            "4109\n",
            "4110\n",
            "4111\n",
            "4112\n",
            "4113\n",
            "4114\n",
            "4115\n",
            "4116\n",
            "4117\n",
            "4118\n",
            "4119\n",
            "4120\n",
            "4121\n",
            "4122\n",
            "4123\n",
            "4124\n",
            "4125\n",
            "4126\n",
            "4127\n",
            "4128\n",
            "4129\n",
            "4130\n",
            "4131\n",
            "4132\n",
            "4133\n",
            "4134\n",
            "4135\n",
            "4136\n",
            "4137\n",
            "4138\n",
            "4139\n",
            "4140\n",
            "4141\n",
            "4142\n",
            "4143\n",
            "4144\n",
            "4145\n",
            "4146\n",
            "4147\n",
            "4148\n",
            "4149\n",
            "4150\n",
            "4151\n",
            "4152\n",
            "4153\n",
            "4154\n",
            "4155\n",
            "4156\n",
            "4157\n",
            "4158\n",
            "4159\n",
            "4160\n",
            "4161\n",
            "4162\n",
            "4163\n",
            "4164\n",
            "4165\n",
            "4166\n",
            "4167\n",
            "4168\n",
            "4169\n",
            "4170\n",
            "4171\n",
            "4172\n",
            "4173\n",
            "4174\n",
            "4175\n",
            "4176\n",
            "4177\n",
            "4178\n",
            "4179\n",
            "4180\n",
            "4181\n",
            "4182\n",
            "4183\n",
            "4184\n",
            "4185\n",
            "4186\n",
            "4187\n",
            "4188\n",
            "4189\n",
            "4190\n",
            "4191\n",
            "4192\n",
            "4193\n",
            "4194\n",
            "4195\n",
            "4196\n",
            "4197\n",
            "4198\n",
            "4199\n",
            "4200\n",
            "4201\n",
            "4202\n",
            "4203\n",
            "4204\n",
            "4205\n",
            "4206\n",
            "4207\n",
            "4208\n",
            "4209\n",
            "4210\n",
            "4211\n",
            "4212\n",
            "4213\n",
            "4214\n",
            "4215\n",
            "4216\n",
            "4217\n",
            "4218\n",
            "4219\n",
            "4220\n",
            "4221\n",
            "4222\n",
            "4223\n",
            "4224\n",
            "4225\n",
            "4226\n",
            "4227\n",
            "4228\n",
            "4229\n",
            "4230\n",
            "4231\n",
            "4232\n",
            "4233\n",
            "4234\n",
            "4235\n",
            "4236\n",
            "4237\n",
            "4238\n",
            "4239\n",
            "4240\n",
            "4241\n",
            "4242\n",
            "4243\n",
            "4244\n",
            "4245\n",
            "4246\n",
            "4247\n",
            "4248\n",
            "4249\n",
            "4250\n",
            "4251\n",
            "4252\n",
            "4253\n",
            "4254\n",
            "4255\n",
            "4256\n",
            "4257\n",
            "4258\n",
            "4259\n",
            "4260\n",
            "4261\n",
            "4262\n",
            "4263\n",
            "4264\n",
            "4265\n",
            "4266\n",
            "4267\n",
            "4268\n",
            "4269\n",
            "4270\n",
            "4271\n",
            "4272\n",
            "4273\n",
            "4274\n",
            "4275\n",
            "4276\n",
            "4277\n",
            "4278\n",
            "4279\n",
            "4280\n",
            "4281\n",
            "4282\n",
            "4283\n",
            "4284\n",
            "4285\n",
            "4286\n",
            "4287\n",
            "4288\n",
            "4289\n",
            "4290\n",
            "4291\n",
            "4292\n",
            "4293\n",
            "4294\n",
            "4295\n",
            "4296\n",
            "4297\n",
            "4298\n",
            "4299\n",
            "4300\n",
            "4301\n",
            "4302\n",
            "4303\n",
            "4304\n",
            "4305\n",
            "4306\n",
            "4307\n",
            "4308\n",
            "4309\n",
            "4310\n",
            "4311\n",
            "4312\n",
            "4313\n",
            "4314\n",
            "4315\n",
            "4316\n",
            "4317\n",
            "4318\n",
            "4319\n",
            "4320\n",
            "4321\n",
            "4322\n",
            "4323\n",
            "4324\n",
            "4325\n",
            "4326\n",
            "4327\n",
            "4328\n",
            "4329\n",
            "4330\n",
            "4331\n",
            "4332\n",
            "4333\n",
            "4334\n",
            "4335\n",
            "4336\n",
            "4337\n",
            "4338\n",
            "4339\n",
            "4340\n",
            "4341\n",
            "4342\n",
            "4343\n",
            "4344\n",
            "4345\n",
            "4346\n",
            "4347\n",
            "4348\n",
            "4349\n",
            "4350\n",
            "4351\n",
            "4352\n",
            "4353\n",
            "4354\n",
            "4355\n",
            "4356\n",
            "4357\n",
            "4358\n",
            "4359\n",
            "4360\n",
            "4361\n",
            "4362\n",
            "4363\n",
            "4364\n",
            "4365\n",
            "4366\n",
            "4367\n",
            "4368\n",
            "4369\n",
            "4370\n",
            "4371\n",
            "4372\n",
            "4373\n",
            "4374\n",
            "4375\n",
            "4376\n",
            "4377\n",
            "4378\n",
            "4379\n",
            "4380\n",
            "4381\n",
            "4382\n",
            "4383\n",
            "4384\n",
            "4385\n",
            "4386\n",
            "4387\n",
            "4388\n",
            "4389\n",
            "4390\n",
            "4391\n",
            "4392\n",
            "4393\n",
            "4394\n",
            "4395\n",
            "4396\n",
            "4397\n",
            "4398\n",
            "4399\n",
            "4400\n",
            "4401\n",
            "4402\n",
            "4403\n",
            "4404\n",
            "4405\n",
            "4406\n",
            "4407\n",
            "4408\n",
            "4409\n",
            "4410\n",
            "4411\n",
            "4412\n",
            "4413\n",
            "4414\n",
            "4415\n",
            "4416\n",
            "4417\n",
            "4418\n",
            "4419\n",
            "4420\n",
            "4421\n",
            "4422\n",
            "4423\n",
            "4424\n",
            "4425\n",
            "4426\n",
            "4427\n",
            "4428\n",
            "4429\n",
            "4430\n",
            "4431\n",
            "4432\n",
            "4433\n",
            "4434\n",
            "4435\n",
            "4436\n",
            "4437\n",
            "4438\n",
            "4439\n",
            "4440\n",
            "4441\n",
            "4442\n",
            "4443\n",
            "4444\n",
            "4445\n",
            "4446\n",
            "4447\n",
            "4448\n",
            "4449\n",
            "4450\n",
            "4451\n",
            "4452\n",
            "4453\n",
            "4454\n",
            "4455\n",
            "4456\n",
            "4457\n",
            "4458\n",
            "4459\n",
            "4460\n",
            "4461\n",
            "4462\n",
            "4463\n",
            "4464\n",
            "4465\n",
            "4466\n",
            "4467\n",
            "4468\n",
            "4469\n",
            "4470\n",
            "4471\n",
            "4472\n",
            "4473\n",
            "4474\n",
            "4475\n",
            "4476\n",
            "4477\n",
            "4478\n",
            "4479\n",
            "4480\n",
            "4481\n",
            "4482\n",
            "4483\n",
            "4484\n",
            "4485\n",
            "4486\n",
            "4487\n",
            "4488\n",
            "4489\n",
            "4490\n",
            "4491\n",
            "4492\n",
            "4493\n",
            "4494\n",
            "4495\n",
            "4496\n",
            "4497\n",
            "4498\n",
            "4499\n",
            "4500\n",
            "4501\n",
            "4502\n",
            "4503\n",
            "4504\n",
            "4505\n",
            "4506\n",
            "4507\n",
            "4508\n",
            "4509\n",
            "4510\n",
            "4511\n",
            "4512\n",
            "4513\n",
            "4514\n",
            "4515\n",
            "4516\n",
            "4517\n",
            "4518\n",
            "4519\n",
            "4520\n",
            "4521\n",
            "4522\n",
            "4523\n",
            "4524\n",
            "4525\n",
            "4526\n",
            "4527\n",
            "4528\n",
            "4529\n",
            "4530\n",
            "4531\n",
            "4532\n",
            "4533\n",
            "4534\n",
            "4535\n",
            "4536\n",
            "4537\n",
            "4538\n",
            "4539\n",
            "4540\n",
            "4541\n",
            "4542\n",
            "4543\n",
            "4544\n",
            "4545\n",
            "4546\n",
            "4547\n",
            "4548\n",
            "4549\n",
            "4550\n",
            "4551\n",
            "4552\n",
            "4553\n",
            "4554\n",
            "4555\n",
            "4556\n",
            "4557\n",
            "4558\n",
            "4559\n",
            "4560\n",
            "4561\n",
            "4562\n",
            "4563\n",
            "4564\n",
            "4565\n",
            "4566\n",
            "4567\n",
            "4568\n",
            "4569\n",
            "4570\n",
            "4571\n",
            "4572\n",
            "4573\n",
            "4574\n",
            "4575\n",
            "4576\n",
            "4577\n",
            "4578\n",
            "4579\n",
            "4580\n",
            "4581\n",
            "4582\n",
            "4583\n",
            "4584\n",
            "4585\n",
            "4586\n",
            "4587\n",
            "4588\n",
            "4589\n",
            "4590\n",
            "4591\n",
            "4592\n",
            "4593\n",
            "4594\n",
            "4595\n",
            "4596\n",
            "4597\n",
            "4598\n",
            "4599\n",
            "4600\n",
            "4601\n",
            "4602\n",
            "4603\n",
            "4604\n",
            "4605\n",
            "4606\n",
            "4607\n",
            "4608\n",
            "4609\n",
            "4610\n",
            "4611\n",
            "4612\n",
            "4613\n",
            "4614\n",
            "4615\n",
            "4616\n",
            "4617\n",
            "4618\n",
            "4619\n",
            "4620\n",
            "4621\n",
            "4622\n",
            "4623\n",
            "4624\n",
            "4625\n",
            "4626\n",
            "4627\n",
            "4628\n",
            "4629\n",
            "4630\n",
            "4631\n",
            "4632\n",
            "4633\n",
            "4634\n",
            "4635\n",
            "4636\n",
            "4637\n",
            "4638\n",
            "4639\n",
            "4640\n",
            "4641\n",
            "4642\n",
            "4643\n",
            "4644\n",
            "4645\n",
            "4646\n",
            "4647\n",
            "4648\n",
            "4649\n",
            "4650\n",
            "4651\n",
            "4652\n",
            "4653\n",
            "4654\n",
            "4655\n",
            "4656\n",
            "4657\n",
            "4658\n",
            "4659\n",
            "4660\n",
            "4661\n",
            "4662\n",
            "4663\n",
            "4664\n",
            "4665\n",
            "4666\n",
            "4667\n",
            "4668\n",
            "4669\n",
            "4670\n",
            "4671\n",
            "4672\n",
            "4673\n",
            "4674\n",
            "4675\n",
            "4676\n",
            "4677\n",
            "4678\n",
            "4679\n",
            "4680\n",
            "4681\n",
            "4682\n",
            "4683\n",
            "4684\n",
            "4685\n",
            "4686\n",
            "4687\n",
            "4688\n",
            "4689\n",
            "4690\n",
            "4691\n",
            "4692\n",
            "4693\n",
            "4694\n",
            "4695\n",
            "4696\n",
            "4697\n",
            "4698\n",
            "4699\n",
            "4700\n",
            "4701\n",
            "4702\n",
            "4703\n",
            "4704\n",
            "4705\n",
            "4706\n",
            "4707\n",
            "4708\n",
            "4709\n",
            "4710\n",
            "4711\n",
            "4712\n",
            "4713\n",
            "4714\n",
            "4715\n",
            "4716\n",
            "4717\n",
            "4718\n",
            "4719\n",
            "4720\n",
            "4721\n",
            "4722\n",
            "4723\n",
            "4724\n",
            "4725\n",
            "4726\n",
            "4727\n",
            "4728\n",
            "4729\n",
            "4730\n",
            "4731\n",
            "4732\n",
            "4733\n",
            "4734\n",
            "4735\n",
            "4736\n",
            "4737\n",
            "4738\n",
            "4739\n",
            "4740\n",
            "4741\n",
            "4742\n",
            "4743\n",
            "4744\n",
            "4745\n",
            "4746\n",
            "4747\n",
            "4748\n",
            "4749\n",
            "4750\n",
            "4751\n",
            "4752\n",
            "4753\n",
            "4754\n",
            "4755\n",
            "4756\n",
            "4757\n",
            "4758\n",
            "4759\n",
            "4760\n",
            "4761\n",
            "4762\n",
            "4763\n",
            "4764\n",
            "4765\n",
            "4766\n",
            "4767\n",
            "4768\n",
            "4769\n",
            "4770\n",
            "4771\n",
            "4772\n",
            "4773\n",
            "4774\n",
            "4775\n",
            "4776\n",
            "4777\n",
            "4778\n",
            "4779\n",
            "4780\n",
            "4781\n",
            "4782\n",
            "4783\n",
            "4784\n",
            "4785\n",
            "4786\n",
            "4787\n",
            "4788\n",
            "4789\n",
            "4790\n",
            "4791\n",
            "4792\n",
            "4793\n",
            "4794\n",
            "4795\n",
            "4796\n",
            "4797\n",
            "4798\n",
            "4799\n",
            "4800\n",
            "4801\n",
            "4802\n",
            "4803\n",
            "4804\n",
            "4805\n",
            "4806\n",
            "4807\n",
            "4808\n",
            "4809\n",
            "4810\n",
            "4811\n",
            "4812\n",
            "4813\n",
            "4814\n",
            "4815\n",
            "4816\n",
            "4817\n",
            "4818\n",
            "4819\n",
            "4820\n",
            "4821\n",
            "4822\n",
            "4823\n",
            "4824\n",
            "4825\n",
            "4826\n",
            "4827\n",
            "4828\n",
            "4829\n",
            "4830\n",
            "4831\n",
            "4832\n",
            "4833\n",
            "4834\n",
            "4835\n",
            "4836\n",
            "4837\n",
            "4838\n",
            "4839\n",
            "4840\n",
            "4841\n",
            "4842\n",
            "4843\n",
            "4844\n",
            "4845\n",
            "4846\n",
            "4847\n",
            "4848\n",
            "4849\n",
            "4850\n",
            "4851\n",
            "4852\n",
            "4853\n",
            "4854\n",
            "4855\n",
            "4856\n",
            "4857\n",
            "4858\n",
            "4859\n",
            "4860\n",
            "4861\n",
            "4862\n",
            "4863\n",
            "4864\n",
            "4865\n",
            "4866\n",
            "4867\n",
            "4868\n",
            "4869\n",
            "4870\n",
            "4871\n",
            "4872\n",
            "4873\n",
            "4874\n",
            "4875\n",
            "4876\n",
            "4877\n",
            "4878\n",
            "4879\n",
            "4880\n",
            "4881\n",
            "4882\n",
            "4883\n",
            "4884\n",
            "4885\n",
            "4886\n",
            "4887\n",
            "4888\n",
            "4889\n",
            "4890\n",
            "4891\n",
            "4892\n",
            "4893\n",
            "4894\n",
            "4895\n",
            "4896\n",
            "4897\n",
            "4898\n",
            "4899\n",
            "4900\n",
            "4901\n",
            "4902\n",
            "4903\n",
            "4904\n",
            "4905\n",
            "4906\n",
            "4907\n",
            "4908\n",
            "4909\n",
            "4910\n",
            "4911\n",
            "4912\n",
            "4913\n",
            "4914\n",
            "4915\n",
            "4916\n",
            "4917\n",
            "4918\n",
            "4919\n",
            "4920\n",
            "4921\n",
            "4922\n",
            "4923\n",
            "4924\n",
            "4925\n",
            "4926\n",
            "4927\n",
            "4928\n",
            "4929\n",
            "4930\n",
            "4931\n",
            "4932\n",
            "4933\n",
            "4934\n",
            "4935\n",
            "4936\n",
            "4937\n",
            "4938\n",
            "4939\n",
            "4940\n",
            "4941\n",
            "4942\n",
            "4943\n",
            "4944\n",
            "4945\n",
            "4946\n",
            "4947\n",
            "4948\n",
            "4949\n",
            "4950\n",
            "4951\n",
            "4952\n",
            "4953\n",
            "4954\n",
            "4955\n",
            "4956\n",
            "4957\n",
            "4958\n",
            "4959\n",
            "4960\n",
            "4961\n",
            "4962\n",
            "4963\n",
            "4964\n",
            "4965\n",
            "4966\n",
            "4967\n",
            "4968\n",
            "4969\n",
            "4970\n",
            "4971\n",
            "4972\n",
            "4973\n",
            "4974\n",
            "4975\n",
            "4976\n",
            "4977\n",
            "4978\n",
            "4979\n",
            "4980\n",
            "4981\n",
            "4982\n",
            "4983\n",
            "4984\n",
            "4985\n",
            "4986\n",
            "4987\n",
            "4988\n",
            "4989\n",
            "4990\n",
            "4991\n",
            "4992\n",
            "4993\n",
            "4994\n",
            "4995\n",
            "4996\n",
            "4997\n",
            "4998\n",
            "4999\n",
            "5000\n",
            "5001\n",
            "5002\n",
            "5003\n",
            "5004\n",
            "5005\n",
            "5006\n",
            "5007\n",
            "5008\n",
            "5009\n",
            "5010\n",
            "5011\n",
            "5012\n",
            "5013\n",
            "5014\n",
            "5015\n",
            "5016\n",
            "5017\n",
            "5018\n",
            "5019\n",
            "5020\n",
            "5021\n",
            "5022\n",
            "5023\n",
            "5024\n",
            "5025\n",
            "5026\n",
            "5027\n",
            "5028\n",
            "5029\n",
            "5030\n",
            "5031\n",
            "5032\n",
            "5033\n",
            "5034\n",
            "5035\n",
            "5036\n",
            "5037\n",
            "5038\n",
            "5039\n",
            "5040\n",
            "5041\n",
            "5042\n",
            "5043\n",
            "5044\n",
            "5045\n",
            "5046\n",
            "5047\n",
            "5048\n",
            "5049\n",
            "5050\n",
            "5051\n",
            "5052\n",
            "5053\n",
            "5054\n",
            "5055\n",
            "5056\n",
            "5057\n",
            "5058\n",
            "5059\n",
            "5060\n",
            "5061\n",
            "5062\n",
            "5063\n",
            "5064\n",
            "5065\n",
            "5066\n",
            "5067\n",
            "5068\n",
            "5069\n",
            "5070\n",
            "5071\n",
            "5072\n",
            "5073\n",
            "5074\n",
            "5075\n",
            "5076\n",
            "5077\n",
            "5078\n",
            "5079\n",
            "5080\n",
            "5081\n",
            "5082\n",
            "5083\n",
            "5084\n",
            "5085\n",
            "5086\n",
            "5087\n",
            "5088\n",
            "5089\n",
            "5090\n",
            "5091\n",
            "5092\n",
            "5093\n",
            "5094\n",
            "5095\n",
            "5096\n",
            "5097\n",
            "5098\n",
            "5099\n",
            "5100\n",
            "5101\n",
            "5102\n",
            "5103\n",
            "5104\n",
            "5105\n",
            "5106\n",
            "5107\n",
            "5108\n",
            "5109\n",
            "5110\n",
            "5111\n",
            "5112\n",
            "5113\n",
            "5114\n",
            "5115\n",
            "5116\n",
            "5117\n",
            "5118\n",
            "5119\n",
            "5120\n",
            "5121\n",
            "5122\n",
            "5123\n",
            "5124\n",
            "5125\n",
            "5126\n",
            "5127\n",
            "5128\n",
            "5129\n",
            "5130\n",
            "5131\n",
            "5132\n",
            "5133\n",
            "5134\n",
            "5135\n",
            "5136\n",
            "5137\n",
            "5138\n",
            "5139\n",
            "5140\n",
            "5141\n",
            "5142\n",
            "5143\n",
            "5144\n",
            "5145\n",
            "5146\n",
            "5147\n",
            "5148\n",
            "5149\n",
            "5150\n",
            "5151\n",
            "5152\n",
            "5153\n",
            "5154\n",
            "5155\n",
            "5156\n",
            "5157\n",
            "5158\n",
            "5159\n",
            "5160\n",
            "5161\n",
            "5162\n",
            "5163\n",
            "5164\n",
            "5165\n",
            "5166\n",
            "5167\n",
            "5168\n",
            "5169\n",
            "5170\n",
            "5171\n",
            "5172\n",
            "5173\n",
            "5174\n",
            "5175\n",
            "5176\n",
            "5177\n",
            "5178\n",
            "5179\n",
            "5180\n",
            "5181\n",
            "5182\n",
            "5183\n",
            "5184\n",
            "5185\n",
            "5186\n",
            "5187\n",
            "5188\n",
            "5189\n",
            "5190\n",
            "5191\n",
            "5192\n",
            "5193\n",
            "5194\n",
            "5195\n",
            "5196\n",
            "5197\n",
            "5198\n",
            "5199\n",
            "5200\n",
            "5201\n",
            "5202\n",
            "5203\n",
            "5204\n",
            "5205\n",
            "5206\n",
            "5207\n",
            "5208\n",
            "5209\n",
            "5210\n",
            "5211\n",
            "5212\n",
            "5213\n",
            "5214\n",
            "5215\n",
            "5216\n",
            "5217\n",
            "5218\n",
            "5219\n",
            "5220\n",
            "5221\n",
            "5222\n",
            "5223\n",
            "5224\n",
            "5225\n",
            "5226\n",
            "5227\n",
            "5228\n",
            "5229\n",
            "5230\n",
            "5231\n",
            "5232\n",
            "5233\n",
            "5234\n",
            "5235\n",
            "5236\n",
            "5237\n",
            "5238\n",
            "5239\n",
            "5240\n",
            "5241\n",
            "5242\n",
            "5243\n",
            "5244\n",
            "5245\n",
            "5246\n",
            "5247\n",
            "5248\n",
            "5249\n",
            "5250\n",
            "5251\n",
            "5252\n",
            "5253\n",
            "5254\n",
            "5255\n",
            "5256\n",
            "5257\n",
            "5258\n",
            "5259\n",
            "5260\n",
            "5261\n",
            "5262\n",
            "5263\n",
            "5264\n",
            "5265\n",
            "5266\n",
            "5267\n",
            "5268\n",
            "5269\n",
            "5270\n",
            "5271\n",
            "5272\n",
            "5273\n",
            "5274\n",
            "5275\n",
            "5276\n",
            "5277\n",
            "5278\n",
            "5279\n",
            "5280\n",
            "5281\n",
            "5282\n",
            "5283\n",
            "5284\n",
            "5285\n",
            "5286\n",
            "5287\n",
            "5288\n",
            "5289\n",
            "5290\n",
            "5291\n",
            "5292\n",
            "5293\n",
            "5294\n",
            "5295\n",
            "5296\n",
            "5297\n",
            "5298\n",
            "5299\n",
            "5300\n",
            "5301\n",
            "5302\n",
            "5303\n",
            "5304\n",
            "5305\n",
            "5306\n",
            "5307\n",
            "5308\n",
            "5309\n",
            "5310\n",
            "5311\n",
            "5312\n",
            "5313\n",
            "5314\n",
            "5315\n",
            "5316\n",
            "5317\n",
            "5318\n",
            "5319\n",
            "5320\n",
            "5321\n",
            "5322\n",
            "5323\n",
            "5324\n",
            "5325\n",
            "5326\n",
            "5327\n",
            "5328\n",
            "5329\n",
            "5330\n",
            "5331\n",
            "5332\n",
            "5333\n",
            "5334\n",
            "5335\n",
            "5336\n",
            "5337\n",
            "5338\n",
            "5339\n",
            "5340\n",
            "5341\n",
            "5342\n",
            "5343\n",
            "5344\n",
            "5345\n",
            "5346\n",
            "5347\n",
            "5348\n",
            "5349\n",
            "5350\n",
            "5351\n",
            "5352\n",
            "5353\n",
            "5354\n",
            "5355\n",
            "5356\n",
            "5357\n",
            "5358\n",
            "5359\n",
            "5360\n",
            "5361\n",
            "5362\n",
            "5363\n",
            "5364\n",
            "5365\n",
            "5366\n",
            "5367\n",
            "5368\n",
            "5369\n",
            "5370\n",
            "5371\n",
            "5372\n",
            "5373\n",
            "5374\n",
            "5375\n",
            "5376\n",
            "5377\n",
            "5378\n",
            "5379\n",
            "5380\n",
            "5381\n",
            "5382\n",
            "5383\n",
            "5384\n",
            "5385\n",
            "5386\n",
            "5387\n",
            "5388\n",
            "5389\n",
            "5390\n",
            "5391\n",
            "5392\n",
            "5393\n",
            "5394\n",
            "5395\n",
            "5396\n",
            "5397\n",
            "5398\n",
            "5399\n",
            "5400\n",
            "5401\n",
            "5402\n",
            "5403\n",
            "5404\n",
            "5405\n",
            "5406\n",
            "5407\n",
            "5408\n",
            "5409\n",
            "5410\n",
            "5411\n",
            "5412\n",
            "5413\n",
            "5414\n",
            "5415\n",
            "5416\n",
            "5417\n",
            "5418\n",
            "5419\n",
            "5420\n",
            "5421\n",
            "5422\n",
            "5423\n",
            "5424\n",
            "5425\n",
            "5426\n",
            "5427\n",
            "5428\n",
            "5429\n",
            "5430\n",
            "5431\n",
            "5432\n",
            "5433\n",
            "5434\n",
            "5435\n",
            "5436\n",
            "5437\n",
            "5438\n",
            "5439\n",
            "5440\n",
            "5441\n",
            "5442\n",
            "5443\n",
            "5444\n",
            "5445\n",
            "5446\n",
            "5447\n",
            "5448\n",
            "5449\n",
            "5450\n",
            "5451\n",
            "5452\n",
            "5453\n",
            "5454\n",
            "5455\n",
            "5456\n",
            "5457\n",
            "5458\n",
            "5459\n",
            "5460\n",
            "5461\n",
            "5462\n",
            "5463\n",
            "5464\n",
            "5465\n",
            "5466\n",
            "5467\n",
            "5468\n",
            "5469\n",
            "5470\n",
            "5471\n",
            "5472\n",
            "5473\n",
            "5474\n",
            "5475\n",
            "5476\n",
            "5477\n",
            "5478\n",
            "5479\n",
            "5480\n",
            "5481\n",
            "5482\n",
            "5483\n",
            "5484\n",
            "5485\n",
            "5486\n",
            "5487\n",
            "5488\n",
            "5489\n",
            "5490\n",
            "5491\n",
            "5492\n",
            "5493\n",
            "5494\n",
            "5495\n",
            "5496\n",
            "5497\n",
            "5498\n",
            "5499\n",
            "5500\n",
            "5501\n",
            "5502\n",
            "5503\n",
            "5504\n",
            "5505\n",
            "5506\n",
            "5507\n",
            "5508\n",
            "5509\n",
            "5510\n",
            "5511\n",
            "5512\n",
            "5513\n",
            "5514\n",
            "5515\n",
            "5516\n",
            "5517\n",
            "5518\n",
            "5519\n",
            "5520\n",
            "5521\n",
            "5522\n",
            "5523\n",
            "5524\n",
            "5525\n",
            "5526\n",
            "5527\n",
            "5528\n",
            "5529\n",
            "5530\n",
            "5531\n",
            "5532\n",
            "5533\n",
            "5534\n",
            "5535\n",
            "5536\n",
            "5537\n",
            "5538\n",
            "5539\n",
            "5540\n",
            "5541\n",
            "5542\n",
            "5543\n",
            "5544\n",
            "5545\n",
            "5546\n",
            "5547\n",
            "5548\n",
            "5549\n",
            "5550\n",
            "5551\n",
            "5552\n",
            "5553\n",
            "5554\n",
            "5555\n",
            "5556\n",
            "5557\n",
            "5558\n",
            "5559\n",
            "5560\n",
            "5561\n",
            "5562\n",
            "5563\n",
            "5564\n",
            "5565\n",
            "5566\n",
            "5567\n",
            "5568\n",
            "5569\n",
            "5570\n",
            "5571\n",
            "5572\n",
            "5573\n",
            "5574\n",
            "5575\n",
            "5576\n",
            "5577\n",
            "5578\n",
            "5579\n",
            "5580\n",
            "5581\n",
            "5582\n",
            "5583\n",
            "5584\n",
            "5585\n",
            "5586\n",
            "5587\n",
            "5588\n",
            "5589\n",
            "5590\n",
            "5591\n",
            "5592\n",
            "5593\n",
            "5594\n",
            "5595\n",
            "5596\n",
            "5597\n",
            "5598\n",
            "5599\n",
            "5600\n",
            "5601\n",
            "5602\n",
            "5603\n",
            "5604\n",
            "5605\n",
            "5606\n",
            "5607\n",
            "5608\n",
            "5609\n",
            "5610\n",
            "5611\n",
            "5612\n",
            "5613\n",
            "5614\n",
            "5615\n",
            "5616\n",
            "5617\n",
            "5618\n",
            "5619\n",
            "5620\n",
            "5621\n",
            "5622\n",
            "5623\n",
            "5624\n",
            "5625\n",
            "5626\n",
            "5627\n",
            "5628\n",
            "5629\n",
            "5630\n",
            "5631\n",
            "5632\n",
            "5633\n",
            "5634\n",
            "5635\n",
            "5636\n",
            "5637\n",
            "5638\n",
            "5639\n",
            "5640\n",
            "5641\n",
            "5642\n",
            "5643\n",
            "5644\n",
            "5645\n",
            "5646\n",
            "5647\n",
            "5648\n",
            "5649\n",
            "5650\n",
            "5651\n",
            "5652\n",
            "5653\n",
            "5654\n",
            "5655\n",
            "5656\n",
            "5657\n",
            "5658\n",
            "5659\n",
            "5660\n",
            "5661\n",
            "5662\n",
            "5663\n",
            "5664\n",
            "5665\n",
            "5666\n",
            "5667\n",
            "5668\n",
            "5669\n",
            "5670\n",
            "5671\n",
            "5672\n",
            "5673\n",
            "5674\n",
            "5675\n",
            "5676\n",
            "5677\n",
            "5678\n",
            "5679\n",
            "5680\n",
            "5681\n",
            "5682\n",
            "5683\n",
            "5684\n",
            "5685\n",
            "5686\n",
            "5687\n",
            "5688\n",
            "5689\n",
            "5690\n",
            "5691\n",
            "5692\n",
            "5693\n",
            "5694\n",
            "5695\n",
            "5696\n",
            "5697\n",
            "5698\n",
            "5699\n",
            "5700\n",
            "5701\n",
            "5702\n",
            "5703\n",
            "5704\n",
            "5705\n",
            "5706\n",
            "5707\n",
            "5708\n",
            "5709\n",
            "5710\n",
            "5711\n",
            "5712\n",
            "5713\n",
            "5714\n",
            "5715\n",
            "5716\n",
            "5717\n",
            "5718\n",
            "5719\n",
            "5720\n",
            "5721\n",
            "5722\n",
            "5723\n",
            "5724\n",
            "5725\n",
            "5726\n",
            "5727\n",
            "5728\n",
            "5729\n",
            "5730\n",
            "5731\n",
            "5732\n",
            "5733\n",
            "5734\n",
            "5735\n",
            "5736\n",
            "5737\n",
            "5738\n",
            "5739\n",
            "5740\n",
            "5741\n",
            "5742\n",
            "5743\n",
            "5744\n",
            "5745\n",
            "5746\n",
            "5747\n",
            "5748\n",
            "5749\n",
            "5750\n",
            "5751\n",
            "5752\n",
            "5753\n",
            "5754\n",
            "5755\n",
            "5756\n",
            "5757\n",
            "5758\n",
            "5759\n",
            "5760\n",
            "5761\n",
            "5762\n",
            "5763\n",
            "5764\n",
            "5765\n",
            "5766\n",
            "5767\n",
            "5768\n",
            "5769\n",
            "5770\n",
            "5771\n",
            "5772\n",
            "5773\n",
            "5774\n",
            "5775\n",
            "5776\n",
            "5777\n",
            "5778\n",
            "5779\n",
            "5780\n",
            "5781\n",
            "5782\n",
            "5783\n",
            "5784\n",
            "5785\n",
            "5786\n",
            "5787\n",
            "5788\n",
            "5789\n",
            "5790\n",
            "5791\n",
            "5792\n",
            "5793\n",
            "5794\n",
            "5795\n",
            "5796\n",
            "5797\n",
            "5798\n",
            "5799\n",
            "5800\n",
            "5801\n",
            "5802\n",
            "5803\n",
            "5804\n",
            "5805\n",
            "5806\n",
            "5807\n",
            "5808\n",
            "5809\n",
            "5810\n",
            "5811\n",
            "5812\n",
            "5813\n",
            "5814\n",
            "5815\n",
            "5816\n",
            "5817\n",
            "5818\n",
            "5819\n",
            "5820\n",
            "5821\n",
            "5822\n",
            "5823\n",
            "5824\n",
            "5825\n",
            "5826\n",
            "5827\n",
            "5828\n",
            "5829\n",
            "5830\n",
            "5831\n",
            "5832\n",
            "5833\n",
            "5834\n",
            "5835\n",
            "5836\n",
            "5837\n",
            "5838\n",
            "5839\n",
            "5840\n",
            "5841\n",
            "5842\n",
            "5843\n",
            "5844\n",
            "5845\n",
            "5846\n",
            "5847\n",
            "5848\n",
            "5849\n",
            "5850\n",
            "5851\n",
            "5852\n",
            "5853\n",
            "5854\n",
            "5855\n",
            "5856\n",
            "5857\n",
            "5858\n",
            "5859\n",
            "5860\n",
            "5861\n",
            "5862\n",
            "5863\n",
            "5864\n",
            "5865\n",
            "5866\n",
            "5867\n",
            "5868\n",
            "5869\n",
            "5870\n",
            "5871\n",
            "5872\n",
            "5873\n",
            "5874\n",
            "5875\n",
            "5876\n",
            "5877\n",
            "5878\n",
            "5879\n",
            "5880\n",
            "5881\n",
            "5882\n",
            "5883\n",
            "5884\n",
            "5885\n",
            "5886\n",
            "5887\n",
            "5888\n",
            "5889\n",
            "5890\n",
            "5891\n",
            "5892\n",
            "5893\n",
            "5894\n",
            "5895\n",
            "5896\n",
            "5897\n",
            "5898\n",
            "5899\n",
            "5900\n",
            "5901\n",
            "5902\n",
            "5903\n",
            "5904\n",
            "5905\n",
            "5906\n",
            "5907\n",
            "5908\n",
            "5909\n",
            "5910\n",
            "5911\n",
            "5912\n",
            "5913\n",
            "5914\n",
            "5915\n",
            "5916\n",
            "5917\n",
            "5918\n",
            "5919\n",
            "5920\n",
            "5921\n",
            "5922\n",
            "5923\n",
            "5924\n",
            "5925\n",
            "5926\n",
            "5927\n",
            "5928\n",
            "5929\n",
            "5930\n",
            "5931\n",
            "5932\n",
            "5933\n",
            "5934\n",
            "5935\n",
            "5936\n",
            "5937\n",
            "5938\n",
            "5939\n",
            "5940\n",
            "5941\n",
            "5942\n",
            "5943\n",
            "5944\n",
            "5945\n",
            "5946\n",
            "5947\n",
            "5948\n",
            "5949\n",
            "5950\n",
            "5951\n",
            "5952\n",
            "5953\n",
            "5954\n",
            "5955\n",
            "5956\n",
            "5957\n",
            "5958\n",
            "5959\n",
            "5960\n",
            "5961\n",
            "5962\n",
            "5963\n",
            "5964\n",
            "5965\n",
            "5966\n",
            "5967\n",
            "5968\n",
            "5969\n",
            "5970\n",
            "5971\n",
            "5972\n",
            "5973\n",
            "5974\n",
            "5975\n",
            "5976\n",
            "5977\n",
            "5978\n",
            "5979\n",
            "5980\n",
            "5981\n",
            "5982\n",
            "5983\n",
            "5984\n",
            "5985\n",
            "5986\n",
            "5987\n",
            "5988\n",
            "5989\n",
            "5990\n",
            "5991\n",
            "5992\n",
            "5993\n",
            "5994\n",
            "5995\n",
            "5996\n",
            "5997\n",
            "5998\n",
            "5999\n",
            "6000\n",
            "6001\n",
            "6002\n",
            "6003\n",
            "6004\n",
            "6005\n",
            "6006\n",
            "6007\n",
            "6008\n",
            "6009\n",
            "6010\n",
            "6011\n",
            "6012\n",
            "6013\n",
            "6014\n",
            "6015\n",
            "6016\n",
            "6017\n",
            "6018\n",
            "6019\n",
            "6020\n",
            "6021\n",
            "6022\n",
            "6023\n",
            "6024\n",
            "6025\n",
            "6026\n",
            "6027\n",
            "6028\n",
            "6029\n",
            "6030\n",
            "6031\n",
            "6032\n",
            "6033\n",
            "6034\n",
            "6035\n",
            "6036\n",
            "6037\n",
            "6038\n",
            "6039\n",
            "6040\n",
            "6041\n",
            "6042\n",
            "6043\n",
            "6044\n",
            "6045\n",
            "6046\n",
            "6047\n",
            "6048\n",
            "6049\n",
            "6050\n",
            "6051\n",
            "6052\n",
            "6053\n",
            "6054\n",
            "6055\n",
            "6056\n",
            "6057\n",
            "6058\n",
            "6059\n",
            "6060\n",
            "6061\n",
            "6062\n",
            "6063\n",
            "6064\n",
            "6065\n",
            "6066\n",
            "6067\n",
            "6068\n",
            "6069\n",
            "6070\n",
            "6071\n",
            "6072\n",
            "6073\n",
            "6074\n",
            "6075\n",
            "6076\n",
            "6077\n",
            "6078\n",
            "6079\n",
            "6080\n",
            "6081\n",
            "6082\n",
            "6083\n",
            "6084\n",
            "6085\n",
            "6086\n",
            "6087\n",
            "6088\n",
            "6089\n",
            "6090\n",
            "6091\n",
            "6092\n",
            "6093\n",
            "6094\n",
            "6095\n",
            "6096\n",
            "6097\n",
            "6098\n",
            "6099\n",
            "6100\n",
            "6101\n",
            "6102\n",
            "6103\n",
            "6104\n",
            "6105\n",
            "6106\n",
            "6107\n",
            "6108\n",
            "6109\n",
            "6110\n",
            "6111\n",
            "6112\n",
            "6113\n",
            "6114\n",
            "6115\n",
            "6116\n",
            "6117\n",
            "6118\n",
            "6119\n",
            "6120\n",
            "6121\n",
            "6122\n",
            "6123\n",
            "6124\n",
            "6125\n",
            "6126\n",
            "6127\n",
            "6128\n",
            "6129\n",
            "6130\n",
            "6131\n",
            "6132\n",
            "6133\n",
            "6134\n",
            "6135\n",
            "6136\n",
            "6137\n",
            "6138\n",
            "6139\n",
            "6140\n",
            "6141\n",
            "6142\n",
            "6143\n",
            "6144\n",
            "6145\n",
            "6146\n",
            "6147\n",
            "6148\n",
            "6149\n",
            "6150\n",
            "6151\n",
            "6152\n",
            "6153\n",
            "6154\n",
            "6155\n",
            "6156\n",
            "6157\n",
            "6158\n",
            "6159\n",
            "6160\n",
            "6161\n",
            "6162\n",
            "6163\n",
            "6164\n",
            "6165\n",
            "6166\n",
            "6167\n",
            "6168\n",
            "6169\n",
            "6170\n",
            "6171\n",
            "6172\n",
            "6173\n",
            "6174\n",
            "6175\n",
            "6176\n",
            "6177\n",
            "6178\n",
            "6179\n",
            "6180\n",
            "6181\n",
            "6182\n",
            "6183\n",
            "6184\n",
            "6185\n",
            "6186\n",
            "6187\n",
            "6188\n",
            "6189\n",
            "6190\n",
            "6191\n",
            "6192\n",
            "6193\n",
            "6194\n",
            "6195\n",
            "6196\n",
            "6197\n",
            "6198\n",
            "6199\n",
            "6200\n",
            "6201\n",
            "6202\n",
            "6203\n",
            "6204\n",
            "6205\n",
            "6206\n",
            "6207\n",
            "6208\n",
            "6209\n",
            "6210\n",
            "6211\n",
            "6212\n",
            "6213\n",
            "6214\n",
            "6215\n",
            "6216\n",
            "6217\n",
            "6218\n",
            "6219\n",
            "6220\n",
            "6221\n",
            "6222\n",
            "6223\n",
            "6224\n",
            "6225\n",
            "6226\n",
            "6227\n",
            "6228\n",
            "6229\n",
            "6230\n",
            "6231\n",
            "6232\n",
            "6233\n",
            "6234\n",
            "6235\n",
            "6236\n",
            "6237\n",
            "6238\n",
            "6239\n",
            "6240\n",
            "6241\n",
            "6242\n",
            "6243\n",
            "6244\n",
            "6245\n",
            "6246\n",
            "6247\n",
            "6248\n",
            "6249\n",
            "6250\n",
            "6251\n",
            "6252\n",
            "6253\n",
            "6254\n",
            "6255\n",
            "6256\n",
            "6257\n",
            "6258\n",
            "6259\n",
            "6260\n",
            "6261\n",
            "6262\n",
            "6263\n",
            "6264\n",
            "6265\n",
            "6266\n",
            "6267\n",
            "6268\n",
            "6269\n",
            "6270\n",
            "6271\n",
            "6272\n",
            "6273\n",
            "6274\n",
            "6275\n",
            "6276\n",
            "6277\n",
            "6278\n",
            "6279\n",
            "6280\n",
            "6281\n",
            "6282\n",
            "6283\n",
            "6284\n",
            "6285\n",
            "6286\n",
            "6287\n",
            "6288\n",
            "6289\n",
            "6290\n",
            "6291\n",
            "6292\n",
            "6293\n",
            "6294\n",
            "6295\n",
            "6296\n",
            "6297\n",
            "6298\n",
            "6299\n",
            "6300\n",
            "6301\n",
            "6302\n",
            "6303\n",
            "6304\n",
            "6305\n",
            "6306\n",
            "6307\n",
            "6308\n",
            "6309\n",
            "6310\n",
            "6311\n",
            "6312\n",
            "6313\n",
            "6314\n",
            "6315\n",
            "6316\n",
            "6317\n",
            "6318\n",
            "6319\n",
            "6320\n",
            "6321\n",
            "6322\n",
            "6323\n",
            "6324\n",
            "6325\n",
            "6326\n",
            "6327\n",
            "6328\n",
            "6329\n",
            "6330\n",
            "6331\n",
            "6332\n",
            "6333\n",
            "6334\n",
            "6335\n",
            "6336\n",
            "6337\n",
            "6338\n",
            "6339\n",
            "6340\n",
            "6341\n",
            "6342\n",
            "6343\n",
            "6344\n",
            "6345\n",
            "6346\n",
            "6347\n",
            "6348\n",
            "6349\n",
            "6350\n",
            "6351\n",
            "6352\n",
            "6353\n",
            "6354\n",
            "6355\n",
            "6356\n",
            "6357\n",
            "6358\n",
            "6359\n",
            "6360\n",
            "6361\n",
            "6362\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Icf2KTonw65-",
        "colab_type": "code",
        "outputId": "10c24d59-2db2-4a94-aa71-d21c40e35b3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(y_train)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['neutral', 'neutral', 'very_positive', 'positive', 'positive', 'negative', 'positive', 'neutral', 'positive', 'neutral', 'negative', 'positive', 'neutral', 'neutral', 'negative', 'neutral', 'very_positive', 'positive', 'positive', 'neutral', 'negative', 'neutral', 'very_positive', 'positive', 'positive', 'positive', 'neutral', 'neutral', 'positive', 'very_positive', 'positive', 'neutral', 'positive', 'very_positive', 'very_positive', 'very_positive', 'neutral', 'neutral', 'very_negative', 'negative', 'very_positive', 'very_positive', 'very_positive', 'positive', 'negative', 'neutral', 'very_positive', 'very_positive', 'positive', 'neutral', 'negative', 'positive', 'neutral', 'very_positive', 'positive', 'positive', 'very_positive', 'neutral', 'neutral', 'neutral', 'negative', 'positive', 'neutral', 'positive', 'very_positive', 'neutral', 'neutral', 'positive', 'very_positive', 'positive', 'neutral', 'very_positive', 'positive', 'very_positive', 'neutral', 'positive', 'neutral', 'very_positive', 'positive', 'positive', 'positive', 'neutral', 'positive', 'neutral', 'positive', 'positive', 'neutral', 'negative', 'very_positive', 'neutral', 'positive', 'positive', 'negative', 'positive', 'neutral', 'positive', 'neutral', 'neutral', 'positive', 'positive', 'neutral', 'neutral', 'positive', 'positive', 'positive', 'neutral', 'positive', 'negative', 'positive', 'very_positive', 'neutral', 'positive', 'positive', 'neutral', 'positive', 'neutral', 'positive', 'positive', 'positive', 'neutral', 'very_positive', 'positive', 'neutral', 'very_positive', 'neutral', 'neutral', 'negative', 'positive', 'neutral', 'neutral', 'neutral', 'positive', 'neutral', 'neutral', 'very_positive', 'neutral', 'very_positive', 'positive', 'neutral', 'positive', 'neutral', 'very_positive', 'very_positive', 'neutral', 'positive', 'neutral', 'very_positive', 'very_positive', 'very_positive', 'positive', 'very_positive', 'positive', 'neutral', 'neutral', 'positive', 'very_positive', 'positive', 'positive', 'very_positive', 'positive', 'neutral', 'negative', 'positive', 'neutral', 'very_positive', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'positive', 'positive', 'positive', 'neutral', 'very_positive', 'positive', 'neutral', 'positive', 'positive', 'positive', 'positive', 'positive', 'neutral', 'positive', 'positive', 'positive', 'positive', 'very_negative', 'very_positive', 'very_positive', 'positive', 'positive', 'positive', 'positive', 'neutral', 'positive', 'positive', 'neutral', 'neutral', 'neutral', 'positive', 'positive', 'neutral', 'neutral', 'very_negative', 'neutral', 'negative', 'positive', 'neutral', 'positive', 'positive', 'neutral', 'positive', 'positive', 'very_positive', 'neutral', 'negative', 'positive', 'negative', 'very_negative', 'positive', 'neutral', 'neutral', 'neutral', 'positive', 'neutral', 'positive', 'positive', 'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'positive', 'very_positive', 'neutral', 'positive', 'positive', 'neutral', 'neutral', 'positive', 'positive', 'positive', 'very_positive', 'negative', 'neutral', 'very_positive', 'neutral', 'positive', 'positive', 'neutral', 'neutral', 'neutral', 'positive', 'positive', 'neutral', 'very_positive', 'positive', 'positive', 'negative', 'neutral', 'neutral', 'very_positive', 'positive', 'neutral', 'very_positive', 'neutral', 'positive', 'positive', 'neutral', 'positive', 'positive', 'very_positive', 'neutral', 'very_positive', 'neutral', 'neutral', 'very_positive', 'neutral', 'very_negative', 'neutral', 'neutral', 'neutral', 'neutral', 'very_positive', 'neutral', 'very_negative', 'positive', 'very_positive', 'positive', 'negative', 'very_negative', 'positive', 'positive', 'neutral', 'negative', 'positive', 'very_positive', 'neutral', 'negative', 'neutral', 'very_positive', 'very_positive', 'very_positive', 'positive', 'positive', 'positive', 'very_positive', 'positive', 'negative', 'positive', 'negative', 'positive', 'neutral', 'positive', 'positive', 'positive', 'positive', 'positive', 'neutral', 'very_positive', 'positive', 'neutral', 'positive', 'positive', 'positive', 'positive', 'neutral', 'positive', 'very_positive', 'positive', 'positive', 'very_positive', 'neutral', 'neutral', 'neutral', 'positive', 'very_positive', 'neutral', 'neutral', 'neutral', 'very_positive', 'neutral', 'positive', 'positive', 'very_positive', 'very_positive', 'neutral', 'neutral', 'neutral', 'positive', 'very_positive', 'positive', 'positive', 'positive', 'very_positive', 'neutral', 'very_positive', 'positive', 'positive', 'neutral', 'very_positive', 'very_positive', 'very_positive', 'positive', 'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'positive', 'very_positive', 'positive', 'neutral', 'very_positive', 'positive', 'positive', 'neutral', 'positive', 'positive', 'neutral', 'neutral', 'positive', 'very_positive', 'negative', 'positive', 'positive', 'neutral', 'very_positive', 'neutral', 'neutral', 'positive', 'very_positive', 'positive', 'very_negative', 'positive', 'positive', 'positive', 'negative', 'positive', 'neutral', 'very_positive', 'very_positive', 'positive', 'neutral', 'positive', 'very_positive', 'positive', 'negative', 'neutral', 'very_positive', 'positive', 'neutral', 'positive', 'positive', 'positive', 'positive', 'neutral', 'positive', 'positive', 'positive', 'positive', 'negative', 'neutral', 'positive', 'neutral', 'neutral', 'neutral', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'neutral', 'positive', 'very_positive', 'neutral', 'negative', 'neutral', 'neutral', 'positive', 'positive', 'very_negative', 'neutral', 'very_positive', 'positive', 'neutral', 'negative', 'very_positive', 'positive', 'neutral', 'positive', 'positive', 'positive', 'very_positive', 'very_negative', 'very_positive', 'neutral', 'neutral', 'neutral', 'positive', 'neutral', 'positive', 'positive', 'neutral', 'positive', 'neutral', 'neutral', 'very_negative', 'positive', 'negative', 'positive', 'positive', 'neutral', 'positive', 'very_positive', 'positive', 'neutral', 'very_positive', 'neutral', 'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'very_positive', 'positive', 'neutral', 'positive', 'very_positive', 'positive', 'positive', 'positive', 'positive', 'neutral', 'positive', 'very_positive', 'neutral', 'negative', 'positive', 'very_positive', 'positive', 'neutral', 'neutral', 'very_positive', 'neutral', 'neutral', 'positive', 'very_positive', 'positive', 'neutral', 'neutral', 'neutral', 'positive', 'neutral', 'neutral', 'very_positive', 'very_positive', 'positive', 'positive', 'negative', 'positive', 'very_positive', 'neutral', 'very_positive', 'neutral', 'positive', 'negative', 'neutral', 'very_positive', 'positive', 'very_positive', 'neutral', 'positive', 'neutral', 'positive', 'neutral', 'positive', 'neutral', 'very_positive', 'very_positive', 'positive', 'positive', 'neutral', 'negative', 'neutral', 'positive', 'very_positive', 'neutral', 'very_positive', 'positive', 'positive', 'positive', 'neutral', 'positive', 'neutral', 'neutral', 'positive', 'neutral', 'neutral', 'very_positive', 'neutral', 'neutral', 'positive', 'negative', 'positive', 'positive', 'very_positive', 'positive', 'very_positive', 'positive', 'negative', 'very_negative', 'positive', 'positive', 'neutral', 'neutral', 'positive', 'negative', 'very_positive', 'neutral', 'very_positive', 'positive', 'positive', 'neutral', 'positive', 'negative', 'positive', 'positive', 'neutral', 'neutral', 'positive', 'negative', 'neutral', 'neutral', 'positive', 'very_positive', 'positive', 'positive', 'very_positive', 'neutral', 'positive', 'neutral', 'neutral', 'very_negative', 'neutral', 'positive', 'positive', 'positive', 'negative', 'positive', 'neutral', 'positive', 'neutral', 'positive', 'positive', 'neutral', 'positive', 'positive', 'positive', 'positive', 'neutral', 'positive', 'very_positive', 'positive', 'positive', 'neutral', 'neutral', 'positive', 'positive', 'very_positive', 'neutral', 'neutral', 'neutral', 'positive', 'very_positive', 'positive', 'positive', 'neutral', 'positive', 'positive', 'neutral', 'neutral', 'positive', 'positive', 'neutral', 'neutral', 'very_positive', 'neutral', 'positive', 'negative', 'neutral', 'neutral', 'very_positive', 'very_positive', 'very_negative', 'neutral', 'neutral', 'positive', 'positive', 'positive', 'neutral', 'positive', 'positive', 'positive', 'positive', 'very_positive', 'neutral', 'neutral', 'neutral', 'very_negative', 'neutral', 'positive', 'neutral', 'positive', 'positive', 'positive', 'negative', 'neutral', 'negative', 'positive', 'very_positive', 'very_positive', 'negative', 'positive', 'positive', 'neutral', 'neutral', 'very_positive', 'positive', 'neutral', 'neutral', 'neutral', 'very_positive', 'positive', 'positive', 'neutral', 'neutral', 'positive', 'neutral', 'neutral', 'neutral', 'positive', 'positive', 'positive', 'positive', 'neutral', 'positive', 'very_negative', 'positive', 'very_positive', 'neutral', 'positive', 'neutral', 'negative', 'positive', 'positive', 'very_positive', 'neutral', 'neutral', 'positive', 'very_positive', 'positive', 'very_positive', 'positive', 'positive', 'positive', 'neutral', 'positive', 'neutral', 'negative', 'positive', 'positive', 'neutral', 'neutral', 'positive', 'neutral', 'positive', 'positive', 'neutral', 'positive', 'negative', 'positive', 'neutral', 'positive', 'very_positive', 'very_positive', 'very_positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'neutral', 'positive', 'positive', 'neutral', 'neutral', 'positive', 'negative', 'positive', 'positive', 'positive', 'positive', 'neutral', 'very_positive', 'neutral', 'positive', 'neutral', 'positive', 'neutral', 'positive', 'neutral', 'negative', 'neutral', 'positive', 'positive', 'neutral', 'negative', 'neutral', 'very_positive', 'positive', 'positive', 'positive', 'positive', 'neutral', 'positive', 'neutral', 'neutral', 'positive', 'very_positive', 'neutral', 'positive', 'negative', 'neutral', 'neutral', 'positive', 'positive', 'positive', 'neutral', 'positive', 'positive', 'very_positive', 'neutral', 'positive', 'neutral', 'positive', 'positive', 'neutral', 'positive', 'positive', 'neutral', 'positive', 'positive', 'positive', 'very_positive', 'negative', 'positive', 'positive', 'neutral', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'neutral', 'positive', 'positive', 'neutral', 'positive', 'positive', 'positive', 'very_negative', 'neutral', 'neutral', 'positive', 'neutral', 'positive', 'positive', 'positive', 'positive', 'negative', 'very_positive', 'positive', 'positive', 'positive', 'negative', 'positive', 'neutral', 'neutral', 'neutral', 'very_positive', 'positive', 'positive', 'very_positive', 'positive', 'positive', 'neutral', 'neutral', 'positive', 'neutral', 'neutral', 'very_positive', 'neutral', 'positive', 'neutral', 'neutral', 'very_positive', 'neutral', 'positive', 'neutral', 'neutral', 'positive', 'neutral', 'positive', 'positive', 'positive', 'neutral', 'neutral', 'neutral', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'neutral', 'positive', 'positive', 'positive', 'neutral', 'positive', 'positive', 'very_positive', 'neutral', 'neutral', 'very_positive', 'very_positive', 'positive', 'positive', 'positive', 'negative', 'positive', 'neutral', 'neutral', 'positive', 'positive', 'very_positive', 'positive', 'positive', 'very_positive', 'positive', 'very_positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'very_negative', 'positive', 'positive', 'positive', 'very_positive', 'positive', 'neutral', 'very_positive', 'positive', 'neutral', 'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'positive', 'neutral', 'neutral', 'positive', 'neutral', 'very_positive', 'positive', 'positive', 'neutral', 'positive', 'negative', 'positive', 'very_positive', 'positive', 'neutral', 'positive', 'positive', 'positive', 'positive', 'neutral', 'neutral', 'positive', 'neutral', 'very_positive', 'positive', 'neutral', 'neutral', 'very_positive', 'neutral', 'negative', 'negative', 'positive', 'positive', 'neutral', 'positive', 'negative', 'neutral', 'positive', 'positive', 'very_positive', 'positive', 'negative', 'very_positive', 'negative', 'positive', 'positive', 'positive', 'positive', 'negative', 'neutral', 'neutral', 'positive', 'neutral', 'positive', 'neutral', 'positive', 'very_positive', 'positive', 'negative', 'very_positive', 'positive', 'neutral', 'neutral', 'very_positive', 'positive', 'neutral', 'positive', 'neutral', 'negative', 'positive', 'positive', 'positive', 'very_positive', 'negative', 'neutral', 'positive', 'neutral', 'very_positive', 'neutral', 'neutral', 'neutral', 'positive', 'neutral', 'positive', 'neutral', 'positive', 'positive', 'positive', 'negative', 'very_positive', 'positive', 'positive', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'very_positive', 'very_positive', 'positive', 'negative', 'positive', 'positive', 'neutral', 'positive', 'very_positive', 'positive', 'very_positive', 'positive', 'neutral', 'positive', 'positive', 'neutral', 'positive', 'neutral', 'neutral', 'positive', 'positive', 'neutral', 'neutral', 'positive', 'neutral', 'positive', 'very_positive', 'positive', 'neutral', 'positive', 'neutral', 'neutral', 'neutral', 'very_positive', 'neutral', 'positive', 'very_positive', 'positive', 'neutral', 'positive', 'neutral', 'very_positive', 'positive', 'very_positive', 'positive', 'positive', 'positive', 'very_positive', 'neutral', 'very_positive', 'very_positive', 'negative', 'positive', 'positive', 'positive', 'positive', 'very_positive', 'positive', 'positive', 'positive', 'very_negative', 'neutral', 'positive', 'very_positive', 'neutral', 'neutral', 'neutral', 'positive', 'neutral', 'positive', 'neutral', 'neutral', 'positive', 'negative', 'neutral', 'very_negative', 'very_positive', 'neutral', 'neutral', 'very_positive', 'very_positive', 'neutral', 'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'positive', 'positive', 'neutral', 'neutral', 'very_negative', 'neutral', 'positive', 'positive', 'neutral', 'positive', 'positive', 'negative', 'very_positive', 'positive', 'very_positive', 'positive', 'positive', 'positive', 'neutral', 'negative', 'very_positive', 'positive', 'neutral', 'very_positive', 'neutral', 'neutral', 'positive', 'positive', 'positive', 'positive', 'positive', 'neutral', 'neutral', 'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'positive', 'positive', 'neutral', 'neutral', 'positive', 'positive', 'positive', 'very_positive', 'neutral', 'positive', 'very_positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'negative', 'negative', 'neutral', 'positive', 'positive', 'neutral', 'neutral', 'very_positive', 'negative', 'very_positive', 'very_positive', 'positive', 'positive', 'positive', 'very_positive', 'neutral', 'negative', 'very_positive', 'very_positive', 'positive', 'positive', 'neutral', 'neutral', 'very_negative', 'positive', 'neutral', 'neutral', 'positive', 'neutral', 'very_positive', 'neutral', 'neutral', 'positive', 'positive', 'neutral', 'positive', 'very_positive', 'positive', 'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'very_positive', 'very_positive', 'neutral', 'positive', 'positive', 'very_positive', 'positive', 'neutral', 'positive', 'neutral', 'neutral', 'neutral', 'positive', 'negative', 'neutral', 'neutral', 'positive', 'positive', 'neutral', 'positive', 'very_positive', 'positive', 'neutral', 'neutral', 'positive', 'neutral', 'very_positive', 'neutral', 'positive', 'positive', 'negative', 'positive', 'positive', 'neutral', 'positive', 'very_positive', 'negative', 'positive', 'very_positive', 'very_positive', 'neutral', 'very_positive', 'positive', 'positive', 'neutral', 'positive', 'very_negative', 'positive', 'neutral', 'very_negative', 'positive', 'negative', 'very_positive', 'neutral', 'positive', 'neutral', 'neutral', 'very_positive', 'positive', 'positive', 'neutral', 'positive', 'very_positive', 'positive', 'neutral', 'very_negative', 'very_positive', 'negative', 'positive', 'positive', 'positive', 'positive', 'neutral', 'positive', 'positive', 'neutral', 'neutral', 'neutral', 'positive', 'very_positive', 'neutral', 'positive', 'neutral', 'neutral', 'negative', 'neutral', 'positive', 'positive', 'positive', 'negative', 'neutral', 'positive', 'neutral', 'positive', 'neutral', 'positive', 'neutral', 'positive', 'very_negative', 'negative', 'neutral', 'negative', 'positive', 'neutral', 'positive', 'neutral', 'positive', 'neutral', 'negative', 'very_negative', 'positive', 'very_positive', 'very_positive', 'neutral', 'very_positive', 'negative', 'positive', 'positive', 'positive', 'neutral', 'positive', 'very_positive', 'very_negative', 'positive', 'positive', 'neutral', 'positive', 'positive', 'very_positive', 'neutral', 'very_negative', 'neutral', 'neutral', 'negative', 'neutral', 'positive', 'neutral', 'positive', 'very_positive', 'positive', 'negative', 'neutral', 'positive', 'positive', 'positive', 'positive', 'very_positive', 'neutral', 'neutral', 'neutral', 'very_positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'very_positive', 'positive', 'neutral', 'very_positive', 'neutral', 'very_positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'neutral', 'positive', 'positive', 'positive', 'very_positive', 'neutral', 'positive', 'neutral', 'positive', 'positive', 'positive', 'positive', 'positive', 'neutral', 'positive', 'neutral', 'positive', 'neutral', 'positive', 'neutral', 'positive', 'neutral', 'very_positive', 'neutral', 'neutral', 'positive', 'very_positive', 'positive', 'very_negative', 'positive', 'neutral', 'positive', 'neutral', 'neutral', 'positive', 'positive', 'positive', 'positive', 'very_positive', 'positive', 'positive', 'neutral', 'neutral', 'neutral', 'positive', 'positive', 'positive', 'positive', 'positive', 'neutral', 'positive', 'neutral', 'neutral', 'very_positive', 'neutral', 'neutral', 'neutral', 'very_positive', 'negative', 'neutral', 'neutral', 'very_positive', 'positive', 'neutral', 'negative', 'positive', 'negative', 'neutral', 'positive', 'neutral', 'negative', 'neutral', 'positive', 'positive', 'positive', 'neutral', 'very_positive', 'very_positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'neutral', 'positive', 'positive', 'neutral', 'neutral', 'positive', 'very_positive', 'very_positive', 'positive', 'very_positive', 'neutral', 'positive', 'neutral', 'positive', 'very_positive', 'neutral', 'negative', 'positive', 'positive', 'positive', 'very_negative', 'positive', 'positive', 'neutral', 'neutral', 'neutral', 'negative', 'very_negative', 'positive', 'neutral', 'positive', 'neutral', 'neutral', 'positive', 'positive', 'neutral', 'neutral', 'positive', 'negative', 'very_negative', 'positive', 'neutral', 'very_positive', 'positive', 'very_positive', 'neutral', 'positive', 'positive', 'neutral', 'very_positive', 'neutral', 'positive', 'positive', 'positive', 'neutral', 'positive', 'neutral', 'neutral', 'positive', 'very_negative', 'neutral', 'positive', 'positive', 'neutral', 'positive', 'positive', 'very_positive', 'very_positive', 'negative', 'negative', 'neutral', 'neutral', 'very_positive', 'neutral', 'neutral', 'very_positive', 'positive', 'positive', 'negative', 'neutral', 'very_positive', 'neutral', 'very_positive', 'neutral', 'positive', 'positive', 'positive', 'neutral', 'positive', 'neutral', 'positive', 'negative', 'neutral', 'positive', 'neutral', 'positive', 'positive', 'positive', 'positive', 'neutral', 'positive', 'positive', 'very_positive', 'neutral', 'positive', 'positive', 'negative', 'positive', 'very_positive', 'positive', 'positive', 'very_positive', 'positive', 'very_positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'neutral', 'very_positive', 'positive', 'positive', 'neutral', 'neutral', 'positive', 'very_positive', 'neutral', 'positive', 'positive', 'neutral', 'neutral', 'negative', 'very_positive', 'positive', 'positive', 'very_positive', 'neutral', 'positive', 'neutral', 'positive', 'negative', 'neutral', 'neutral', 'positive', 'positive', 'neutral', 'very_positive', 'positive', 'neutral', 'positive', 'positive', 'very_positive', 'positive', 'very_positive', 'positive', 'positive', 'neutral', 'positive', 'very_positive', 'positive', 'neutral', 'neutral', 'positive', 'negative', 'positive', 'very_positive', 'neutral', 'very_positive', 'neutral', 'negative', 'positive', 'positive', 'positive', 'neutral', 'neutral', 'positive', 'very_positive', 'negative', 'neutral', 'very_negative', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'positive', 'neutral', 'neutral', 'negative', 'positive', 'positive', 'very_positive', 'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'very_positive', 'very_positive', 'positive', 'positive', 'neutral', 'very_positive', 'neutral', 'positive', 'neutral', 'very_positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'neutral', 'positive', 'neutral', 'very_positive', 'positive', 'negative', 'positive', 'neutral', 'very_positive', 'positive', 'very_positive', 'neutral', 'neutral', 'very_positive', 'neutral', 'positive', 'neutral', 'positive', 'neutral', 'very_negative', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'neutral', 'negative', 'negative', 'positive', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'positive', 'positive', 'very_positive', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'positive', 'very_positive', 'positive', 'neutral', 'neutral', 'neutral', 'positive', 'positive', 'very_positive', 'positive', 'positive', 'positive', 'very_positive', 'positive', 'positive', 'positive', 'positive', 'very_positive', 'positive', 'very_positive', 'neutral', 'neutral', 'very_positive', 'neutral', 'very_positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'very_positive', 'neutral', 'very_positive', 'very_positive', 'neutral', 'positive', 'positive', 'positive', 'neutral', 'very_negative', 'very_positive', 'neutral', 'very_positive', 'positive', 'positive', 'very_positive', 'neutral', 'very_positive', 'neutral', 'positive', 'neutral', 'very_positive', 'positive', 'positive', 'positive']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSNrqLwvpLXU",
        "colab_type": "code",
        "outputId": "94e342aa-7659-464d-d55e-c25fa26bbabe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "#Load data part2\n",
        "# y_tr.dropna()\n",
        "# x_train = np.asarray(trainingImages1)\n",
        "x_train = np.asarray(trainingImages1)\n",
        "y_train3 = pd.DataFrame(y_train)\n",
        "\n",
        "y_train3 = pd.get_dummies(y_train3)\n",
        "y_train3 = np.asarray(y_train3)\n",
        "# y_train.dropna()\n",
        "x_train.shape, y_train3.shape\n",
        "print(y_train3)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 1 0 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 1 0 0 0]\n",
            " ...\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZzCY4fYpLa-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_trainCNN = y_train3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsRMey15pLeY",
        "colab_type": "code",
        "outputId": "80339166-0cda-48d2-bcc0-a11064fe1143",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(x_train.shape, y_trainCNN.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6363, 224, 224, 3) (6363, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGKzW-3xpLhP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# EPOCHS = 8\n",
        "# NUM_CLASSES = 5 # (0, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcXXVCkhpLkq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# model = Sequential()\n",
        "# model.add(Conv2D(32, (3, 3), input_shape=(64,64,3), activation='relu'))\n",
        "# model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "# model.add(Dropout(0.2))\n",
        "# model.add(Conv2D(64, (3, 3),activation='relu'))\n",
        "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "# model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "# model.add(Dropout(0.2))\n",
        "# model.add(Conv2D(128, (5, 5), activation='relu'))\n",
        "# model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "# model.add(Dropout(0.2))\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(256, activation='relu'))\n",
        "# model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
        "# model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-eOcd2lpcsd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xni6IXMRpf9R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htQWcPBGpgHe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bC87Wrxpc23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePaECXbgoWQK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_model.load_weights('/content/drive/My Drive/Resnet-dense128-dense5-epoch-5.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfVNfDInoWVz",
        "colab_type": "code",
        "outputId": "ce7f32f2-61c2-461a-e98e-b1e052cc5e15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        }
      },
      "source": [
        "from keras import optimizers\n",
        "\n",
        "#LATE FUSION\n",
        "twitter = Sequential()\n",
        "twitter.add(embedding_layer)#### model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X_proc.shape[1])) ##### making changes here maybe\n",
        "#model.add(SpatialDropout1D(0.2))\n",
        "#model.add((SimpleRNN(32,activation='relu',input_shape=(1,60))))\n",
        "#model.add(Flatten())\n",
        "#model.add(Dense(60,input_shape=(60,)))\n",
        "twitter.add((LSTM(200,return_sequences=True,kernel_initializer='zeros',activation='relu')))\n",
        "# model.add((LSTM(200,return_sequences=True,kernel_initializer='zeros',activation='relu')))\n",
        "\n",
        "#model.add((LSTM(200,return_sequences=True,kernel_initializer='zeros',activation='relu')))\n",
        "#model.add(LSTM(200,kernel_initializer='zeros',activation='relu'))\n",
        "#model.add(Conv1D(512, 3, activation='relu'))\n",
        "#model.add(MaxPooling1D(5))\n",
        "#model.add(Conv1D(512, 3, activation='relu'))\n",
        "#model.add(MaxPooling1D(2))\n",
        "#model.add(Dense(128,activation='relu'))\n",
        "#model.add(Dense(64,activation='relu'))\n",
        "twitter.add(Flatten())\n",
        "twitter.add(Dense(104,activation='relu',kernel_initializer=keras.initializers.RandomUniform(minval=-0.05, maxval=0.05, seed=None)\n",
        ",bias_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)))\n",
        "twitter.add(Dense(128, activation='softmax'))\n",
        "twitter.add(Dense(64, activation='softmax'))\n",
        "\n",
        "twitter.add(Dense(4, activation='softmax'))\n",
        "\n",
        "print(twitter.summary())\n",
        "# twitter.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(lr=0.01), metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4409: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4409: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 60, 200)           2421000   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 60, 200)           320800    \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 12000)             0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 104)               1248104   \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 128)               13440     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 4)                 260       \n",
            "=================================================================\n",
            "Total params: 4,011,860\n",
            "Trainable params: 1,590,860\n",
            "Non-trainable params: 2,421,000\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wRQzl8BoWbo",
        "colab_type": "code",
        "outputId": "1c95e0c8-db5e-412a-bca8-0a9330a18695",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "concatenated = keras.layers.concatenate([img_model.layers[-1].output, twitter.layers[-1].output])\n",
        "temp = Dense(64, activation='relu')(concatenated)\n",
        "out = Dense(4,activation='softmax')(temp)\n",
        "classification_model = Model(inputs=[img_model.input,twitter.input], outputs = out)\n",
        "classification_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_preact_bn (BatchNo (None, 56, 56, 64)   256         pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_preact_relu (Activ (None, 56, 56, 64)   0           conv2_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4096        conv2_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_pad (ZeroPadding (None, 58, 58, 64)   0           conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36864       conv2_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Add)          (None, 56, 56, 256)  0           conv2_block1_0_conv[0][0]        \n",
            "                                                                 conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_preact_bn (BatchNo (None, 56, 56, 256)  1024        conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_preact_relu (Activ (None, 56, 56, 256)  0           conv2_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16384       conv2_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_pad (ZeroPadding (None, 58, 58, 64)   0           conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36864       conv2_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_preact_bn (BatchNo (None, 56, 56, 256)  1024        conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_preact_relu (Activ (None, 56, 56, 256)  0           conv2_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16384       conv2_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_pad (ZeroPadding (None, 58, 58, 64)   0           conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 28, 28, 64)   36864       conv2_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 28, 28, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 28, 28, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 28, 28, 256)  0           conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 28, 28, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Add)          (None, 28, 28, 256)  0           max_pooling2d_1[0][0]            \n",
            "                                                                 conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_preact_bn (BatchNo (None, 28, 28, 256)  1024        conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_preact_relu (Activ (None, 28, 28, 256)  0           conv3_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32768       conv3_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147456      conv3_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv3_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Add)          (None, 28, 28, 512)  0           conv3_block1_0_conv[0][0]        \n",
            "                                                                 conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_preact_bn (BatchNo (None, 28, 28, 512)  2048        conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_preact_relu (Activ (None, 28, 28, 512)  0           conv3_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65536       conv3_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147456      conv3_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_preact_bn (BatchNo (None, 28, 28, 512)  2048        conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_preact_relu (Activ (None, 28, 28, 512)  0           conv3_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65536       conv3_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147456      conv3_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_preact_bn (BatchNo (None, 28, 28, 512)  2048        conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_preact_relu (Activ (None, 28, 28, 512)  0           conv3_block4_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65536       conv3_block4_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 14, 14, 128)  147456      conv3_block4_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 14, 14, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 14, 14, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 512)  0           conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 14, 14, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Add)          (None, 14, 14, 512)  0           max_pooling2d_2[0][0]            \n",
            "                                                                 conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_preact_bn (BatchNo (None, 14, 14, 512)  2048        conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_preact_relu (Activ (None, 14, 14, 512)  0           conv4_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131072      conv4_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv4_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_conv[0][0]        \n",
            "                                                                 conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block4_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block4_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block4_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block5_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block5_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block5_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block6_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block6_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 7, 7, 256)    589824      conv4_block6_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 7, 7, 256)    0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 7, 7, 1024)   0           conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Add)          (None, 7, 7, 1024)   0           max_pooling2d_3[0][0]            \n",
            "                                                                 conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_preact_bn (BatchNo (None, 7, 7, 1024)   4096        conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_preact_relu (Activ (None, 7, 7, 1024)   0           conv5_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524288      conv5_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv5_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_conv[0][0]        \n",
            "                                                                 conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_preact_bn (BatchNo (None, 7, 7, 2048)   8192        conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_preact_relu (Activ (None, 7, 7, 2048)   0           conv5_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1048576     conv5_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_preact_bn (BatchNo (None, 7, 7, 2048)   8192        conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_preact_relu (Activ (None, 7, 7, 2048)   0           conv5_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1048576     conv5_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1_input (InputLayer)  (None, 60)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 60, 200)      2421000     embedding_1_input[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "post_bn (BatchNormalization)    (None, 7, 7, 2048)   8192        conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 60, 200)      320800      embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "post_relu (Activation)          (None, 7, 7, 2048)   0           post_bn[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 12000)        0           lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (GlobalAveragePooling2 (None, 2048)         0           post_relu[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 104)          1248104     flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 128)          262272      avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 128)          13440       dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 64)           8256        dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 64)           8256        dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 4)            260         dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 4)            260         dense_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 8)            0           dense_3[0][0]                    \n",
            "                                                                 dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 64)           576         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 4)            260         dense_8[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 27,848,284\n",
            "Trainable params: 1,862,484\n",
            "Non-trainable params: 25,985,800\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6wMIFFypkYC",
        "colab_type": "code",
        "outputId": "43241ee8-399b-4403-c592-141e59ea96f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "classification_model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(lr=0.01), metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MI_KNTzu4Ahg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fake_img = np.zeros([6367,224,224,3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtb4U_iqpka1",
        "colab_type": "code",
        "outputId": "dc788555-4a42-47e8-be00-032910b3ece6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "history = classification_model.fit([x_train, X_proc], y,  epochs=40, batch_size=32, validation_split=0.1)  #### x_train maybe wrong"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-5d5c0da61a86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_proc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_offensive\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#### x_train maybe wrong\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;31m# Check that all arrays have the same length.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcheck_array_lengths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m                 \u001b[0mcheck_array_length_consistency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m                 \u001b[0;31m# Additional checks to avoid users mistakenly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mcheck_array_length_consistency\u001b[0;34m(inputs, targets, weights)\u001b[0m\n\u001b[1;32m    229\u001b[0m         raise ValueError('All input arrays (x) should have '\n\u001b[1;32m    230\u001b[0m                          \u001b[0;34m'the same number of samples. Got array shapes: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m                          str([x.shape for x in inputs]))\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_y\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         raise ValueError('All target arrays (y) should have '\n",
            "\u001b[0;31mValueError\u001b[0m: All input arrays (x) should have the same number of samples. Got array shapes: [(6363, 224, 224, 3), (6367, 60)]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KArJgqbzpke2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot training & validation accuracy values\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYD8TNJcoWh1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}